
 <!DOCTYPE HTML>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  
  
    <title>scrapy大战京东商城 | 觅</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="Chenjiabing">
    

    
    <meta name="description" content="SCrapy爬虫大战京东商城引言
上一篇已经讲过怎样获取链接，怎样获得参数了，详情请看python爬取京东商城普通篇

代码详解

首先应该构造请求，这里使用scrapy.Request,这个方法默认调用的是start_urls构造请求，如果要改变默认的请求，那么必须重载该方法，这个方法的返回值必须是一个可迭代的对象，一般是用yield返回，代码如下：


12345def start_reque">
<meta property="og:type" content="article">
<meta property="og:title" content="scrapy大战京东商城">
<meta property="og:url" content="http://chenjiabing666.github.io/2017/04/23/scrapy大战京东商城/index.html">
<meta property="og:site_name" content="觅">
<meta property="og:description" content="SCrapy爬虫大战京东商城引言
上一篇已经讲过怎样获取链接，怎样获得参数了，详情请看python爬取京东商城普通篇

代码详解

首先应该构造请求，这里使用scrapy.Request,这个方法默认调用的是start_urls构造请求，如果要改变默认的请求，那么必须重载该方法，这个方法的返回值必须是一个可迭代的对象，一般是用yield返回，代码如下：


12345def start_reque">
<meta property="og:updated_time" content="2017-04-23T14:16:59.098Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="scrapy大战京东商城">
<meta name="twitter:description" content="SCrapy爬虫大战京东商城引言
上一篇已经讲过怎样获取链接，怎样获得参数了，详情请看python爬取京东商城普通篇

代码详解

首先应该构造请求，这里使用scrapy.Request,这个方法默认调用的是start_urls构造请求，如果要改变默认的请求，那么必须重载该方法，这个方法的返回值必须是一个可迭代的对象，一般是用yield返回，代码如下：


12345def start_reque">

    
    <link rel="alternative" href="/atom.xml" title="觅" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css">
</head>

  <body>
    <header>
      
<div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/avatar.jpg" alt="觅" title="觅"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="觅">觅</a></h1>
				<h2 class="blog-motto">爱生活爱编码</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">首页</a></li>
					
						<li><a href="/archives/">归档</a></li>
					
						<li><a href="/about/">关于我</a></li>
					
					<li>
 					
					<form class="search" action="/search/index.html" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" autocomplete="off" name="q" maxlength="20" placeholder="搜索" />
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
  
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/04/23/scrapy大战京东商城/" title="scrapy大战京东商城" itemprop="url">scrapy大战京东商城</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Chenjiabing" target="_blank" itemprop="author">Chenjiabing</a>
		
  <p class="article-time">
    <time datetime="2017-04-23T14:12:30.000Z" itemprop="datePublished"> 发表于 2017-04-23</time>
    
  </p>
</header>
	<div class="article-content">
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">文章目录</strong>
		
			<ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#SCrapy爬虫大战京东商城"><span class="toc-number">1.</span> <span class="toc-text">SCrapy爬虫大战京东商城</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#引言"><span class="toc-number">1.1.</span> <span class="toc-text">引言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#代码详解"><span class="toc-number">1.2.</span> <span class="toc-text">代码详解</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#小技巧"><span class="toc-number">1.3.</span> <span class="toc-text">小技巧</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#作者说"><span class="toc-number">1.4.</span> <span class="toc-text">作者说</span></a></li></ol></li></ol>
		
		</div>
		
		<h1 id="SCrapy爬虫大战京东商城"><a href="#SCrapy爬虫大战京东商城" class="headerlink" title="SCrapy爬虫大战京东商城"></a>SCrapy爬虫大战京东商城</h1><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><blockquote>
<p><strong>上一篇已经讲过怎样获取链接，怎样获得参数了，详情请看<a href="https://chenjiabing666.github.io/2017/04/23/python%E7%88%AC%E8%99%AB%E5%A4%A7%E6%88%98%E4%BA%AC%E4%B8%9C%E5%95%86%E5%9F%8E/">python爬取京东商城普通篇</a></strong></p>
</blockquote>
<h2 id="代码详解"><a href="#代码详解" class="headerlink" title="代码详解"></a>代码详解</h2><blockquote>
<ul>
<li><strong>首先应该构造请求，这里使用<a href="http://scrapy-chs.readthedocs.io/zh_CN/0.24/topics/spiders.html" target="_blank" rel="external">scrapy.Request</a>,这个方法默认调用的是<code>start_urls</code>构造请求，如果要改变默认的请求，那么必须重载该方法，这个方法的返回值必须是一个可迭代的对象，一般是用<code>yield</code>返回，代码如下：</strong></li>
</ul>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(self)</span>:</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">101</span>):</div><div class="line">        page=i*<span class="number">2</span><span class="number">-1</span>    <span class="comment">#这里是构造请求url的page,表示奇数</span></div><div class="line">        url=self.start_url+str(page)</div><div class="line">        <span class="keyword">yield</span> scrapy.Request(url,meta=&#123;<span class="string">'search_page'</span>:page+<span class="number">1</span>&#125;,callback=self.parse_url)   <span class="comment">#这里使用meta想回调函数传入数据，回调函数使用response.meta['search-page']接受数据</span></div></pre></td></tr></table></figure>
<blockquote>
<p><strong>下面就是解析网页了，从上面看出这里的解析回调函数是<code>parse_url</code>,因此在此函数中解析网页。这里还是和上面说的一样，这个<code>url</code>得到的仅仅是前一半的信息，如果想要得到后一半的信息还有再次请求，这里还有注意的就是一个技巧：一般先解析出一个数据的数组，不急着取出第一个数，先要用if语句判断，因为如果得到的是<code>[]</code>，那么直接取出<code>[0]</code>是会报错的，这只是一个避免报错的方法吧，代码如下:</strong></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_url</span><span class="params">(self,response)</span>:</span></div><div class="line">    <span class="keyword">if</span> response.status==<span class="number">200</span>:   <span class="comment">#判断是否请求成功</span></div><div class="line">        <span class="comment"># print response.url</span></div><div class="line">        pids = set()    <span class="comment">#这个集合用于过滤和保存得到的id,用于作为后面的ajax请求的url构成</span></div><div class="line">        <span class="keyword">try</span>:</div><div class="line">            all_goods = response.xpath(<span class="string">"//div[@id='J_goodsList']/ul/li"</span>)   <span class="comment">#首先得到所有衣服的整个框架，然后从中抽取每一个框架</span></div><div class="line"></div><div class="line">            <span class="keyword">for</span> goods <span class="keyword">in</span> all_goods:   <span class="comment">#从中解析每一个</span></div><div class="line">                <span class="comment"># scrapy.shell.inspect_response(response,self)   #这是一个调试的方法，这里会直接打开调试模式</span></div><div class="line">                items = JdSpiderItem()   <span class="comment">#定义要抓取的数据</span></div><div class="line">                img_url_src = goods.xpath(<span class="string">"div/div[1]/a/img/@src"</span>).extract()  <span class="comment"># 如果不存在就是一个空数组[]，因此不能在这里取[0]</span></div><div class="line">                img_url_delay = goods.xpath(</div><div class="line">                    <span class="string">"div/div[1]/a/img/@data-lazy-img"</span>).extract()  <span class="comment"># 这个是没有加载出来的图片，这里不能写上数组取第一个[0]</span></div><div class="line">                price = goods.xpath(<span class="string">"div/div[3]/strong/i/text()"</span>).extract()  <span class="comment">#价格</span></div><div class="line">                cloths_name = goods.xpath(<span class="string">"div/div[4]/a/em/text()"</span>).extract()</div><div class="line">                shop_id = goods.xpath(<span class="string">"div/div[7]/@ data-shopid"</span>).extract()</div><div class="line">                cloths_url = goods.xpath(<span class="string">"div/div[1]/a/@href"</span>).extract()</div><div class="line">                person_number = goods.xpath(<span class="string">"div/div[5]/strong/a/text()"</span>).extract()</div><div class="line">                pid = goods.xpath(<span class="string">"@data-pid"</span>).extract()</div><div class="line">                <span class="comment"># product_id=goods.xpath("@data-sku").extract()</span></div><div class="line">                <span class="keyword">if</span> pid:</div><div class="line">                    pids.add(pid[<span class="number">0</span>])</div><div class="line">                <span class="keyword">if</span> img_url_src:  <span class="comment"># 如果img_url_src存在</span></div><div class="line">                    <span class="keyword">print</span> img_url_src[<span class="number">0</span>]</div><div class="line">                    items[<span class="string">'img_url'</span>] = img_url_src[<span class="number">0</span>]</div><div class="line">                <span class="keyword">if</span> img_url_delay:  <span class="comment"># 如果到了没有加载完成的图片，就取这个url</span></div><div class="line">                    <span class="keyword">print</span> img_url_delay[<span class="number">0</span>]</div><div class="line">                    items[<span class="string">'img_url'</span>] = img_url_delay[<span class="number">0</span>]  <span class="comment"># 这里如果数组不是空的，就能写了</span></div><div class="line">                <span class="keyword">if</span> price:</div><div class="line">                    items[<span class="string">'price'</span>] = price[<span class="number">0</span>]</div><div class="line">                <span class="keyword">if</span> cloths_name:</div><div class="line">                    items[<span class="string">'cloths_name'</span>] = cloths_name[<span class="number">0</span>]</div><div class="line">                <span class="keyword">if</span> shop_id:</div><div class="line">                    items[<span class="string">'shop_id'</span>] = shop_id[<span class="number">0</span>]</div><div class="line">                    shop_url = <span class="string">"https://mall.jd.com/index-"</span> + str(shop_id[<span class="number">0</span>]) + <span class="string">".html"</span></div><div class="line">                    items[<span class="string">'shop_url'</span>] = shop_url</div><div class="line">                <span class="keyword">if</span> cloths_url:</div><div class="line">                    items[<span class="string">'cloths_url'</span>] = cloths_url[<span class="number">0</span>]</div><div class="line">                <span class="keyword">if</span> person_number:</div><div class="line">                    items[<span class="string">'person_number'</span>] = person_number[<span class="number">0</span>]</div><div class="line">                <span class="comment"># if product_id:</span></div><div class="line">                <span class="comment">#     print "************************************csdjkvjfskvnk***********************"</span></div><div class="line">                <span class="comment">#     print self.comments_url.format(str(product_id[0]),str(self.count))</span></div><div class="line">                <span class="comment">#     yield scrapy.Request(url=self.comments_url.format(str(product_id[0]),str(self.count)),callback=self.comments)</span></div><div class="line">                <span class="comment">#yield scrapy.Request写在这里就是每解析一个键裤子就会调用回调函数一次</span></div><div class="line">                <span class="keyword">yield</span> items</div><div class="line">        <span class="keyword">except</span> Exception:</div><div class="line">            <span class="keyword">print</span> <span class="string">"********************************************ERROR**********************************************************************"</span></div><div class="line"></div><div class="line">        <span class="keyword">yield</span> scrapy.Request(url=self.search_url.format(str(response.meta[<span class="string">'search_page'</span>]),<span class="string">","</span>.join(pids)),callback=self.next_half_parse)    <span class="comment">#再次请求，这里是请求ajax加载的数据，必须放在这里，因为只有等到得到所有的pid才能构成这个请求，回调函数用于下面的解析</span></div></pre></td></tr></table></figure>
<blockquote>
<ul>
<li><strong>从上面代码的最后可以看出最后就是解析<code>ajax</code>加载的网页了，这里调用的<code>next_half_parse</code>函数，和解析前面一个网页一样，这里需要的注意的是，如果前面定义的数据没有搜索完毕是不能使用<code>yield items</code>的，必须将items通过meta传入下一个回调函数继续完善后才能<code>yield items</code>,这里就不需要了，代码如下：</strong></li>
</ul>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#分析异步加载的网页</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">next_half_parse</span><span class="params">(self,response)</span>:</span></div><div class="line">        <span class="keyword">if</span> response.status==<span class="number">200</span>:</div><div class="line">            <span class="keyword">print</span> response.url</div><div class="line">            items=JdSpiderItem()</div><div class="line">            <span class="comment">#scrapy.shell.inspect_response(response,self)    #y用来调试的</span></div><div class="line">            <span class="keyword">try</span>:</div><div class="line">                lis=response.xpath(<span class="string">"//li[@class='gl-item']"</span>)</div><div class="line">                <span class="keyword">for</span> li <span class="keyword">in</span> lis:</div><div class="line">                    cloths_url=li.xpath(<span class="string">"div/div[1]/a/@href"</span>).extract()</div><div class="line">                    img_url_1=li.xpath(<span class="string">"div/div[1]/a/img/@src"</span>).extract()</div><div class="line">                    img_url_2=li.xpath(<span class="string">"div/div[1]/a/img/@data-lazy-img"</span>).extract()</div><div class="line">                    cloths_name=li.xpath(<span class="string">"div/div[4]/a/em/text()"</span>).extract()</div><div class="line">                    price=li.xpath(<span class="string">"div/div[3]/strong/i/text()"</span>).extract()</div><div class="line">                    shop_id=li.xpath(<span class="string">"div/div[7]/@data-shopid"</span>).extract()</div><div class="line">                    person_number=li.xpath(<span class="string">"div/div[5]/strong/a/text()"</span>).extract()</div><div class="line">                    <span class="keyword">if</span> cloths_url:</div><div class="line">                        <span class="keyword">print</span> cloths_url[<span class="number">0</span>]</div><div class="line">                        items[<span class="string">'cloths_url'</span>]=cloths_url[<span class="number">0</span>]</div><div class="line">                    <span class="keyword">if</span> img_url_1:</div><div class="line">                        <span class="keyword">print</span> img_url_1[<span class="number">0</span>]</div><div class="line">                        items[<span class="string">'img_url'</span>]=img_url_1</div><div class="line">                    <span class="keyword">if</span> img_url_2:</div><div class="line">                        <span class="keyword">print</span> img_url_2[<span class="number">0</span>]</div><div class="line">                        items[<span class="string">'img_url'</span>]=img_url_2[<span class="number">0</span>]</div><div class="line">                    <span class="keyword">if</span> cloths_name:</div><div class="line">                        items[<span class="string">'cloths_name'</span>]=cloths_name[<span class="number">0</span>]</div><div class="line">                    <span class="keyword">if</span> price:</div><div class="line">                        items[<span class="string">'price'</span>]=price[<span class="number">0</span>]</div><div class="line">                    <span class="keyword">if</span> shop_id:</div><div class="line">                        items[<span class="string">'shop_id'</span>]=shop_id[<span class="number">0</span>]</div><div class="line">                        items[<span class="string">'shop_url'</span>]=<span class="string">"https://mall.jd.com/index-"</span> + str(shop_id[<span class="number">0</span>]) + <span class="string">".html"</span></div><div class="line">                    <span class="keyword">if</span> person_number:</div><div class="line">                        items[<span class="string">'person_number'</span>]=person_number[<span class="number">0</span>]</div><div class="line">                    <span class="keyword">yield</span> items   <span class="comment">#又一次的生成，这里是完整的数据，因此可以yield items</span></div><div class="line">            <span class="keyword">except</span> Exception:</div><div class="line">                <span class="keyword">print</span> <span class="string">"**************************************************"</span></div></pre></td></tr></table></figure>
<blockquote>
<ul>
<li><strong>当然这里还用到了设置请求池，<code>mysql</code>存储，没有使用到<code>ip</code>代理，这个在我前面的博客中又讲到，这里就不再赘述了，想看源代码的朋友请<a href="https://github.com/chenjiabing666/JD_Scrapy_Spider" target="_blank" rel="external">点击这里</a></strong></li>
</ul>
</blockquote>
<h2 id="小技巧"><a href="#小技巧" class="headerlink" title="小技巧"></a>小技巧</h2><blockquote>
<ul>
<li><p><strong>人们会抱怨为什么自己的爬虫在中途断开就要重头开始爬，为什么不能从断开那里开始爬呢，这里提供一个方法：在配置文件<code>settings.py</code>中加入<code>JOBDIR=file_name</code>,这里的<code>file_name</code>是一个文件的名字</strong></p>
</li>
<li><p><strong>设置下载延迟防止被<code>ban</code>:<code>DOWNLOAD_DELAY = 2</code>:设置每一次的间隔时间   <code>RANDOMIZE_DOWNLOAD_DELAY = True</code>:这个是随机设置延迟时间  在设置的时间的<code>0.5-1.5</code>倍之间，这样可以更有效的防止被ban,一般是配套使用的</strong></p>
</li>
<li><p><strong><code>ROBOTSTXT_OBEY = False</code> :这里是表示不遵循<code>robots.txt</code>文件，默认是<code>True</code>表示遵循，这里将之改成<code>False</code></strong></p>
</li>
<li><p><strong><code>CONCURRENT_REQUESTS</code> :设置最大请求数，这里默认的时<code>16</code>，我们可以根据自己电脑的配置改的大一点来加快请求的速度</strong></p>
</li>
</ul>
<blockquote>
<h2 id="作者说"><a href="#作者说" class="headerlink" title="作者说"></a>作者说</h2><blockquote>
<p>本人秉着方便他人的想法才开始写技术文章的，因为对于自学的人来说想要找到系统的学习教程很困难，这一点我深有体会，我也是在不断的摸索中才小有所成，如果你们觉得我写的不错就帮我推广一下，让更多的人看到。另外如果有什么错误的地方也要及时联系我，方便我改进，谢谢大家对我的支持</p>
</blockquote>
</blockquote>
</blockquote>
<p><em>版权信息所有者：chenjiabing</em><br><em>如若转载请标明出处：chenjiabing666.github.io6</em></p>
  
	</div>
		<footer class="article-footer clearfix">
<div class="article-catetags">

<div class="article-categories">
  <span></span>
  <a class="article-category-link" href="/categories/Scrapy学习/">Scrapy学习</a>
</div>


  <div class="article-tags">
  
  <span></span> <a href="/tags/scrapy/">scrapy</a>
  </div>

</div>



	<div class="article-share" id="share">
	
	  <div data-url="http://chenjiabing666.github.io/2017/04/23/scrapy大战京东商城/" data-title="scrapy大战京东商城 | 觅" data-tsina="5651317821" class="share clearfix">
	  </div>
	
	</div>


</footer>

   	       
	</article>
	
<nav class="article-nav clearfix">
 
 <div class="prev" >
 <a href="/2017/04/24/Scrapyd部署爬虫/" title="Scrapyd部署爬虫">
  <strong>上一篇：</strong><br/>
  <span>
  Scrapyd部署爬虫</span>
</a>
</div>


<div class="next">
<a href="/2017/04/23/python爬虫大战京东商城/"  title="python爬虫大战京东商城">
 <strong>下一篇：</strong><br/> 
 <span>python爬虫大战京东商城
</span>
</a>
</div>

</nav>

	

<section id="comments" class="comment">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>

</div>  
      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>

  <div id="toc" class="toc-aside">
  <strong class="toc-title">文章目录</strong>
 
 <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#SCrapy爬虫大战京东商城"><span class="toc-number">1.</span> <span class="toc-text">SCrapy爬虫大战京东商城</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#引言"><span class="toc-number">1.1.</span> <span class="toc-text">引言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#代码详解"><span class="toc-number">1.2.</span> <span class="toc-text">代码详解</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#小技巧"><span class="toc-number">1.3.</span> <span class="toc-text">小技巧</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#作者说"><span class="toc-number">1.4.</span> <span class="toc-text">作者说</span></a></li></ol></li></ol>
 
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隐藏侧边栏"></a></div>
<aside class="clearfix">

  
<div class="categorieslist">
	<p class="asidetitle">分类</p>
		<ul>
		
		  
			<li><a href="/categories/BootStrap学习/" title="BootStrap学习">BootStrap学习<sup>1</sup></a></li>
		  
		
		  
			<li><a href="/categories/JQuery学习/" title="JQuery学习">JQuery学习<sup>3</sup></a></li>
		  
		
		  
			<li><a href="/categories/Linux/" title="Linux">Linux<sup>1</sup></a></li>
		  
		
		  
			<li><a href="/categories/Scrapy学习/" title="Scrapy学习">Scrapy学习<sup>9</sup></a></li>
		  
		
		  
			<li><a href="/categories/java学习/" title="java学习">java学习<sup>10</sup></a></li>
		  
		
		  
			<li><a href="/categories/python/" title="python">python<sup>2</sup></a></li>
		  
		
		  
			<li><a href="/categories/python数据挖掘与分析/" title="python数据挖掘与分析">python数据挖掘与分析<sup>1</sup></a></li>
		  
		
		  
			<li><a href="/categories/数据库干货篇/" title="数据库干货篇">数据库干货篇<sup>6</sup></a></li>
		  
		
		</ul>
</div>


  
<div class="tagslist">
	<p class="asidetitle">标签</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/scrapy/" title="scrapy">scrapy<sup>9</sup></a></li>
			
		
			
				<li><a href="/tags/swing/" title="swing">swing<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/JQuery/" title="JQuery">JQuery<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/java图形与文本处理/" title="java图形与文本处理">java图形与文本处理<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/MongoDB/" title="MongoDB">MongoDB<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/SQL/" title="SQL">SQL<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/JDBC/" title="JDBC">JDBC<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/python爬虫/" title="python爬虫">python爬虫<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/java基础/" title="java基础">java基础<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/Linux/" title="Linux">Linux<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/matplotlib/" title="matplotlib">matplotlib<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/BootStrap/" title="BootStrap">BootStrap<sup>1</sup></a></li>
			
		
		</ul>
</div>


  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS 订阅</a>
</div>

</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> 人前显贵人后受罪 <br/>
			This is my blog,believe it or not.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		<a href="http://weibo.com/5651317821" target="_blank" class="icon-weibo" title="微博"></a>
		
		
		<a href="https://github.com/chenjiabing666" target="_blank" class="icon-github" title="github"></a>
		
		
		
		
		
		
		<a href="https://www.douban.com/people/155022807" target="_blank" class="icon-douban" title="豆瓣"></a>
		
		
		
		
	</div>
			
		

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Jacman">Jacman</a> © 2017 
		
		<a href="/about" target="_blank" title="Chenjiabing">Chenjiabing</a>
		
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    $('#toc.toc-aside').css('display', 'block').addClass('fadeIn');//新加的，打开文章时自动隐藏左边的栏
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
        getSize();
        if (myWidth >= 1024) {
          c.click();
        }
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
        
    }
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  c.click(function(){
    ta.css('display', 'block').addClass('fadeIn');
  });
  o.click(function(){
    ta.css('display', 'none');
  });
  $(window).scroll(function(){
    ta.css("top",Math.max(140,320-$(this).scrollTop()));
  });
});
</script>


<script type="text/javascript">
$(document).ready(function(){ 
  var $this = $('.share'),
      url = $this.attr('data-url'),
      encodedUrl = encodeURIComponent(url),
      title = $this.attr('data-title'),
      tsina = $this.attr('data-tsina'),
      description = $this.attr('description');
  var html = [
  '<div class="hoverqrcode clearfix"></div>',
  '<a class="overlay" id="qrcode"></a>',
  '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
  '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
  '<a href="#qrcode" class="article-share-qrcode" title="微信"></a>',
  '<a href="http://widget.renren.com/dialog/share?resourceUrl=' + encodedUrl + '&srcUrl=' + encodedUrl + '&title=' + title +'" class="article-share-renren" target="_blank" title="人人"></a>',
  '<a href="http://service.weibo.com/share/share.php?title='+title+'&url='+encodedUrl +'&ralateUid='+ tsina +'&searchPic=true&style=number' +'" class="article-share-weibo" target="_blank" title="微博"></a>',
  '<span title="Share to"></span>'
  ].join('');
  $this.append(html);

  $('.hoverqrcode').hide();

  var myWidth = 0;
  function updatehoverqrcode(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
    var qrsize = myWidth > 1024 ? 200:100;
    var options = {render: 'image', size: qrsize, fill: '#2ca6cb', text: url, radius: 0.5, quiet: 1};
    var p = $('.article-share-qrcode').position();
    $('.hoverqrcode').empty().css('width', qrsize).css('height', qrsize)
                          .css('left', p.left-qrsize/2+20).css('top', p.top-qrsize-10)
                          .qrcode(options);
  };
  $(window).resize(function(){
    $('.hoverqrcode').hide();
  });
  $('.article-share-qrcode').click(function(){
    updatehoverqrcode();
    $('.hoverqrcode').toggle();
  });
  $('.article-share-qrcode').hover(function(){}, function(){
      $('.hoverqrcode').hide();
  });
});   
</script>




<script type="text/javascript">

var disqus_shortname = 'chenjiabing666';

(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
</script>






<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->

<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'null', 'null');  
ga('send', 'pageview');
</script>



<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?e6d1f421bbc9962127a50488f9ed37d1";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>



<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1261577779'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s23.cnzz.com/z_stat.php%3Fid%3D1261577779' type='text/javascript'%3E%3C/script%3E"));</script>



<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="返回顶部"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

    <script type="text/javascript" src="/js/src/love.js"></script>

  </body>
  
  <script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>
</html>
