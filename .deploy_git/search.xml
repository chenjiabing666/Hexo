<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[Spring Boot 与多数据源的那点事儿~]]></title>
      <url>%2F2020%2F10%2F21%2FSpringBoot%E4%B8%8E%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%90%E7%9A%84%E9%82%A3%E7%82%B9%E4%BA%8B%E5%84%BF%2F</url>
      <content type="text"><![CDATA[前言大约在19年的这个时候，老同事公司在做医疗系统，需要和HIS系统对接一些信息，比如患者、医护、医嘱、科室等信息。但是起初并不知道如何与HIS无缝对接，于是向我取经。 最终经过讨论采用了视图对接的方式，大致就是HIS系统提供视图，他们进行对接。 写这篇文章的目的这篇文章将会涉及到Spring Boot 与Mybatis、数据库整合，类似于整合Mybatis与数据库的文章其实网上很多，作者此前也写过一篇文章详细的介绍了一些整合的套路：Spring Boot 整合多点套路，少走点弯路~，有兴趣的可以看看。 什么是多数据源？最常见的单一应用中最多涉及到一个数据库，即是一个数据源（Datasource）。那么顾名思义，多数据源就是在一个单一应用中涉及到了两个及以上的数据库了。 其实在配置数据源的时候就已经很明确这个定义了，如以下代码：123456789@Bean(name = "dataSource")public DataSource dataSource() &#123; DruidDataSource druidDataSource = new DruidDataSource(); druidDataSource.setUrl(url); druidDataSource.setUsername(username); druidDataSource.setDriverClassName(driverClassName); druidDataSource.setPassword(password); return druidDataSource;&#125; url、username、password这三个属性已经唯一确定了一个数据库了，DataSource则是依赖这三个创建出来的。则多数据源即是配置多个DataSource（暂且这么理解）。 何时用到多数据源？正如前言介绍到的一个场景，相信大多数做过医疗系统的都会和HIS打交道，为了简化护士以及医生的操作流程，必须要将必要的信息从HIS系统对接过来，据我了解的大致有两种方案如下： HIS提供视图，比如医护视图、患者视图等，而此时其他系统只需要定时的从HIS视图中读取数据同步到自己数据库中即可。 HIS提供接口，无论是webService还是HTTP形式都是可行的，此时其他系统只需要按照要求调接口即可。 很明显第一种方案涉及到了至少两个数据库了，一个是HIS数据库，一个自己系统的数据库，在单一应用中必然需要用到多数据源的切换才能达到目的。 当然多数据源的使用场景还是有很多的，以上只是简单的一个场景。 整合单一的数据源本文使用阿里的数据库连接池druid，添加依赖如下：123456&lt;!--druid连接池--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.9&lt;/version&gt;&lt;/dependency&gt; 阿里的数据库连接池非常强大，比如数据监控、数据库加密等等内容，本文仅仅演示与Spring Boot整合的过程，一些其他的功能后续可以自己研究添加。 Druid连接池的starter的自动配置类是DruidDataSourceAutoConfigure，类上标注如下一行注解：1@EnableConfigurationProperties(&#123;DruidStatProperties.class, DataSourceProperties.class&#125;) @EnableConfigurationProperties这个注解使得配置文件中的配置生效并且映射到指定类的属性。 DruidStatProperties中指定的前缀是spring.datasource.druid，这个配置主要是用来设置连接池的一些参数。 DataSourceProperties中指定的前缀是spring.datasource，这个主要是用来设置数据库的url、username、password等信息。 因此我们只需要在全局配置文件中指定数据库的一些配置以及连接池的一些配置信息即可，前缀分别是spring.datasource.druid、spring.datasource，以下是个人随便配置的(application.properties)： 123456789101112131415161718192021222324252627282930spring.datasource.url=jdbc\:mysql\://120.26.101.xxx\:3306/xxx?useUnicode\=true&amp;characterEncoding\=UTF-8&amp;zeroDateTimeBehavior\=convertToNull&amp;useSSL\=false&amp;allowMultiQueries\=true&amp;serverTimezone=Asia/Shanghaispring.datasource.username=rootspring.datasource.password=xxxxspring.datasource.type=com.alibaba.druid.pool.DruidDataSourcespring.datasource.driver-class-name=com.mysql.jdbc.Driver#初始化连接大小spring.datasource.druid.initial-size=0#连接池最大使用连接数量spring.datasource.druid.max-active=20#连接池最小空闲spring.datasource.druid.min-idle=0#获取连接最大等待时间spring.datasource.druid.max-wait=6000spring.datasource.druid.validation-query=SELECT 1#spring.datasource.druid.validation-query-timeout=6000spring.datasource.druid.test-on-borrow=falsespring.datasource.druid.test-on-return=falsespring.datasource.druid.test-while-idle=true#配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒spring.datasource.druid.time-between-eviction-runs-millis=60000#置一个连接在池中最小生存的时间，单位是毫秒spring.datasource.druid.min-evictable-idle-time-millis=25200000#spring.datasource.druid.max-evictable-idle-time-millis=#打开removeAbandoned功能,多少时间内必须关闭连接spring.datasource.druid.removeAbandoned=true#1800秒，也就是30分钟spring.datasource.druid.remove-abandoned-timeout=1800#&lt;!-- 1800秒，也就是30分钟 --&gt;spring.datasource.druid.log-abandoned=truespring.datasource.druid.filters=mergeStat 在全局配置文件application.properties文件中配置以上的信息即可注入一个数据源到Spring Boot中。其实这仅仅是一种方式，下面介绍另外一种方式。 在自动配置类中DruidDataSourceAutoConfigure中有如下一段代码：123456@Bean(initMethod = "init") @ConditionalOnMissingBean public DataSource dataSource() &#123; LOGGER.info("Init DruidDataSource"); return new DruidDataSourceWrapper(); &#125; @ConditionalOnMissingBean和@Bean这两个注解的结合，意味着我们可以覆盖，只需要提前在IOC中注入一个DataSource类型的Bean即可。 因此我们在自定义的配置类中定义如下配置即可：1234567891011/** * @Bean：向IOC容器中注入一个Bean * @ConfigurationProperties：使得配置文件中以spring.datasource为前缀的属性映射到Bean的属性中 * @return */ @ConfigurationProperties(prefix = "spring.datasource") @Bean public DataSource dataSource()&#123; //做一些其他的自定义配置，比如密码加密等...... return new DruidDataSource(); &#125; 以上介绍了两种数据源的配置方式，第一种比较简单，第二种适合扩展，按需选择。 整合MybatisSpring Boot 整合Mybatis其实很简单，简单的几步就搞定，首先添加依赖：12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt;&lt;/dependency&gt; 第二步找到自动配置类MybatisAutoConfiguration，有如下一行代码：1@EnableConfigurationProperties(MybatisProperties.class) 老套路了，全局配置文件中配置前缀为mybatis的配置将会映射到该类中的属性。 可配置的东西很多，比如XML文件的位置、类型处理器等等，如下简单的配置：12mybatis.type-handlers-package=com.demo.typehandlermybatis.configuration.map-underscore-to-camel-case=true 如果需要通过包扫描的方式注入Mapper，则需要在配置类上加入一个注解：@MapperScan，其中的value属性指定需要扫描的包。 直接在全局配置文件配置各种属性是一种比较简单的方式，其实的任何组件的整合都有不少于两种的配置方式，下面来介绍下配置类如何配置。 MybatisAutoConfiguration自动配置类有如下一断代码：123@Bean@ConditionalOnMissingBeanpublic SqlSessionFactory sqlSessionFactory(DataSource dataSource) throws Exception &#123;&#125; @ConditionalOnMissingBean和@Bean真是老搭档了，意味着我们又可以覆盖，只需要在IOC容器中注入SqlSessionFactory（Mybatis六剑客之一生产者）。 在自定义配置类中注入即可，如下：12345678910111213141516/** * 注入SqlSessionFactory */ @Bean("sqlSessionFactory1") public SqlSessionFactory sqlSessionFactory(DataSource dataSource) throws Exception &#123; SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean(); sqlSessionFactoryBean.setDataSource(dataSource); sqlSessionFactoryBean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources("classpath*:/mapper/**/*.xml")); org.apache.ibatis.session.Configuration configuration = new org.apache.ibatis.session.Configuration(); // 自动将数据库中的下划线转换为驼峰格式 configuration.setMapUnderscoreToCamelCase(true); configuration.setDefaultFetchSize(100); configuration.setDefaultStatementTimeout(30); sqlSessionFactoryBean.setConfiguration(configuration); return sqlSessionFactoryBean.getObject(); &#125; 以上介绍了配置Mybatis的两种方式，其实在大多数场景中使用第一种已经够用了，至于为什么介绍第二种呢？当然是为了多数据源的整合而做准备了。 在MybatisAutoConfiguration中有一行很重要的代码，如下：1@ConditionalOnSingleCandidate(DataSource.class) @ConditionalOnSingleCandidate这个注解的意思是当IOC容器中只有一个候选Bean的实例才会生效。 这行代码标注在Mybatis的自动配置类中有何含义呢？下面介绍，哈哈哈~ 多数据源如何整合？上文留下的问题：为什么的Mybatis自动配置上标注如下一行代码：1@ConditionalOnSingleCandidate(DataSource.class) 以上这行代码的言外之意：当IOC容器中只有一个数据源DataSource，这个自动配置类才会生效。 哦？照这样搞，多数据源是不能用Mybatis吗？ 可能大家会有一个误解，认为多数据源就是多个的DataSource并存的，当然这样说也不是不正确。 多数据源的情况下并不是多个数据源并存的，Spring提供了AbstractRoutingDataSource这样一个抽象类，使得能够在多数据源的情况下任意切换，相当于一个动态路由的作用，作者称之为动态数据源。因此Mybatis只需要配置这个动态数据源即可。 什么是动态数据源？动态数据源简单的说就是能够自由切换的数据源，类似于一个动态路由的感觉，Spring 提供了一个抽象类AbstractRoutingDataSource，这个抽象类中哟一个属性，如下：1private Map&lt;Object, Object&gt; targetDataSources; targetDataSources是一个Map结构，所有需要切换的数据源都存放在其中，根据指定的KEY进行切换。当然还有一个默认的数据源。 AbstractRoutingDataSource这个抽象类中有一个抽象方法需要子类实现，如下：1protected abstract Object determineCurrentLookupKey(); determineCurrentLookupKey()这个方法的返回值决定了需要切换的数据源的KEY，就是根据这个KEY从targetDataSources取值（数据源）。 数据源切换如何保证线程隔离？数据源属于一个公共的资源，在多线程的情况下如何保证线程隔离呢？不能我这边切换了影响其他线程的执行。 说到线程隔离，自然会想到ThreadLocal了，将切换数据源的KEY（用于从targetDataSources中取值）存储在ThreadLocal中，执行结束之后清除即可。 单独封装了一个DataSourceHolder，内部使用ThreadLocal隔离线程，代码如下：1234567891011121314151617181920212223/** * 使用ThreadLocal存储切换数据源后的KEY */public class DataSourceHolder &#123; //线程 本地环境 private static final ThreadLocal&lt;String&gt; dataSources = new InheritableThreadLocal(); //设置数据源 public static void setDataSource(String datasource) &#123; dataSources.set(datasource); &#125; //获取数据源 public static String getDataSource() &#123; return dataSources.get(); &#125; //清除数据源 public static void clearDataSource() &#123; dataSources.remove(); &#125;&#125; 如何构造一个动态数据源？上文说过只需继承一个抽象类AbstractRoutingDataSource，重写其中的一个方法determineCurrentLookupKey()即可。代码如下：123456789101112131415161718192021222324252627/** * 动态数据源，继承AbstractRoutingDataSource */public class DynamicDataSource extends AbstractRoutingDataSource &#123; /** * 返回需要使用的数据源的key，将会按照这个KEY从Map获取对应的数据源（切换） * @return */ @Override protected Object determineCurrentLookupKey() &#123; //从ThreadLocal中取出KEY return DataSourceHolder.getDataSource(); &#125; /** * 构造方法填充Map，构建多数据源 */ public DynamicDataSource(DataSource defaultTargetDataSource, Map&lt;Object, Object&gt; targetDataSources) &#123; //默认的数据源，可以作为主数据源 super.setDefaultTargetDataSource(defaultTargetDataSource); //目标数据源 super.setTargetDataSources(targetDataSources); //执行afterPropertiesSet方法，完成属性的设置 super.afterPropertiesSet(); &#125;&#125; 上述代码很简单，分析如下： 一个多参的构造方法，指定了默认的数据源和目标数据源。 重写determineCurrentLookupKey()方法，返回数据源对应的KEY，这里是直接从ThreadLocal中取值，就是上文封装的DataSourceHolder。 定义一个注解为了操作方便且低耦合，不能每次需要切换的数据源的时候都要手动调一下接口吧，可以定义一个切换数据源的注解，如下：123456789101112131415161718/** * 切换数据源的注解 */@Target(value = ElementType.METHOD)@Retention(value = RetentionPolicy.RUNTIME)@Documentedpublic @interface SwitchSource &#123; /** * 默认切换的数据源KEY */ String DEFAULT_NAME = "hisDataSource"; /** * 需要切换到数据的KEY */ String value() default DEFAULT_NAME;&#125; 注解中只有一个value属性，指定了需要切换数据源的KEY。 有注解还不行，当然还要有切面，代码如下：12345678910111213141516171819202122232425262728293031323334@Aspect//优先级设置到最高@Order(Ordered.HIGHEST_PRECEDENCE)@Component@Slf4jpublic class DataSourceAspect &#123; @Pointcut("@annotation(SwitchSource)") public void pointcut() &#123; &#125; /** * 在方法执行之前切换到指定的数据源 * @param joinPoint */ @Before(value = "pointcut()") public void beforeOpt(JoinPoint joinPoint) &#123; /*因为是对注解进行切面，所以这边无需做过多判定，直接获取注解的值，进行环绕，将数据源设置成远方，然后结束后，清楚当前线程数据源*/ Method method = ((MethodSignature) joinPoint.getSignature()).getMethod(); SwitchSource switchSource = method.getAnnotation(SwitchSource.class); log.info("[Switch DataSource]:" + switchSource.value()); DataSourceHolder.setDataSource(switchSource.value()); &#125; /** * 方法执行之后清除掉ThreadLocal中存储的KEY，这样动态数据源会使用默认的数据源 */ @After(value = "pointcut()") public void afterOpt() &#123; DataSourceHolder.clearDataSource(); log.info("[Switch Default DataSource]"); &#125;&#125; 这个ASPECT很容易理解，beforeOpt()在方法之前执行，取值@SwitchSource中value属性设置到ThreadLocal中;afterOpt()方法在方法执行之后执行，清除掉ThreadLocal中的KEY，保证了如果不切换数据源，则用默认的数据源。 如何与Mybatis整合？单一数据源与Mybatis整合上文已经详细讲解了，数据源DataSource作为参数构建了SqlSessionFactory，同样的思想，只需要把这个数据源换成动态数据源即可。注入的代码如下：12345678910111213141516/** * 创建动态数据源的SqlSessionFactory，传入的是动态数据源 * @Primary这个注解很重要，如果项目中存在多个SqlSessionFactory，这个注解一定要加上 */ @Primary @Bean("sqlSessionFactory2") public SqlSessionFactory sqlSessionFactoryBean(DynamicDataSource dynamicDataSource) throws Exception &#123; SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean(); sqlSessionFactoryBean.setDataSource(dynamicDataSource); org.apache.ibatis.session.Configuration configuration = new org.apache.ibatis.session.Configuration(); configuration.setMapUnderscoreToCamelCase(true); configuration.setDefaultFetchSize(100); configuration.setDefaultStatementTimeout(30); sqlSessionFactoryBean.setConfiguration(configuration); return sqlSessionFactoryBean.getObject(); &#125; 与Mybatis整合很简单，只需要把数据源替换成自定义的动态数据源DynamicDataSource。 那么动态数据源如何注入到IOC容器中呢？看上文自定义的DynamicDataSource构造方法，肯定需要两个数据源了，因此必须先注入两个或者多个数据源到IOC容器中，如下：12345678910111213141516171819/** * @Bean：向IOC容器中注入一个Bean * @ConfigurationProperties：使得配置文件中以spring.datasource为前缀的属性映射到Bean的属性中 */ @ConfigurationProperties(prefix = "spring.datasource") @Bean("dataSource") public DataSource dataSource()&#123; return new DruidDataSource(); &#125; /** * 向IOC容器中注入另外一个数据源 * 全局配置文件中前缀是spring.datasource.his */ @Bean(name = SwitchSource.DEFAULT_NAME) @ConfigurationProperties(prefix = "spring.datasource.his") public DataSource hisDataSource() &#123; return DataSourceBuilder.create().build(); &#125; 以上构建的两个数据源，一个是默认的数据源，一个是需要切换到的数据源（targetDataSources），这样就组成了动态数据源了。数据源的一些信息，比如url，username需要自己在全局配置文件中根据指定的前缀配置即可，代码不再贴出。 动态数据源的注入代码如下：12345678910111213141516/** * 创建动态数据源的SqlSessionFactory，传入的是动态数据源 * @Primary这个注解很重要，如果项目中存在多个SqlSessionFactory，这个注解一定要加上 */ @Primary @Bean("sqlSessionFactory2") public SqlSessionFactory sqlSessionFactoryBean(DynamicDataSource dynamicDataSource) throws Exception &#123; SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean(); sqlSessionFactoryBean.setDataSource(dynamicDataSource); org.apache.ibatis.session.Configuration configuration = new org.apache.ibatis.session.Configuration(); configuration.setMapUnderscoreToCamelCase(true); configuration.setDefaultFetchSize(100); configuration.setDefaultStatementTimeout(30); sqlSessionFactoryBean.setConfiguration(configuration); return sqlSessionFactoryBean.getObject(); &#125; 这里还有一个问题：IOC中存在多个数据源了，那么事务管理器怎么办呢？它也懵逼了，到底选择哪个数据源呢？因此事务管理器肯定还是要重新配置的。 事务管理器此时管理的数据源将是动态数据源DynamicDataSource，配置如下：12345678/** * 重写事务管理器，管理动态数据源 */ @Primary @Bean(value = "transactionManager2") public PlatformTransactionManager annotationDrivenTransactionManager(DynamicDataSource dataSource) &#123; return new DataSourceTransactionManager(dataSource); &#125; 至此，Mybatis与多数据源的整合就完成了。 演示使用也是很简单，在需要切换数据源的方法上方标注@SwitchSource切换到指定的数据源即可，如下：12345678//不开启事务@Transactional(propagation = Propagation.NOT_SUPPORTED)//切换到HIS的数据源@SwitchSource@Overridepublic List&lt;DeptInfo&gt; list() &#123; return hisDeptInfoMapper.listDept();&#125; 这样只要执行到这方法将会切换到HIS的数据源，方法执行结束之后将会清除，执行默认的数据源。 总结本篇文章讲了Spring Boot与单数据源、Mybatis、多数据源之间的整合，希望这篇文章能够帮助读者理解多数据源的整合，虽说用的不多，但是在有些领域仍然是比较重要的。 原创不易，点点赞分享一波，谢谢支持~ 源码已经上传，需要源码的朋友公众号回复关键词多数据源。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[这类注解都不知道，还好意思说用过Spring Boot~]]></title>
      <url>%2F2020%2F10%2F20%2F%E8%BF%99%E7%B1%BB%E6%B3%A8%E8%A7%A3%E9%83%BD%E4%B8%8D%E7%9F%A5%E9%81%93%EF%BC%8C%E8%BF%98%E5%A5%BD%E6%84%8F%E6%80%9D%E8%AF%B4%E7%94%A8%E8%BF%87Spring%20Boot%2F</url>
      <content type="text"><![CDATA[前言不知道大家在使用Spring Boot开发的日常中有没有用过@Conditionalxxx注解，比如@ConditionalOnMissingBean。相信看过Spring Boot源码的朋友一定不陌生。 @Conditionalxxx这类注解表示某种判断条件成立时才会执行相关操作。掌握该类注解，有助于日常开发，框架的搭建。 今天这篇文章就从前世今生介绍一下该类注解。 Spring Boot 版本本文基于的Spring Boot的版本是2.3.4.RELEASE。 @Conditional@Conditional注解是从Spring4.0才有的，可以用在任何类型或者方法上面，通过@Conditional注解可以配置一些条件判断，当所有条件都满足的时候，被@Conditional标注的目标才会被Spring容器处理。 @Conditional的使用很广，比如控制某个Bean是否需要注册，在Spring Boot中的变形很多，比如@ConditionalOnMissingBean、@ConditionalOnBean等等，如下： 该注解的源码其实很简单，只有一个属性value，表示判断的条件（一个或者多个），是org.springframework.context.annotation.Condition类型，源码如下：1234567891011@Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface Conditional &#123; /** * All &#123;@link Condition&#125; classes that must &#123;@linkplain Condition#matches match&#125; * in order for the component to be registered. */ Class&lt;? extends Condition&gt;[] value();&#125; @Conditional注解实现的原理很简单，就是通过org.springframework.context.annotation.Condition这个接口判断是否应该执行操作。 Condition接口@Conditional注解判断条件与否取决于value属性指定的Condition实现，其中有一个matches()方法，返回true表示条件成立，反之不成立，接口如下：1234@FunctionalInterfacepublic interface Condition &#123; boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata);&#125; matches中的两个参数如下： context：条件上下文，ConditionContext接口类型的，可以用来获取容器中上下文信息。 metadata：用来获取被@Conditional标注的对象上的所有注解信息 ConditionContext接口这个接口很重要，能够从中获取Spring上下文的很多信息，比如ConfigurableListableBeanFactory，源码如下：1234567891011121314151617181920212223242526272829public interface ConditionContext &#123; /** * 返回bean定义注册器，可以通过注册器获取bean定义的各种配置信息 */ BeanDefinitionRegistry getRegistry(); /** * 返回ConfigurableListableBeanFactory类型的bean工厂，相当于一个ioc容器对象 */ @Nullable ConfigurableListableBeanFactory getBeanFactory(); /** * 返回当前spring容器的环境配置信息对象 */ Environment getEnvironment(); /** * 返回资源加载器 */ ResourceLoader getResourceLoader(); /** * 返回类加载器 */ @Nullable ClassLoader getClassLoader();&#125; 如何自定义Condition？举个栗子：假设有这样一个需求，需要根据运行环境注入不同的Bean，Windows环境和Linux环境注入不同的Bean。 实现很简单，分别定义不同环境的判断条件，实现org.springframework.context.annotation.Condition即可。 windows环境的判断条件源码如下：123456789101112131415161718/** * 操作系统的匹配条件，如果是windows系统，则返回true */public class WindowsCondition implements Condition &#123; @Override public boolean matches(ConditionContext conditionContext, AnnotatedTypeMetadata metadata) &#123; //获取当前环境信息 Environment environment = conditionContext.getEnvironment(); //获得当前系统名 String property = environment.getProperty("os.name"); //包含Windows则说明是windows系统，返回true if (property.contains("Windows"))&#123; return true; &#125; return false; &#125;&#125; Linux环境判断源码如下：12345678910111213141516/** * 操作系统的匹配条件，如果是windows系统，则返回true */public class LinuxCondition implements Condition &#123; @Override public boolean matches(ConditionContext conditionContext, AnnotatedTypeMetadata metadata) &#123; Environment environment = conditionContext.getEnvironment(); String property = environment.getProperty("os.name"); if (property.contains("Linux"))&#123; return true; &#125; return false; &#125;&#125; 配置类中结合@Bean注入不同的Bean，如下：12345678910111213141516171819202122@Configurationpublic class CustomConfig &#123; /** * 在Windows环境下注入的Bean为winP * @return */ @Bean("winP") @Conditional(value = &#123;WindowsCondition.class&#125;) public Person personWin()&#123; return new Person(); &#125; /** * 在Linux环境下注入的Bean为LinuxP * @return */ @Bean("LinuxP") @Conditional(value = &#123;LinuxCondition.class&#125;) public Person personLinux()&#123; return new Person(); &#125; 简单的测试一下，如下：1234567891011121314151617@SpringBootTestclass SpringbootInterceptApplicationTests &#123; @Autowired(required = false) @Qualifier(value = "winP") private Person winP; @Autowired(required = false) @Qualifier(value = "LinuxP") private Person linP; @Test void contextLoads() &#123; System.out.println(winP); System.out.println(linP); &#125;&#125; Windows环境下执行单元测试，输出如下：12com.example.springbootintercept.domain.Person@885e7ffnull 很显然，判断生效了，Windows环境下只注入了WINP。 条件判断在什么时候执行？条件判断的执行分为两个阶段，如下： 配置类解析阶段(ConfigurationPhase.PARSE_CONFIGURATION)：在这个阶段会得到一批配置类的信息和一些需要注册的Bean。 Bean注册阶段(ConfigurationPhase.REGISTER_BEAN)：将配置类解析阶段得到的配置类和需要注册的Bean注入到容器中。 默认都是配置解析阶段，其实也就够用了，但是在Spring Boot中使用了ConfigurationCondition，这个接口可以自定义执行阶段，比如@ConditionalOnMissingBean都是在Bean注册阶段执行，因为需要从容器中判断Bean。 这个两个阶段有什么不同呢？：其实很简单的，配置类解析阶段只是将需要加载配置类和一些Bean（被@Conditional注解过滤掉之后）收集起来，而Bean注册阶段是将的收集来的Bean和配置类注入到容器中，如果在配置类解析阶段执行Condition接口的matches()接口去判断某些Bean是否存在IOC容器中，这个显然是不行的，因为这些Bean还未注册到容器中。 什么是配置类，有哪些？：类上被@Component、 @ComponentScan、@Import、@ImportResource、@Configuration标注的以及类中方法有@Bean的方法。如何判断配置类，在源码中有单独的方法：org.springframework.context.annotation.ConfigurationClassUtils#isConfigurationCandidate。 ConfigurationCondition接口这个接口相比于@Condition接口就多了一个getConfigurationPhase()方法，可以自定义执行阶段。源码如下： 123456789101112131415161718192021222324public interface ConfigurationCondition extends Condition &#123; /** * 条件判断的阶段，是在解析配置类的时候过滤还是在创建bean的时候过滤 */ ConfigurationPhase getConfigurationPhase(); /** * 表示阶段的枚举：2个值 */ enum ConfigurationPhase &#123; /** * 配置类解析阶段，如果条件为false，配置类将不会被解析 */ PARSE_CONFIGURATION, /** * bean注册阶段，如果为false，bean将不会被注册 */ REGISTER_BEAN &#125;&#125; 这个接口在需要指定执行阶段的时候可以实现，比如需要根据某个Bean是否在IOC容器中来注入指定的Bean，则需要指定执行阶段为Bean的注册阶段（ConfigurationPhase.REGISTER_BEAN）。 多个Condition的执行顺序@Conditional中的Condition判断条件可以指定多个，默认是按照先后顺序执行，如下：12345678910111213141516171819202122232425262728class Condition1 implements Condition &#123; @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) &#123; System.out.println(this.getClass().getName()); return true; &#125;&#125;class Condition2 implements Condition &#123; @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) &#123; System.out.println(this.getClass().getName()); return true; &#125;&#125;class Condition3 implements Condition &#123; @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) &#123; System.out.println(this.getClass().getName()); return true; &#125;&#125;@Configuration@Conditional(&#123;Condition1.class, Condition2.class, Condition3.class&#125;)public class MainConfig5 &#123;&#125; 上述例子会依次按照Condition1、Condition2、Condition3执行。 默认按照先后顺序执行，但是当我们需要指定顺序呢？很简单，有如下三种方式： 实现PriorityOrdered接口，指定优先级 实现Ordered接口接口，指定优先级 使用@Order注解来指定优先级 例子如下：123456789101112131415161718192021222324252627282930313233343536373839@Order(1) class Condition1 implements Condition &#123; @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) &#123; System.out.println(this.getClass().getName()); return true; &#125;&#125;class Condition2 implements Condition, Ordered &#123; @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) &#123; System.out.println(this.getClass().getName()); return true; &#125; @Override public int getOrder() &#123; return 0; &#125;&#125;class Condition3 implements Condition, PriorityOrdered &#123; @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) &#123; System.out.println(this.getClass().getName()); return true; &#125; @Override public int getOrder() &#123; return 1000; &#125;&#125;@Configuration@Conditional(&#123;Condition1.class, Condition2.class, Condition3.class&#125;)public class MainConfig6 &#123;&#125; 根据排序的规则，PriorityOrdered的会排在前面，然后会再按照order升序，最后可以顺序是：Condtion3-&gt;Condtion2-&gt;Condtion1 Spring Boot中常用的一些注解Spring Boot中大量使用了这些注解，常见的注解如下： @ConditionalOnBean：当容器中有指定Bean的条件下进行实例化。 @ConditionalOnMissingBean：当容器里没有指定Bean的条件下进行实例化。 @ConditionalOnClass：当classpath类路径下有指定类的条件下进行实例化。 @ConditionalOnMissingClass：当类路径下没有指定类的条件下进行实例化。 @ConditionalOnWebApplication：当项目是一个Web项目时进行实例化。 @ConditionalOnNotWebApplication：当项目不是一个Web项目时进行实例化。 @ConditionalOnProperty：当指定的属性有指定的值时进行实例化。 @ConditionalOnExpression：基于SpEL表达式的条件判断。 @ConditionalOnJava：当JVM版本为指定的版本范围时触发实例化。 @ConditionalOnResource：当类路径下有指定的资源时触发实例化。 @ConditionalOnJndi：在JNDI存在的条件下触发实例化。 @ConditionalOnSingleCandidate：当指定的Bean在容器中只有一个，或者有多个但是指定了首选的Bean时触发实例化。 比如在WEB模块的自动配置类WebMvcAutoConfiguration下有这样一段代码：12345678 @Bean@ConditionalOnMissingBeanpublic InternalResourceViewResolver defaultViewResolver() &#123; InternalResourceViewResolver resolver = new InternalResourceViewResolver(); resolver.setPrefix(this.mvcProperties.getView().getPrefix()); resolver.setSuffix(this.mvcProperties.getView().getSuffix()); return resolver;&#125; 常见的@Bean和@ConditionalOnMissingBean注解结合使用，意思是当容器中没有InternalResourceViewResolver这种类型的Bean才会注入。这样写有什么好处呢？好处很明显，可以让开发者自定义需要的视图解析器，如果没有自定义，则使用默认的，这就是Spring Boot为自定义配置提供的便利。 总结@Conditional注解在Spring Boot中演变的注解很多，需要着重了解，特别是后期框架整合的时候会大量涉及。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring Boot整合多点套路，少走点弯路！！！]]></title>
      <url>%2F2020%2F10%2F15%2FSpring%20Boot%20%E7%AC%AC%20%E5%8D%81%E4%BA%8C%E5%BC%B9%EF%BC%8CSpring%20Boot%E6%95%B4%E5%90%88%E5%A4%9A%E7%82%B9%E5%A5%97%E8%B7%AF%EF%BC%8C%E5%B0%91%E8%B5%B0%E7%82%B9%E5%BC%AF%E8%B7%AF%EF%BC%81%EF%BC%81%EF%BC%81%2F</url>
      <content type="text"><![CDATA[前言 网上有很多文章都在说Spring Boot 如何整合 xxx，有文章教你为什么这么整合吗？整合了千万个框架，其实套路就那么几个，干嘛要学千万个，不如来这学习几个套路轻松整合，它不香吗？？？ 今天写这篇文章的目的就是想从思想上教给大家几个套路，不用提到整合什么就去百度了，自己尝试去亲手整合一个。 Spring Boot 版本 本文基于的Spring Boot的版本是2.3.4.RELEASE。 1. 找到自动配置类 Spring Boot 在整合任何一个组件的时候都会先添加一个依赖starter，比如整合的Mybatis有一个mybatis-spring-boot-starter，依赖如下： &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt;&lt;/dependency&gt; 每一个starter基本都会有一个自动配置类，命名方式也是类似的，格式为：xxxAutoConfiguration，比如Mybatis的自动配置类就是MybatisAutoConfiguration，Redis的自动配置类是RedisAutoConfiguration，WEB模块的自动配置类是WebMvcAutoConfiguration。 2. 注意@Conditionalxxx注解 @Conditionalxxx标注在配置类上或者结合@Bean标注在方法上，究竟是什么意思，在上一篇文章这类注解都不知道，还好意思说会Spring Boot已经从表层到底层深入的讲了一遍，不理解的可以查阅一下。 首先需要注意自动配置类上的@Conditionalxxx注解，这个是自动配置类生效的条件。 比如WebMvcAutoConfiguration类上标了一个如下注解： @ConditionalOnMissingBean(WebMvcConfigurationSupport.class) 以上这行代码的意思就是当前IOC容器中没有WebMvcConfigurationSupport这个类的实例时自动配置类才会生效，这也就是在配置类上标注@EnableWebMvc会导致自动配置类WebMvcAutoConfiguration失效的原因。 其次需要注意方法上的@Conditionalxxx注解，Spring Boot会在自动配置类中结合@Bean和@Conditionalxxx注解提供一些组件运行的默认配置，但是利用@Conditionalxxx（在特定条件下生效）注解的条件性，方便开发者覆盖这些配置。 比如在Mybatis的自动配置类MybatisAutoConfiguration中有如下一个方法： @Bean @ConditionalOnMissingBean public SqlSessionFactory sqlSessionFactory(DataSource dataSource) throws Exception {} 以上这个方法不用看方法体的内容，只看方法上的注解。@Bean这个注解的意思是注入一个Bean到IOC容器中，@ConditionalOnMissingBean这个注解就是一个条件判断了，表示当SqlSessionFactory类型的对象在IOC容器中不存在才会注入。 哦？领悟到了吧，言外之意就是如果开发者需要定制SqlSessionFactory，则可以自己的创建一个SqlSessionFactory类型的对象并且注入到IOC容器中即能覆盖自动配置类中的。比如在Mybatis配置多数据源的时候就需要定制一个SqlSessionFactory而不是使用自动配置类中的。 总之，一定要注意自动配置类上或者方法上的@Conditionalxxx注解，这个注解表示某种特定条件。 下面列出了常用的几种注解，如下： @ConditionalOnBean：当容器中有指定Bean的条件下进行实例化。@ConditionalOnMissingBean：当容器里没有指定Bean的条件下进行实例化。@ConditionalOnClass：当classpath类路径下有指定类的条件下进行实例化。@ConditionalOnMissingClass：当类路径下没有指定类的条件下进行实例化。@ConditionalOnWebApplication：当项目是一个Web项目时进行实例化。@ConditionalOnNotWebApplication：当项目不是一个Web项目时进行实例化。@ConditionalOnProperty：当指定的属性有指定的值时进行实例化。@ConditionalOnExpression：基于SpEL表达式的条件判断。@ConditionalOnJava：当JVM版本为指定的版本范围时触发实例化。@ConditionalOnResource：当类路径下有指定的资源时触发实例化。@ConditionalOnJndi：在JNDI存在的条件下触发实例化。@ConditionalOnSingleCandidate：当指定的Bean在容器中只有一个，或者有多个但是指定了首选的Bean时触发实例化。 3. 注意EnableConfigurationProperties注解 EnableConfigurationProperties这个注解常标注在配置类上，使得@ConfigurationProperties标注的配置文件生效，这样就可以在全局配置文件（application.xxx）配置指定前缀的属性了。 在Redis的自动配置类RedisAutoConfiguration上方标注如下一行代码： @EnableConfigurationProperties(RedisProperties.class) 这行代码有意思了，我们可以看看RedisProperties的源码，如下： @ConfigurationProperties(prefix = “spring.redis”)public class RedisProperties { private int database = 0; private String url; private String host = “localhost”; private String password; ….. @ConfigurationProperties这个注解指定了全局配置文件中以spring.redis.xxx为前缀的配置都会映射到RedisProperties的指定属性中，其实RedisProperties这个类中定义了Redis的一些所需属性，比如host，IP地址，密码等等。 @EnableConfigurationProperties注解就是使得指定的配置生效，能够将全局配置文件中配置的属性映射到相关类的属性中。 为什么要注意@EnableConfigurationProperties这个注解呢？ 引入一个组件后往往需要改些配置，我们都知道在全局配置文件中可以修改，但是不知道前缀是什么，可以改哪些属性，因此找到@EnableConfigurationProperties这个注解后就能找到对应的配置前缀以及可以修改的属性了。 4. 注意@Import注解 这个注解有点牛逼了，Spring 3.x中就已经有的一个注解，大致的意思的就是快速导入一个Bean或者配置类到IOC容器中。这个注解有很多妙用，后续会单独写篇文章介绍下。 @Import这个注解通常标注在自动配置类上方，并且一般都是导入一个或者多个配置类。 比如RabbitMQ的自动配置类RabbitAutoConfiguration上有如下一行代码： @Import(RabbitAnnotationDrivenConfiguration.class) 这行代码的作用就是添加了RabbitAnnotationDrivenConfiguration这个配置类，使得Spring Boot在加载到自动配置类的时候能够一起加载。 比如Redis的自动配置类RedisAutoConfiguration上有如下一行代码： @Import({ LettuceConnectionConfiguration.class, JedisConnectionConfiguration.class }) 这个@Import同时引入了Lettuce和Jedis两个配置类了，因此如果你的Redis需要使用Jedis作为连接池的话，想要知道Jedis都要配置什么，此时就应该看看JedisConnectionConfiguration这个配置类了。 总结：@Import标注在自动配置类上方，一般都是快速导入一个或者多个配置类，因此如果自动配置类没有配置一些东西时，一定要看看@Import这个注解导入的配置类。 5. 注意@AutoConfigurexxx注解 @AutoConfigurexxx这类注解决定了自动配置类的加载顺序，比如AutoConfigureAfter（在指定自动配置类之后）、AutoConfigureBefore（在指定自动配置类之前）、AutoConfigureOrder（指定自动配置类的优先级）。 为什么要注意顺序呢？因为某些组件往往之间是相互依赖的，比如Mybatis和DataSource，肯定要先将数据源相关的东西配置成功才能配置Mybatis吧。@AutoConfigurexxx这类注解正是解决了组件之间相互依赖的问题。 比如MybatisAutoConfiguration上方标注了如下一行代码： @AutoConfigureAfter(DataSourceAutoConfiguration.class) 这个行代码意思很简单，就是MybatisAutoConfiguration这个自动配置在DataSourceAutoConfiguration这个之后加载，因为你需要我，多么简单的理由。 好了，这下明白了吧，以后别犯傻问：为什么Mybatis配置好了，启动会报错？这个问题先看看数据源有没有配置成功吧。 6. 注意内部静态配置类 有些自动配置类比较简单没那么多套路，比如RedisAutoConfiguration这个自动配置类中就定义了两个注入Bean的方法，其他的没了。 但是有些自动配置类就没那么单纯了，中间能嵌套n个静态配置类，比如WebMvcAutoConfiguration，类中还嵌套了WebMvcAutoConfigurationAdapter、EnableWebMvcConfiguration、ResourceChainCustomizerConfiguration这三个配置类。如果你光看WebMvcAutoConfiguration这个自动配置类好像没配置什么，但是其内部却是大有乾坤啊。 总结：一定要自动配置类的内部嵌套的配置类，真是大有乾坤啊。 总结 以上总结了六条整合的套路，希望能够帮助读者摆脱百度，自己也能独立整合组件。 总之，Spring Boot整合xxx组件的文章很多，相信大家也看的比较懵，其实套路都是一样，学会陈某分享的套路，让你少走弯路！！！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[优质资源分享 ! Spring Boot 入门到放弃！！！]]></title>
      <url>%2F2020%2F10%2F14%2FSpring%20Boot%20%E7%AC%AC%E5%8D%81%E5%BC%B9%EF%BC%8C%E4%BC%98%E8%B4%A8%E8%B5%84%E6%BA%90%E5%88%86%E4%BA%AB%20!%20Spring%20Boot%20%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83%EF%BC%81%EF%BC%81%EF%BC%81%2F</url>
      <content type="text"><![CDATA[持续原创输出，点击上方蓝字关注我目录前言视频目录如何获取？总结前言最近不知不觉写Spring Boot专栏已经写了九篇文章了，从最底层的项目搭建到源码解析以及高级整合的部分，作者一直在精心准备文章，定时更新，有兴趣的可以看我的专栏Spring Boot进阶。有些读者反映文章更新的有点慢，想要尽快的入门Spring Boot，想我推荐一个Spring Boot的视频教程，最好能够和我的文章大纲有契合的地方。于是作者回家找了一套个人觉得很好的视频教程，今天在这里免费分享给大家。视频目录整个教程分为基础和高级整合两个部分，每套教程都有完整的代码和上课的课件，可以说是非常完整的。基础的部分目录如下：入门-课程简介入门-Spring Boot简介入门-微服务简介入门-环境准备入门-springboot-helloworld入门-HelloWorld细节-场景启动器（starter）入门-HelloWorld细节-自动配置入门-使用向导快速创建Spring Boot应用配置-yaml简介配置-yaml语法配置-yaml配置文件值获取配置-properties配置文件编码问题配置-@ConfigurationProperties与@Value区别配置-@PropertySource.@ImportResource.@Bean配置-配置文件占位符配置-Profile多环境支持配置-配置文件的加载位置配置-外部配置加载顺序配置-自动配置原理配置-@Conditional&amp;自动配置报告日志-日志框架分类和选择日志-slf4j使用原理日志-其他日志框架统一转换为slf4j日志-SpringBoot日志关系日志-SpringBoot默认配置日志-指定日志文件和日志Profile功能日志-切换日志框架web开发-简介web开发-webjars&amp;静态资源映射规则web开发-引入thymeleafweb开发-thymeleaf语法web开发-SpringMVC自动配置原理web开发-扩展与全面接管SpringMVCweb开发-【实验】-引入资源web开发-【实验】-国际化web开发-【实验】-登陆&amp;拦截器web开发-【实验】-Restful实验要求web开发-【实验】-员工列表-公共页抽取web开发-【实验】-员工列表-链接高亮&amp;列表完成web开发-【实验】-员工添加-来到添加页面web开发-【实验】-员工添加-添加完成web开发-【实验】-员工修改-重用页面&amp;修改完成web开发-【实验】-员工删除-删除完成web开发-错误处理原理&amp;定制错误页面web开发-定制错误数据web开发-嵌入式Servlet容器配置修改web开发-注册servlet三大组件web开发-切换其他嵌入式Servlet容器web开发-嵌入式Servlet容器自动配置原理web开发-嵌入式Servlet容器启动原理web开发-使用外部Servlet容器&amp;JSP支持web开发-外部Servlet容器启动SpringBoot应用原理Docker-简介Docker-核心概念Docker-linux环境准备Docker-docker安装&amp;启动&amp;停止Docker-docker镜像操作常用命令Docker-docker容器操作常用命令Docker-docker安装MySQL数据访问-简介数据访问-JDBC&amp;自动配置原理数据访问-整合Druid&amp;配置数据源监控数据访问-整合MyBatis（一）-基础环境搭建数据访问-整合MyBatis（二）-注解版MyBatis数据访问-整合MyBatis（二）-配置版MyBatis数据访问-SpringData JPA简介数据访问-整合JPA原理-第一步：创建SpringApplication原理-第二步：启动应用原理-事件监听机制相关测试原理-自定义starter结束语高级整合的部分目录如下：尚硅谷SpringBoot高级源码.课件缓存-JSR107简介缓存-Spring缓存抽象简介缓存-基本环境搭建缓存-@Cacheable初体验缓存-缓存工作原理&amp;@Cacheable运行流程缓存-@Cacheable其他属性缓存-@CachePut缓存-@CacheEvict缓存-@Caching&amp;@CacheConfig缓存-搭建redis环境&amp;测试缓存-RedisTemplate&amp;序列化机制缓存-自定义CacheManager消息-JMS&amp;AMQP简介消息-RabbitMQ基本概念简介消息-RabbitMQ运行机制消息-RabbitMQ安装测试消息-RabbitTemplate发送接受消息&amp;序列化机制消息-@RabbitListener&amp;@EnableRabbit消息-AmqpAdmin管理组件的使用检索-Elasticsearch简介&amp;安装检索-Elasticsearch快速入门检索-SpringBoot整合Jest操作ES检索-整合SpringDataElasticsearch任务-异步任务任务-定时任务任务-邮件任务安全-测试环境搭建安全-登录&amp;认证&amp;授权安全-权限控制&amp;注销安全-记住我&amp;定制登陆页分布式-dubbo简介分布式-docker安装zookeeper分布式-SpringBoot.Dubbo.Zookeeper整合分布式-SpringCloud-Eureka注册中心分布式-服务注册分布式-服务发现&amp;消费热部署-devtools开发热部署监管-监管端点测试监管-定制端点监管-自定义HealthIndicator如何获取分别回复关键词Spring Boot初级和Spring Boot高级即可获取两套视频教程。纯属个人分享，如果有侵权立即删除。总结作者的专栏文章大致和这个视频教程的大纲相同，有兴趣的可以结合着视频学习一波。持续原创输出，点击上方蓝字关注我目录前言视频目录如何获取？总结前言最近不知不觉写Spring Boot专栏已经写了九篇文章了，从最底层的项目搭建到源码解析以及高级整合的部分，作者一直在精心准备文章，定时更新，有兴趣的可以看我的专栏Spring Boot进阶。有些读者反映文章更新的有点慢，想要尽快的入门Spring Boot，想我推荐一个Spring Boot的视频教程，最好能够和我的文章大纲有契合的地方。于是作者回家找了一套个人觉得很好的视频教程，今天在这里免费分享给大家。视频目录整个教程分为基础和高级整合两个部分，每套教程都有完整的代码和上课的课件，可以说是非常完整的。基础的部分目录如下：入门-课程简介入门-Spring Boot简介入门-微服务简介入门-环境准备入门-springboot-helloworld入门-HelloWorld细节-场景启动器（starter）入门-HelloWorld细节-自动配置入门-使用向导快速创建Spring Boot应用配置-yaml简介配置-yaml语法配置-yaml配置文件值获取配置-properties配置文件编码问题配置-@ConfigurationProperties与@Value区别配置-@PropertySource.@ImportResource.@Bean配置-配置文件占位符配置-Profile多环境支持配置-配置文件的加载位置配置-外部配置加载顺序配置-自动配置原理配置-@Conditional&amp;自动配置报告日志-日志框架分类和选择日志-slf4j使用原理日志-其他日志框架统一转换为slf4j日志-SpringBoot日志关系日志-SpringBoot默认配置日志-指定日志文件和日志Profile功能日志-切换日志框架web开发-简介web开发-webjars&amp;静态资源映射规则web开发-引入thymeleafweb开发-thymeleaf语法web开发-SpringMVC自动配置原理web开发-扩展与全面接管SpringMVCweb开发-【实验】-引入资源web开发-【实验】-国际化web开发-【实验】-登陆&amp;拦截器web开发-【实验】-Restful实验要求web开发-【实验】-员工列表-公共页抽取web开发-【实验】-员工列表-链接高亮&amp;列表完成web开发-【实验】-员工添加-来到添加页面web开发-【实验】-员工添加-添加完成web开发-【实验】-员工修改-重用页面&amp;修改完成web开发-【实验】-员工删除-删除完成web开发-错误处理原理&amp;定制错误页面web开发-定制错误数据web开发-嵌入式Servlet容器配置修改web开发-注册servlet三大组件web开发-切换其他嵌入式Servlet容器web开发-嵌入式Servlet容器自动配置原理web开发-嵌入式Servlet容器启动原理web开发-使用外部Servlet容器&amp;JSP支持web开发-外部Servlet容器启动SpringBoot应用原理Docker-简介Docker-核心概念Docker-linux环境准备Docker-docker安装&amp;启动&amp;停止Docker-docker镜像操作常用命令Docker-docker容器操作常用命令Docker-docker安装MySQL数据访问-简介数据访问-JDBC&amp;自动配置原理数据访问-整合Druid&amp;配置数据源监控数据访问-整合MyBatis（一）-基础环境搭建数据访问-整合MyBatis（二）-注解版MyBatis数据访问-整合MyBatis（二）-配置版MyBatis数据访问-SpringData JPA简介数据访问-整合JPA原理-第一步：创建SpringApplication原理-第二步：启动应用原理-事件监听机制相关测试原理-自定义starter结束语高级整合的部分目录如下：尚硅谷SpringBoot高级源码.课件缓存-JSR107简介缓存-Spring缓存抽象简介缓存-基本环境搭建缓存-@Cacheable初体验缓存-缓存工作原理&amp;@Cacheable运行流程缓存-@Cacheable其他属性缓存-@CachePut缓存-@CacheEvict缓存-@Caching&amp;@CacheConfig缓存-搭建redis环境&amp;测试缓存-RedisTemplate&amp;序列化机制缓存-自定义CacheManager消息-JMS&amp;AMQP简介消息-RabbitMQ基本概念简介消息-RabbitMQ运行机制消息-RabbitMQ安装测试消息-RabbitTemplate发送接受消息&amp;序列化机制消息-@RabbitListener&amp;@EnableRabbit消息-AmqpAdmin管理组件的使用检索-Elasticsearch简介&amp;安装检索-Elasticsearch快速入门检索-SpringBoot整合Jest操作ES检索-整合SpringDataElasticsearch任务-异步任务任务-定时任务任务-邮件任务安全-测试环境搭建安全-登录&amp;认证&amp;授权安全-权限控制&amp;注销安全-记住我&amp;定制登陆页分布式-dubbo简介分布式-docker安装zookeeper分布式-SpringBoot.Dubbo.Zookeeper整合分布式-SpringCloud-Eureka注册中心分布式-服务注册分布式-服务发现&amp;消费热部署-devtools开发热部署监管-监管端点测试监管-定制端点监管-自定义HealthIndicator如何获取分别回复关键词Spring Boot初级和Spring Boot高级即可获取两套视频教程。纯属个人分享，如果有侵权立即删除。总结作者的专栏文章大致和这个视频教程的大纲相同，有兴趣的可以结合着视频学习一波。本文使用 mdnice 排版]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[满屏的try-catch，你不瘆得慌？]]></title>
      <url>%2F2020%2F10%2F14%2FSpring%20Boot%E7%AC%AC%E4%B9%9D%E5%BC%B9%EF%BC%8C%E6%BB%A1%E5%B1%8F%E7%9A%84try-catch%EF%BC%8C%E4%BD%A0%E4%B8%8D%E7%98%86%E5%BE%97%E6%85%8C%EF%BC%9F%2F</url>
      <content type="text"><![CDATA[持续原创输出，点击上方蓝字关注我 目录前言Spring Boot 版本全局统一异常处理的前世今生Spring Boot的异常如何分类？如何统一异常处理？异常匹配的顺序是什么？总结前言软件开发过程中难免遇到各种的BUG，各种的异常，一直就是在解决异常的路上永不停歇，如果你的代码中再出现try(){…}catch(){…}finally{…}代码块，你还有心情看下去吗？自己不觉得恶心吗？冗余的代码往往回丧失写代码的动力，每天搬砖似的写代码，真的很难受。今天这篇文章教你如何去掉满屏的try(){…}catch(){…}finally{…}，解放你的双手。Spring Boot 版本本文基于的Spring Boot的版本是2.3.4.RELEASE。全局统一异常处理的前世今生早在Spring 3.x就已经提出了@ControllerAdvice，可以与@ExceptionHandler、@InitBinder、@ModelAttribute 等注解注解配套使用，这几个此处就不再详细解释了。这几个注解小眼一瞟只有@ExceptionHandler与异常有关啊，翻译过来就是异常处理器。其实异常的处理可以分为两类，分别是局部异常处理和全局异常处理。局部异常处理：@ExceptionHandler和@Controller注解搭配使用，只有指定的controller层出现了异常才会被@ExceptionHandler捕获到，实际生产中怕是有成百上千个controller了吧，显然这种方式不合适。全局异常处理：既然局部异常处理不合适了，自然有人站出来解决问题了，于是就有了@ControllerAdvice这个注解的横空出世了，@ControllerAdvice搭配@ExceptionHandler彻底解决了全局统一异常处理。当然后面还出现了@RestControllerAdvice这个注解，其实就是@ControllerAdvice和@ResponseBody结晶。Spring Boot的异常如何分类？Java中的异常就很多，更别说Spring Boot中的异常了，这里不再根据传统意义上Java的异常进行分类了，而是按照controller进行分类，分为进入controller前的异常和业务层的异常，如下图：进入controller之前异常一般是javax.servlet.ServletException类型的异常，因此在全局异常处理的时候需要统一处理。几个常见的异常如下：NoHandlerFoundException：客户端的请求没有找到对应的controller，将会抛出404异常。HttpRequestMethodNotSupportedException：若匹配到了（匹配结果是一个列表，不同的是http方法不同，如：Get、Post等），则尝试将请求的http方法与列表的控制器做匹配，若没有对应http方法的控制器，则抛该异常HttpMediaTypeNotSupportedException：然后再对请求头与控制器支持的做比较，比如content-type请求头，若控制器的参数签名包含注解@RequestBody，但是请求的content-type请求头的值没有包含application/json，那么会抛该异常（当然，不止这种情况会抛这个异常）MissingPathVariableException：未检测到路径参数。比如url为：/user/{userId}，参数签名包含@PathVariable(“userId”)，当请求的url为/user，在没有明确定义url为/user的情况下，会被判定为：缺少路径参数如何统一异常处理？在统一异常处理之前其实还有许多东西需要优化的，比如统一结果返回的形式。当然这里不再细说了，不属于本文范畴。统一异常处理很简单，这里以前后端分离的项目为例，步骤如下：新建一个统一异常处理的一个类类上标注@RestControllerAdvice这一个注解，或者同时标注@ControllerAdvice和@ResponseBody这两个注解。在方法上标注@ExceptionHandler注解，并且指定需要捕获的异常，可以同时捕获多个。下面是作者随便配置一个demo，如下：/ 全局统一的异常处理，简单的配置下，根据自己的业务要求详细配置 /@RestControllerAdvice@Slf4jpublic class GlobalExceptionHandler { / 重复请求的异常 @param ex @return / @ExceptionHandler(RepeatSubmitException.class) public ResultResponse onException(RepeatSubmitException ex){ //打印日志 log.error(ex.getMessage()); //todo 日志入库等等操作 //统一结果返回 return new ResultResponse(ResultCodeEnum.CODE_NOT_REPEAT_SUBMIT); } / 自定义的业务上的异常 / @ExceptionHandler(ServiceException.class) public ResultResponse onException(ServiceException ex){ //打印日志 log.error(ex.getMessage()); //todo 日志入库等等操作 //统一结果返回 return new ResultResponse(ResultCodeEnum.CODE_SERVICE_FAIL); } / 捕获一些进入controller之前的异常，有些4xx的状态码统一设置为200 @param ex @return / @ExceptionHandler({HttpRequestMethodNotSupportedException.class, HttpMediaTypeNotSupportedException.class, HttpMediaTypeNotAcceptableException.class, MissingPathVariableException.class, MissingServletRequestParameterException.class, ServletRequestBindingException.class, ConversionNotSupportedException.class, TypeMismatchException.class, HttpMessageNotReadableException.class, HttpMessageNotWritableException.class, MissingServletRequestPartException.class, BindException.class, NoHandlerFoundException.class, AsyncRequestTimeoutException.class}) public ResultResponse onException(Exception ex){ //打印日志 log.error(ex.getMessage()); //todo 日志入库等等操作 //统一结果返回 return new ResultResponse(ResultCodeEnum.CODE_FAIL); }}注意：上面的只是一个例子，实际开发中还有许多的异常需要捕获，比如TOKEN失效、过期等等异常，如果整合了其他的框架，还要注意这些框架抛出的异常，比如Shiro，Spring Security等等框架。异常匹配的顺序是什么？有些朋友可能疑惑了，如果我同时捕获了父类和子类，那么到底能够被那个异常处理器捕获呢？比如Exception和ServiceException。此时可能就疑惑了，这里先揭晓一下答案，当然是ServiceException的异常处理器捕获了，精确匹配，如果没有ServiceException的异常处理器才会轮到它的父亲，父亲没有才会到祖父。总之一句话，精准匹配，找那个关系最近的。为什么呢？这可不是凭空瞎说的，源码为证，出处org.springframework.web.method.annotation.ExceptionHandlerMethodResolver#getMappedMethod，如下：@Nullable private Method getMappedMethod(Class&lt;? extends Throwable&gt; exceptionType) { List&lt;Class&lt;? extends Throwable&gt;&gt; matches = new ArrayList&lt;&gt;(); //遍历异常处理器中定义的异常类型 for (Class&lt;? extends Throwable&gt; mappedException : this.mappedMethods.keySet()) { //是否是抛出异常的父类，如果是添加到集合中 if (mappedException.isAssignableFrom(exceptionType)) { //添加到集合中 matches.add(mappedException); } } //如果集合不为空，则按照规则进行排序 if (!matches.isEmpty()) { matches.sort(new ExceptionDepthComparator(exceptionType)); //取第一个 return this.mappedMethods.get(matches.get(0)); } else { return null; } }在初次异常处理的时候会执行上述的代码找到最匹配的那个异常处理器方法，后续都是直接从缓存中（一个Map结构，key是异常类型，value是异常处理器方法）。别着急，上面代码最精华的地方就是对matches进行排序的代码了，我们来看看ExceptionDepthComparator这个比较器的关键代码，如下：//递归调用，获取深度，depth值越小越精准匹配private int getDepth(Class&lt;?&gt; declaredException, Class&lt;?&gt; exceptionToMatch, int depth) { //如果匹配了，返回 if (exceptionToMatch.equals(declaredException)) { // Found it! return depth; } // 递归结束的条件，最大限度了 if (exceptionToMatch == Throwable.class) { return Integer.MAX_VALUE; } //继续匹配父类 return getDepth(declaredException, exceptionToMatch.getSuperclass(), depth + 1); }精髓全在这里了，一个递归搞定，计算深度，depth初始值为0。值越小，匹配度越高越精准。总结全局异常的文章万万千，能够讲清楚的能有几篇呢？只出最精的文章，做最野的程序员，如果觉得不错的，关注分享走一波，谢谢支持！！！另外作者的第一本PDF书籍已经整理好了，由浅入深的详细介绍了Mybatis基础以及底层源码，有需要的朋友公众号回复关键词Mybatis进阶即可获取，目录如下：]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[一波带走，教你Spring Boot如何扩展、接管MVC？]]></title>
      <url>%2F2020%2F10%2F14%2FSpring%20Boot%E7%AC%AC%E5%85%AB%E5%BC%B9%EF%BC%8C%E4%B8%80%E6%B3%A2%E5%B8%A6%E8%B5%B0%EF%BC%8C%E6%95%99%E4%BD%A0Spring%20Boot%E5%A6%82%E4%BD%95%E6%89%A9%E5%B1%95%E3%80%81%E6%8E%A5%E7%AE%A1MVC%EF%BC%9F%2F</url>
      <content type="text"><![CDATA[持续原创输出，点击上方蓝字关注我 目录前言Spring Boot 版本如何扩展MVC？如何自定义一个拦截器？什么都不配置为什么依然能运行MVC相关的功能？如何全面接管MVC？【不推荐】为什么@EnableWebMvc一个注解就能够全面接管MVC？Spring Boot相关资料总结前言自从用了Spring Boot是否有一个感觉，以前MVC的配置都很少用到了，比如视图解析器，拦截器，过滤器等等，这也正是Spring Boot好处之一。但是往往Spring Boot提供默认的配置不一定适合实际的需求，因此需要能够定制MVC的相关功能，这篇文章就介绍一下如何扩展和全面接管MVC。Spring Boot 版本本文基于的Spring Boot的版本是2.3.4.RELEASE。如何扩展MVC？在这里需要声明一个前提：配置类上没有标注@EnableWebMvc并且没有任何一个配置类继承了WebMvcConfigurationSupport。至于具体原因，下文会详细解释。扩展MVC其实很简单，只需要以下步骤：创建一个MVC的配置类，并且标注@Configuration注解。实现WebMvcConfigurer这个接口，并且实现需要的方法。WebMvcConfigurer这个接口中定义了MVC相关的各种组件，比如拦截器，视图解析器等等的定制方法，需要定制什么功能，只需要实现即可。在Spring Boot之前的版本还可以继承一个抽象类WebMvcConfigurerAdapter，不过在2.3.4.RELEASE这个版本中被废弃了，如下：@Deprecatedpublic abstract class WebMvcConfigurerAdapter implements WebMvcConfigurer {}举个栗子：现在要添加一个拦截器，使其在Spring Boot中生效，此时就可以在MVC的配置类重写addInterceptors()方法，如下：/ MVC扩展的配置类，实现WebMvcConfigurer接口 /@Configurationpublic class WebConfig implements WebMvcConfigurer { @Autowired private RepeatSubmitInterceptor repeatSubmitInterceptor; / 重写addInterceptors方法，注入自定义的拦截器 / @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(repeatSubmitInterceptor).excludePathPatterns(“/error”); }}操作很简单，除了拦截器，还可以定制视图解析，资源映射处理器等等相关的功能，和Spring MVC很类似，只不过Spring MVC是在XML文件中配置，Spring Boot是在配置类中配置而已。什么都不配置为什么依然能运行MVC相关的功能？早期的SSM架构中想要搭建一个MVC其实挺复杂的，需要配置视图解析器，资源映射处理器，DispatcherServlet等等才能正常运行，但是为什么Spring Boot仅仅是添加一个WEB模块依赖即能正常运行呢？依赖如下：&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;其实这已经涉及到了Spring Boot高级的知识点了，在这里就简单的说一下，Spring Boot的每一个starter都会有一个自动配置类，什么是自动配置类呢？自动配置类就是在Spring Boot项目启动的时候会自动加载的类，能够在启动期间就配置一些默认的配置。WEB模块的自动配置类是WebMvcAutoConfiguration。WebMvcAutoConfiguration这个配置类中还含有如下一个子配置类WebMvcAutoConfigurationAdapter，如下：@Configuration(proxyBeanMethods = false) @Import(EnableWebMvcConfiguration.class) @EnableConfigurationProperties({ WebMvcProperties.class, ResourceProperties.class }) @Order(0) public static class WebMvcAutoConfigurationAdapter implements WebMvcConfigurer {}WebMvcAutoConfigurationAdapter这个子配置类实现了WebMvcConfigurer这个接口，这个正是MVC扩展接口，这个就很清楚了。自动配置类是在项目启动的时候就加载的，因此Spring Boot会在项目启动时加载WebMvcAutoConfigurationAdapter这个MVC扩展配置类，提前完成一些默认的配置（比如内置了默认的视图解析器，资源映射处理器等等），这也就是为什么没有配置什么MVC相关的东西依然能够运行。如何全面接管MVC？【不推荐】全面接管MVC是什么意思呢？全面接管的意思就是不需要Spring Boot自动配置，而是全部使用自定义的配置。全面接管MVC其实很简单，只需要在配置类上添加一个@EnableWebMvc注解即可。还是添加拦截器，例子如下：/* @EnableWebMvc：全面接管MVC，导致自动配置类失效 */@Configuration@EnableWebMvcpublic class WebMvcConfig implements WebMvcConfigurer { @Autowired private RepeatSubmitInterceptor repeatSubmitInterceptor; @Override public void addInterceptors(InterceptorRegistry registry) { //添加拦截器 registry.addInterceptor(repeatSubmitInterceptor).excludePathPatterns(“/error”); }}一个注解就能全面接口MVC，是不是很爽，不过，不建议使用。为什么@EnableWebMvc一个注解就能够全面接管MVC？what？？？为什么呢？上面刚说过自动配置类WebMvcAutoConfiguration会在项目启动期间加载一些默认的配置，这会怎么添加一个@EnableWebMvc注解就不行了呢？其实很简单，@EnableWebMvc源码如下：@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)@Documented@Import(DelegatingWebMvcConfiguration.class)public @interface EnableWebMvc {}其实重要的就是这个@Import(DelegatingWebMvcConfiguration.class)注解了，Spring中的注解，快速导入一个配置类DelegatingWebMvcConfiguration，源码如下：@Configuration(proxyBeanMethods = false)public class DelegatingWebMvcConfiguration extends WebMvcConfigurationSupport {}明白了，@EnableWebMvc这个注解实际上就是导入了一个WebMvcConfigurationSupport子类型的配置类而已。而WEB模块的自动配置类有这么一行注解@ConditionalOnMissingBean(WebMvcConfigurationSupport.class)，源码如下：@Configuration(proxyBeanMethods = false)@ConditionalOnWebApplication(type = Type.SERVLET)@ConditionalOnClass({ Servlet.class, DispatcherServlet.class, WebMvcConfigurer.class })@ConditionalOnMissingBean(WebMvcConfigurationSupport.class)@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE + 10)@AutoConfigureAfter({ DispatcherServletAutoConfiguration.class, TaskExecutionAutoConfiguration.class, ValidationAutoConfiguration.class })public class WebMvcAutoConfiguration {这个注解@ConditionalOnMissingBean什么意思呢？简单的说就是IOC容器中没有指定的Bean这个配置才会生效。一切都已经揭晓了，@EnableWebMvc导入了一个WebMvcConfigurationSupport类型的配置类，导致了自动配置类WebMvcAutoConfiguration标注的@@ConditionalOnMissingBean(WebMvcConfigurationSupport.class)判断为false了，从而自动配置类失效了。Spring Boot相关资料前期有很多的小伙伴私信我，觉得看文章太枯燥了，有些东西也不能理解的透彻，有没有好的视频课程分享，前几天特意回家找了找资源，总算找到了适合入门学习的完整视频教程，从Spring Boot初级入门到高级整合，讲解的非常全面，一些目录如下：这些资料全部免费提供，我的文章也是尽量跟着视频大纲匹配，希望小伙伴能够系统完整的学习Spring Boot。公众号【码猿技术专栏】回复关键词Spring Boot初级和Spring Boot高级分别获取初级和高级的视频教程。总结扩展和全面接管MVC都很简单，但是不推荐全面接管MVC，一旦全面接管了，WEb模块的这个starter将没有任何意义，一些全局配置文件中与MVC相关的配置也将会失效。另外作者的第一本PDF书籍已经整理好了，由浅入深的详细介绍了Mybatis基础以及底层源码，有需要的朋友公众号回复关键词Mybatis进阶即可获取，目录如下：]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[过滤器如何配置，一波梭哈~]]></title>
      <url>%2F2020%2F10%2F14%2FSpring%20Boot%E7%AC%AC%E4%B8%83%E5%BC%B9%EF%BC%8C%E8%BF%87%E6%BB%A4%E5%99%A8%E5%A6%82%E4%BD%95%E9%85%8D%E7%BD%AE%EF%BC%8C%E4%B8%80%E6%B3%A2%E6%A2%AD%E5%93%88~%2F</url>
      <content type="text"><![CDATA[持续原创输出，点击上方蓝字关注我 目录前言Spring Boot 版本什么是过滤器？Filter的执行原理如何自定义一个Filter？Spring Boot如何配置Filter？配置类中使用@Bean注入【推荐使用】使用@WebFilter举个栗子总结前言上篇文章介绍了Spring Boot中如何配置拦截器，今天这篇文章就来讲讲类似于拦截器的一个组件：过滤器。其实在实际开发中过滤器真的接触的不多，但是在应用中却是不可或缺的角色，值得花费一个章节专门介绍一下。Spring Boot 版本本文基于的Spring Boot的版本是2.3.4.RELEASE。什么是过滤器？Filter也称之为过滤器，它是Servlet技术中最实用的技术，WEB开发人员通过Filter技术，对web服务器管理的所有web资源：例如JSP，Servlet，静态图片文件或静态HTML文件进行拦截，从而实现一些特殊功能。例如实现URL级别的权限控制、过滤敏感词汇、压缩响应信息等一些高级功能。Filter的执行原理当客户端发出Web资源的请求时，Web服务器根据应用程序配置文件设置的过滤规则进行检查，若客户请求满足过滤规则，则对客户请求／响应进行拦截，对请求头和请求数据进行检查或改动，并依次通过过滤器链，最后把请求／响应交给请求的Web资源处理。请求信息在过滤器链中可以被修改，也可以根据条件让请求不发往资源处理器，并直接向客户机发回一个响应。当资源处理器完成了对资源的处理后，响应信息将逐级逆向返回。同样在这个过程中，用户可以修改响应信息，从而完成一定的任务，如下图：服务器会按照过滤器定义的先后循序组装成一条链，然后一次执行其中的doFilter()方法。（注：这一点Filter和Servlet是不一样的）执行的顺序就如下图所示，执行第一个过滤器的chain.doFilter()之前的代码，第二个过滤器的chain.doFilter()之前的代码，请求的资源，第二个过滤器的chain.doFilter()之后的代码，第一个过滤器的chain.doFilter()之后的代码，最后返回响应。如何自定义一个Filter？这个问题其实不是Spring Boot这个章节应该介绍的了，在Spring MVC中就应该会的内容，只需要实现javax.servlet.Filter这个接口，重写其中的方法。实例如下：@Componentpublic class CrosFilter implements Filter { //重写其中的doFilter方法 @Override public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException { //继续执行下一个过滤器 chain.doFilter(req, response); }Spring Boot如何配置Filter？自定义好了过滤器当然要使其在Spring Boot中生效了，Spring Boot配置Filter有两种方式，其实都很简单，下面一一介绍。配置类中使用@Bean注入【推荐使用】其实很简单，只需要将FilterRegistrationBean这个实例注入到IOC容器中即可，如下：@Configurationpublic class FilterConfig { @Autowired private Filter1 filter1; @Autowired private Filter2 filter2; / 注入Filter1 @return / @Bean public FilterRegistrationBean filter1() { FilterRegistrationBean registration = new FilterRegistrationBean(); registration.setFilter(filter1); registration.addUrlPatterns(“/“); registration.setName(“filter1”); //设置优先级别 registration.setOrder(1); return registration; } / 注入Filter2 @return / @Bean public FilterRegistrationBean filter2() { FilterRegistrationBean registration = new FilterRegistrationBean(); registration.setFilter(filter2); registration.addUrlPatterns(“/“); registration.setName(“filter2”); //设置优先级别 registration.setOrder(2); return registration; }}注意：设置的优先级别决定了过滤器的执行顺序。使用@WebFilter@WebFilter是Servlet3.0的一个注解，用于标注一个Filter，Spring Boot也是支持这种方式，只需要在自定义的Filter上标注该注解即可，如下：@WebFilter(filterName = “crosFilter”,urlPatterns = {“/“})public class CrosFilter implements Filter { //重写其中的doFilter方法 @Override public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException { //继续执行下一个过滤器 chain.doFilter(req, response); }}要想@WebFilter注解生效，需要在配置类上标注另外一个注解@ServletComponentScan用于扫描使其生效，如下：@SpringBootApplication@ServletComponentScan(value = {“com.example.springbootintercept.filter”})public class SpringbootApplication {}至此，配置就完成了，启动项目，即可正常运行。举个栗子对于前后端分离的项目来说跨域是一个难题，什么是跨域问题？如何造成的？这个不是本章的重点。对于跨域问题有多中解决方案，比如JSONP，网关支持等等。关于跨域的问题以及Spring Boot如何优雅的解决跨域问题？将会在后续文章中介绍。今天主要介绍如何使用过滤器来解决跨域问题。其实原理很简单，只需要在请求头中添加相应支持跨域的内容即可，如下代码仅仅是简单的演示下，针对细致的内容还需自己完善，比如白名单等等。@Componentpublic class CrosFilter implements Filter { //重写其中的doFilter方法 @Override public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException { HttpServletResponse response = (HttpServletResponse) res; response.setHeader(“Access-Control-Allow-Origin”, ““); response.setHeader(“Access-Control-Allow-Credentials”, “true”); response.setHeader(“Access-Control-Allow-Methods”, “POST, GET, OPTIONS, DELETE”); response.setHeader(“Access-Control-Max-Age”, “3600”); response.setHeader(“Access-Control-Allow-Headers”,“ Origin, X-Requested-With, Content-Type, Accept”); //继续执行下一个过滤器 chain.doFilter(req, response); }}配置类中注入FilterRegistrationBean，如下代码：@Configurationpublic class FilterConfig { @Autowired private CrosFilter crosFilter; /* 注入crosFilter @return / @Bean public FilterRegistrationBean crosFilter() { FilterRegistrationBean registration = new FilterRegistrationBean(); registration.setFilter(crosFilter); registration.addUrlPatterns(“/*”); registration.setName(“crosFilter”); //设置优先级别 registration.setOrder(Ordered.HIGHEST_PRECEDENCE); return registration; }}至此，配置完成，相关细致功能还需自己润色。总结过滤器内容相对简单些，但是在实际开发中不可或缺，比如常用的权限控制框架Shiro，Spring Security，内部都是使用过滤器，了解一下对以后的深入学习有着固本的作用。另外作者的第一本PDF书籍已经整理好了，由浅入深的详细介绍了Mybatis基础以及底层源码，有需要的朋友公众号回复关键词Mybatis进阶即可获取，目录如下：如果有所收获，不妨关注在看支持一下，持续连载中…..]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[拦截器如何配置，看这儿~]]></title>
      <url>%2F2020%2F10%2F14%2FSpring%20Boot%E7%AC%AC%E5%85%AD%E5%BC%B9%EF%BC%8C%E6%8B%A6%E6%88%AA%E5%99%A8%E5%A6%82%E4%BD%95%E9%85%8D%E7%BD%AE%EF%BC%8C%E7%9C%8B%E8%BF%99%E5%84%BF~%2F</url>
      <content type="text"><![CDATA[持续原创输出，点击上方蓝字关注我吧 目录前言Spring Boot 版本什么是拦截器？如何自定义一个拦截器？如何使其在Spring Boot中生效？举个栗子思路根据什么判断这个接口已经请求了？这个具体的信息存放在哪里？如何实现？总结前言上篇文章讲了Spring Boot的WEB开发基础内容，相信读者朋友们已经有了初步的了解，知道如何写一个接口。今天这篇文章来介绍一下拦截器在Spring Boot中如何自定义以及配置。Spring Boot 版本本文基于的Spring Boot的版本是2.3.4.RELEASE。什么是拦截器？Spring MVC中的拦截器（Interceptor）类似于Servlet中的过滤器（Filter），它主要用于拦截用户请求并作相应的处理。例如通过拦截器可以进行权限验证、记录请求信息的日志、判断用户是否登录等。如何自定义一个拦截器？自定义一个拦截器非常简单，只需要实现HandlerInterceptor这个接口即可，该接口有三个可以实现的方法，如下：preHandle()方法：该方法会在控制器方法前执行，其返回值表示是否知道如何写一个接口。中断后续操作。当其返回值为true时，表示继续向下执行；当其返回值为false时，会中断后续的所有操作（包括调用下一个拦截器和控制器类中的方法执行等）。postHandle()方法：该方法会在控制器方法调用之后，且解析视图之前执行。可以通过此方法对请求域中的模型和视图做出进一步的修改。afterCompletion()方法：该方法会在整个请求完成，即视图渲染结束之后执行。可以通过此方法实现一些资源清理、记录日志信息等工作。如何使其在Spring Boot中生效？其实想要在Spring Boot生效其实很简单，只需要定义一个配置类，实现WebMvcConfigurer这个接口，并且实现其中的addInterceptors()方法即可，代码演示如下：@Configurationpublic class WebConfig implements WebMvcConfigurer { @Autowired private XXX xxx; @Override public void addInterceptors(InterceptorRegistry registry) { //不拦截的uri final String[] commonExclude = {}}; registry.addInterceptor(xxx).excludePathPatterns(commonExclude); }}举个栗子开发中可能会经常遇到短时间内由于用户的重复点击导致几秒之内重复的请求，可能就是在这几秒之内由于各种问题，比如网络，事务的隔离性等等问题导致了数据的重复等问题，因此在日常开发中必须规避这类的重复请求操作，今天就用拦截器简单的处理一下这个问题。思路在接口执行之前先对指定接口（比如标注某个注解的接口）进行判断，如果在指定的时间内（比如5秒）已经请求过一次了，则返回重复提交的信息给调用者。根据什么判断这个接口已经请求了？根据项目的架构可能判断的条件也是不同的，比如IP地址，用户唯一标识、请求参数、请求URI等等其中的某一个或者多个的组合。这个具体的信息存放在哪里？由于是短时间内甚至是瞬间并且要保证定时失效，肯定不能存在事务性数据库中了，因此常用的几种数据库中只有Redis比较合适了。如何实现？第一步，先自定义一个注解，可以标注在类或者方法上，如下：@Target({ElementType.METHOD, ElementType.TYPE})@Retention(RetentionPolicy.RUNTIME)public @interface RepeatSubmit { / 默认失效时间5秒 / long seconds() default 5;}第二步，创建一个拦截器，注入到IOC容器中，实现的思路很简单，判断controller的类或者方法上是否标注了@RepeatSubmit这个注解，如果标注了，则拦截判断，否则跳过，代码如下：/ 重复请求的拦截器 @Component：该注解将其注入到IOC容器中 /@Componentpublic class RepeatSubmitInterceptor implements HandlerInterceptor { /** Redis的API / @Autowired private StringRedisTemplate stringRedisTemplate; /** preHandler方法，在controller方法之前执行 判断条件仅仅是用了uri，实际开发中根据实际情况组合一个唯一识别的条件。 / @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { if (handler instanceof HandlerMethod){ //只拦截标注了@RepeatSubmit该注解 HandlerMethod method=(HandlerMethod)handler; //标注在方法上的@RepeatSubmit RepeatSubmit repeatSubmitByMethod = AnnotationUtils.findAnnotation(method.getMethod(),RepeatSubmit.class); //标注在controler类上的@RepeatSubmit RepeatSubmit repeatSubmitByCls = AnnotationUtils.findAnnotation(method.getMethod().getDeclaringClass(), RepeatSubmit.class); //没有限制重复提交，直接跳过 if (Objects.isNull(repeatSubmitByMethod)&amp;&amp;Objects.isNull(repeatSubmitByCls)) return true; // todo: 组合判断条件，这里仅仅是演示，实际项目中根据架构组合条件 //请求的URI String uri = request.getRequestURI(); //存在即返回false，不存在即返回true Boolean ifAbsent = stringRedisTemplate.opsForValue().setIfAbsent(uri, “”, Objects.nonNull(repeatSubmitByMethod)?repeatSubmitByMethod.seconds():repeatSubmitByCls.seconds(), TimeUnit.SECONDS); //如果存在，表示已经请求过了，直接抛出异常，由全局异常进行处理返回指定信息 if (ifAbsent!=null&amp;&amp;!ifAbsent) throw new RepeatSubmitException(); } return true; }}第三步，在Spring Boot中配置这个拦截器，代码如下：@Configurationpublic class WebConfig implements WebMvcConfigurer { @Autowired private RepeatSubmitInterceptor repeatSubmitInterceptor; @Override public void addInterceptors(InterceptorRegistry registry) { //不拦截的uri final String[] commonExclude = {“/error”, “/files/*“}; registry.addInterceptor(repeatSubmitInterceptor).excludePathPatterns(commonExclude); }}OK，拦截器已经配置完成，只需要在需要拦截的接口上标注@RepeatSubmit这个注解即可，如下：@RestController@RequestMapping(“/user”)//标注了@RepeatSubmit注解，全部的接口都需要拦截@RepeatSubmitpublic class LoginController { @RequestMapping(“/login”) public String login(){ return “login success”; }}此时，请求这个URI:http://localhost:8080/springboot-demo/user/login在5秒之内只能请求一次。注意：标注在方法上的超时时间会覆盖掉类上的时间，因为如下一段代码：Boolean ifAbsent = stringRedisTemplate.opsForValue().setIfAbsent(uri, “”, Objects.nonNull(repeatSubmitByMethod)?repeatSubmitByMethod.seconds():repeatSubmitByCls.seconds(), TimeUnit.SECONDS);这段代码的失效时间先取值repeatSubmitByMethod中配置的，如果为null，则取值repeatSubmitByCls配置的。总结至此，拦截器的内容就介绍完了，其实配置起来很简单，没什么重要的内容。上述例子中的源代码有需要的朋友公众号码猿技术专栏内回复关键词拦截器即可获取。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring Boot WEB开发初了解~]]></title>
      <url>%2F2020%2F10%2F14%2FSpring%20Boot%E7%AC%AC%E4%BA%94%E5%BC%B9%EF%BC%8CWEB%E5%BC%80%E5%8F%91%E5%88%9D%E4%BA%86%E8%A7%A3~%2F</url>
      <content type="text"><![CDATA[持续原创输出，点击上方蓝字关注我吧目录前言Spring Boot 版本前提条件（必须注意）添加依赖第一个接口开发如何自定义tomcat的端口？如何自定义项目路径？JSON格式化日期格式的设置其他属性的配置如何在配置类配置？总结前言今天是Spring Boot专栏的第五篇文章，相信大家看了前四篇文章对Spring Boot已经有了初步的了解，今天这篇文章就来介绍一下Spring Boot的重要功能WEB开发。Spring Boot 版本本文基于的Spring Boot的版本是2.3.4.RELEASE。前提条件（必须注意）Spring Boot的WEB开发有自己的启动器和自动配置，最好采用Spring Boot的一套配置，这里千万不要在任何一个配置类上添加@EnableWebMvc这个注解，具体原因会单独一篇文章讲述。此篇文章所有的内容都是在没有标注@EnableWebMvc这个注解的前提下。添加依赖Spring Boot对web模块有一个启动器，只需要在pom.xml中引入即可，如下：&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;这个依赖看似只是引入了一个依赖，其实内部引入了Spring,Spring MVC的相关依赖，Spring Boot的启动器就是这么神奇，后面的文章会介绍启动器的原理和如何自定义启动器。第一个接口开发假设这么一个需求，需要根据用户的ID获取用户信息，我们应该如何写接口呢？其实和Spring MVC开发步骤一样，写一个controller，各种注解骚操作搞起，如下：@RestController@RequestMapping(“/user”)public class UserController { @GetMapping(“/{id}”) public Object getById(@PathVariable(“id”) String id){ return User.builder() .id(id) .name(“不才陈某”) .age(18) .birthday(new Date()) .build(); }}这样一个接口就已经完成了，启动项目访问http://localhost:8080/user/1即可得到如下的结果：{“id”: 1,“age”: 18,“birthday”: 1601454650860,“name”: “不才陈某”}如何自定义tomcat的端口？Spring Boot其实默认内嵌了Tomcat，当然默认的端口号也是8080，如果需要修改的话，只需要在配置文件中添加如下一行配置即可:server.port=9090如何自定义项目路径？在配置文件中添加如下配置即可：server.servlet.context-path=/springboot01以上的端口和项目路径改了之后，只需要访问http://localhost:9090/springboot01/user/1即可。JSON格式化在前后端分离的项目中大部分的接口基本都是返回JSON字符串，因此对返回的JSON也是需要定制一下，比如日期的格式，NULL值是否返回等等内容。Spring Boot默认是使用Jackson对返回结果进行处理，在引入WEB启动器的时候会引入相关的依赖，如下图：同样是引入了一个启动器，则意味着我们既可以在配置文件中修改配置，也可以在配置类中重写其中的配置。JackSon的自动配置类是JacksonAutoConfiguration日期格式的设置上面的例子中日期的返回结果其实是一个时间戳，那么我们需要返回格式为yyyy-MM-dd HH:mm:ss。可以在配置文件application.properties中设置指定的格式，这属于全局配置，如下：spring.jackson.date-format= yyyy-MM-dd HH:mm:ssspring.jackson.time-zone= GMT+8也可以在实体属性中标注@JsonFormat这个注解，属于局部配置，会覆盖全局配置，如下：@JsonFormat(pattern = “yyyy-MM-dd HH:mm”,timezone = “GMT+8”) private Date birthday;上述日期格式配置完成之后返回的就是指定格式的日期，如下：{“id”: “1”,“age”: 18,“birthday”: “2020-09-30 17:21”,“name”: “不才陈某”}其他属性的配置Jackson还有很多的属性可以配置，这里就不再一一介绍了，所有的配置前缀都是spring.jackson。如何在配置类配置？前面说过在引入WEB模块的时候还引入了JackSon的启动器，这是个好东西，这也是Spring Boot的好处之一，自动配置类中所需的一些配置既可以在全局配置文件application.properties中配置也可以在配置类中重新注入某个Bean而达到修改默认配置的效果。在JackSon自动配置类JacksonAutoConfiguration中有如下一段代码： @Bean @Primary @ConditionalOnMissingBean ObjectMapper jacksonObjectMapper(Jackson2ObjectMapperBuilder builder) { return builder.createXmlMapper(false).build(); }这一段代码可能初学者比较懵逼了，什么意思呢？别着急，@Bean这个注解无非就是注入一个Bean到IOC容器中，@Primary这个注解自不用说了，剩下的就是@ConditionalOnMissingBean这个注解了，什么意思呢？其实仔细研究过Spring Boot的源码的朋友都知道，类似这种@Conditionalxxx的注解还有很多，这里就不再深入讲了，后期的文章会介绍。@ConditionalOnMissingBean这个注解的意思很简单，就是当IOC容器中没有指定Bean的时候才会注入，言下之意就是当容器中不存在ObjectMapper这个Bean会使用这里生成的，类似于一种生效的条件。言外之意就是只需要自定义一个ObjectMapper然后注入到IOC容器中，那么这个自动配置类JacksonAutoConfiguration中注入的将会失效，也就达到了覆盖的作用了。因此只需要定义一个配置类，注入ObjectMapper即可，如下：/* 自定义jackson序列化与反序列规则，增加相关格式（全局配置） */@Configurationpublic class JacksonConfig { @Bean @Primary public ObjectMapper jacksonObjectMapper(Jackson2ObjectMapperBuilder builder) { builder.locale(Locale.CHINA); builder.timeZone(TimeZone.getTimeZone(ZoneId.systemDefault())); builder.simpleDateFormat(DatePattern.NORM_DATETIME_PATTERN); builder.modules(new CustomTimeModule()); ObjectMapper objectMapper = builder.createXmlMapper(false).build(); objectMapper.setSerializationInclusion(JsonInclude.Include.NON_EMPTY); //遇到未知属性的时候抛出异常，//为true 会抛出异常 objectMapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false); // 允许出现特殊字符和转义符 objectMapper.configure(JsonParser.Feature.ALLOW_UNQUOTED_CONTROL_CHARS, true); // 允许出现单引号 objectMapper.configure(JsonParser.Feature.ALLOW_SINGLE_QUOTES, true); objectMapper.registerModule(new CustomTimeModule()); return objectMapper; }}上面只是个例子，关于ObjectMapper中的一些内容感兴趣的可以自己查查相关资料。总结这篇文章算是WEB开发的入门，介绍了如何定义接口，返回JSON如何定制等内容，如果觉得有所收获点点关注在看分享一波！！！作者的上个Mybatis专栏已经结束了，作者特意将全部文章整理成册，关注公众号【码猿技术专栏】回复关键词Mybatis进阶即可领取此册。本文使用 mdnice 排版]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[一文带你搞懂日志框架如何切换？]]></title>
      <url>%2F2020%2F10%2F14%2FSpring%20Boot%E7%AC%AC%E5%9B%9B%E5%BC%B9%EF%BC%8C%E4%B8%80%E6%96%87%E5%B8%A6%E4%BD%A0%E6%90%9E%E6%87%82%E6%97%A5%E5%BF%97%E6%A1%86%E6%9E%B6%E5%A6%82%E4%BD%95%E5%88%87%E6%8D%A2%EF%BC%9F%2F</url>
      <content type="text"><![CDATA[持续原创输出，点击上方蓝字关注我吧 目录前言Spring Boot 版本什么是日志门面？如何做到无感知切换？如何切换？引入依赖指定配置文件日志如何配置？总结前言首先要感谢一下读者朋友们的支持，你们每一个的赞都是对陈某最大的肯定，陈某也会一如既往的加油，奥利给！！！言归正传，上一篇文章写了Spring Boot的默认日志框架Logback的基本配置，有兴趣的可以看看：Spring Boot第三弹，一文带你搞懂日志如何配置？。今天就来介绍一下Spring Boot如何无感的切换日志框架？Spring Boot 版本本文基于的Spring Boot的版本是2.3.4.RELEASE。什么是日志门面？前面介绍的日志框架都是基于日志门面SLF4j即简单日志门面（Simple Logging Facade for Java），SLF4j并不是一个真正的日志实现，而是一个抽象层，它允许你在后台使用任意一个日志实现。使用了slf4j后，对于应用程序来说，无论底层的日志框架如何变，应用程序不需要修改任意一行代码，就可以直接上线了。如果对SLF4j比较感兴趣的可以去官网看看：SLF4j官网如何做到无感知切换？SLF4j是日志门面，无论什么日志框架都是基于SLF4j的API实现，因此无论是代码打印日志还是Lombok注解形式打印日志，都要使用的SLF4j的API，而不是日志框架的API，这样才能解耦，做到无感知。因为最终切换的框架只是对于SLF4j的实现，并不是切换SLF4j。其实这一条在阿里开发手册中也是明确指出了，如下：如何切换？Spring Boot默认是Logback日志框架，如果需要切换到其他的日志框架应该如何做？首先我们先看官网的一张图，一切都在图中，如下：SLF4j只是一个门面，共有两大特性。一是静态绑定、二是桥接。什么是静态绑定？：我们以log4j为例。首先我们的application中会使用slf4j的api进行日志记录。我们引入适配层的jar包slf4j-log412.jar及底层日志框架实现log4j.jar。简单的说适配层做的事情就是把slf4j的api转化成log4j的api。通过这样的方式来屏蔽底层框架实现细节。什么是桥接？：比如你的application中使用了slf4j，并绑定了logback。但是项目中引入了一个A.jar，A.jar使用的日志框架是log4j。那么有没有方法让slf4j来接管这个A.jar包中使用log4j输出的日志呢？这就用到了桥接包。你只需要引入log4j-over-slf4j.jar并删除log4j.jar就可以实现slf4j对A.jar中log4j的接管.听起来有些不可思议。你可能会想如果删除log4j.jar那A.jar不会报编译错误嘛？答案是不会。因为log4j-over-slf4j.jar实现了log4j几乎所有public的API。但关键方法都被改写了。不再是简单的输出日志，而是将日志输出指令委托给slf4j。下面就以log4j2为例，切换Spring Boot的日志框架为Log4j2。引入依赖Spring Boot 默认是Logback日志框架，如果想要切换log4j2肯定是要将Logback的依赖移除，只需要排除web模块中的日志启动器即可，如下：&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;!– 去掉springboot默认日志框架logback –&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;排除了默认的logback依赖，肯定是需要引入log4j2的依赖，其实log4j2为了与Spring Boot适配也做了个启动器，不需要在引入其他的jar包了，只需要添加如下依赖即可：&lt;!– 引入log4j2依赖 –&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt;&lt;/dependency&gt;指定配置文件Spring Boot官方文档已经给出了默认两个log4j2的配置的名称，分别为：log4j2-spring.xml, log4j2.xml，但是建议使用log4j2-spring.xml，因为Spring Boot会做一些扩展，行吧，就整这个放在src/resources文件夹下即可。另外上篇文章也说过，如果不使用默认的配置名称，则需要在application.properties指定配置文件，如下：logging.config=classpath:logging-config.xml日志如何配置？其实log4j2的一些配置和logback很相似，这里就不再一一介绍，有兴趣的可以去官网查查，直接贴出一些即用的配置，如下：&lt;?xml version=”1.0” encoding=”UTF-8”?&gt;&lt;!–Configuration后面的status，这个用于设置log4j2自身内部的信息输出，可以不设置，当设置成trace时，你会看到log4j2内部各种详细输出–&gt;&lt;!–monitorInterval：Log4j能够自动检测修改配置 文件和重新配置本身，设置间隔秒数–&gt;&lt;configuration monitorInterval=“5”&gt; &lt;!–日志级别以及优先级排序: OFF &gt; FATAL &gt; ERROR &gt; WARN &gt; INFO &gt; DEBUG &gt; TRACE &gt; ALL –&gt; &lt;!–变量配置–&gt; &lt;Properties&gt; &lt;!– 格式化输出：%date表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度 %msg：日志消息，%n是换行符–&gt; &lt;!– %logger{36} 表示 Logger 名字最长36个字符 –&gt; &lt;property name=“LOG_PATTERN” value=“%date{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n” /&gt; &lt;!– 定义日志存储的路径 –&gt; &lt;property name=“FILE_PATH” value=“更换为你的日志路径” /&gt; &lt;property name=“FILE_NAME” value=“更换为你的项目名” /&gt; &lt;/Properties&gt; &lt;appenders&gt; &lt;console name=“Console” target=“SYSTEM_OUT”&gt; &lt;!–输出日志的格式–&gt; &lt;PatternLayout pattern=“${LOG_PATTERN}”/&gt; &lt;!–控制台只输出level及其以上级别的信息（onMatch），其他的直接拒绝（onMismatch）–&gt; &lt;ThresholdFilter level=“info” onMatch=“ACCEPT” onMismatch=“DENY”/&gt; &lt;/console&gt; &lt;!–文件会打印出所有信息，这个log每次运行程序会自动清空，由append属性决定，适合临时测试用–&gt; &lt;File name=“Filelog” fileName=“${FILE_PATH}/test.log” append=“false”&gt; &lt;PatternLayout pattern=“${LOG_PATTERN}”/&gt; &lt;/File&gt; &lt;!– 这个会打印出所有的info及以下级别的信息，每次大小超过size，则这size大小的日志会自动存入按年份-月份建立的文件夹下面并进行压缩，作为存档–&gt; &lt;RollingFile name=“RollingFileInfo” fileName=“${FILE_PATH}/info.log” filePattern=“${FILE_PATH}/${FILENAME}-INFO-%d{yyyy-MM-dd}%i.log.gz”&gt; &lt;!–控制台只输出level及以上级别的信息（onMatch），其他的直接拒绝（onMismatch）–&gt; &lt;ThresholdFilter level=“info” onMatch=“ACCEPT” onMismatch=“DENY”/&gt; &lt;PatternLayout pattern=“${LOG_PATTERN}”/&gt; &lt;Policies&gt; &lt;!–interval属性用来指定多久滚动一次，默认是1 hour–&gt; &lt;TimeBasedTriggeringPolicy interval=“1”/&gt; &lt;SizeBasedTriggeringPolicy size=“10MB”/&gt; &lt;/Policies&gt; &lt;!– DefaultRolloverStrategy属性如不设置，则默认为最多同一文件夹下7个文件开始覆盖–&gt; &lt;DefaultRolloverStrategy max=“15”/&gt; &lt;/RollingFile&gt; &lt;!– 这个会打印出所有的warn及以下级别的信息，每次大小超过size，则这size大小的日志会自动存入按年份-月份建立的文件夹下面并进行压缩，作为存档–&gt; &lt;RollingFile name=“RollingFileWarn” fileName=“${FILE_PATH}/warn.log” filePattern=“${FILE_PATH}/${FILENAME}-WARN-%d{yyyy-MM-dd}%i.log.gz”&gt; &lt;!–控制台只输出level及以上级别的信息（onMatch），其他的直接拒绝（onMismatch）–&gt; &lt;ThresholdFilter level=“warn” onMatch=“ACCEPT” onMismatch=“DENY”/&gt; &lt;PatternLayout pattern=“${LOG_PATTERN}”/&gt; &lt;Policies&gt; &lt;!–interval属性用来指定多久滚动一次，默认是1 hour–&gt; &lt;TimeBasedTriggeringPolicy interval=“1”/&gt; &lt;SizeBasedTriggeringPolicy size=“10MB”/&gt; &lt;/Policies&gt; &lt;!– DefaultRolloverStrategy属性如不设置，则默认为最多同一文件夹下7个文件开始覆盖–&gt; &lt;DefaultRolloverStrategy max=“15”/&gt; &lt;/RollingFile&gt; &lt;!– 这个会打印出所有的error及以下级别的信息，每次大小超过size，则这size大小的日志会自动存入按年份-月份建立的文件夹下面并进行压缩，作为存档–&gt; &lt;RollingFile name=“RollingFileError” fileName=“${FILE_PATH}/error.log” filePattern=“${FILE_PATH}/${FILENAME}-ERROR-%d{yyyy-MM-dd}%i.log.gz”&gt; &lt;!–控制台只输出level及以上级别的信息（onMatch），其他的直接拒绝（onMismatch）–&gt; &lt;ThresholdFilter level=“error” onMatch=“ACCEPT” onMismatch=“DENY”/&gt; &lt;PatternLayout pattern=“${LOG_PATTERN}”/&gt; &lt;Policies&gt; &lt;!–interval属性用来指定多久滚动一次，默认是1 hour–&gt; &lt;TimeBasedTriggeringPolicy interval=“1”/&gt; &lt;SizeBasedTriggeringPolicy size=“10MB”/&gt; &lt;/Policies&gt; &lt;!– DefaultRolloverStrategy属性如不设置，则默认为最多同一文件夹下7个文件开始覆盖–&gt; &lt;DefaultRolloverStrategy max=“15”/&gt; &lt;/RollingFile&gt; &lt;/appenders&gt; &lt;!–Logger节点用来单独指定日志的形式，比如要为指定包下的class指定不同的日志级别等。–&gt; &lt;!–然后定义loggers，只有定义了logger并引入的appender，appender才会生效–&gt; &lt;loggers&gt; &lt;!–过滤掉spring和mybatis的一些无用的DEBUG信息–&gt; &lt;logger name=“org.mybatis” level=“info” additivity=“false”&gt; &lt;AppenderRef ref=“Console”/&gt; &lt;/logger&gt; &lt;!–监控系统信息–&gt; &lt;!–若是additivity设为false，则 子Logger 只会在自己的appender里输出，而不会在 父Logger 的appender里输出。–&gt; &lt;Logger name=“org.springframework” level=“info” additivity=“false”&gt; &lt;AppenderRef ref=“Console”/&gt; &lt;/Logger&gt; &lt;root level=“info”&gt; &lt;appender-ref ref=“Console”/&gt; &lt;appender-ref ref=“Filelog”/&gt; &lt;appender-ref ref=“RollingFileInfo”/&gt; &lt;appender-ref ref=“RollingFileWarn”/&gt; &lt;appender-ref ref=“RollingFileError”/&gt; &lt;/root&gt; &lt;/loggers&gt;&lt;/configuration&gt;上面的配置中如果需要使用的话，需要改掉全局变量中的日志路径和项目名称，如下部分：&lt;property name=“FILE_PATH” value=“更换为你的日志路径” /&gt;&lt;property name=“FILE_NAME” value=“更换为你的项目名” /&gt;总结本篇文章介绍了Spring Boot如何切换日志框架以及SLF4j一些内容，如果有所收点点在看关注分享一波，谢谢！！！作者的上个Mybatis专栏已经结束了，作者特意将全部文章整理成册，关注公众号【码猿技术专栏】回复关键词Mybatis进阶即可领取此册。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[一文带你搞懂日志如何配置？]]></title>
      <url>%2F2020%2F10%2F14%2FSpring%20Boot%E7%AC%AC%E4%B8%89%E5%BC%B9%EF%BC%8C%E4%B8%80%E6%96%87%E5%B8%A6%E4%BD%A0%E6%90%9E%E6%87%82%E6%97%A5%E5%BF%97%E5%A6%82%E4%BD%95%E9%85%8D%E7%BD%AE%EF%BC%9F%2F</url>
      <content type="text"><![CDATA[持续原创输出，点击上方蓝字关注我吧 目录前言Spring Boot 版本日志级别日志框架有哪些？Spring Boot 日志框架代码中如何使用日志？如何定制日志级别？日志如何输出到文件中？如何定制日志格式？如何自定义日志配置？总结前言日志通常不会在需求阶段作为一个功能单独提出来，也不会在产品方案中看到它的细节。但是，这丝毫不影响它在任何一个系统中的重要的地位。今天就来介绍一下Spring Boot中的日志如何配置。Spring Boot 版本本文基于的Spring Boot的版本是2.3.4.RELEASE。日志级别几种常见的日志级别由低到高分为：TRACE &lt; DEBUG &lt; INFO &lt; WARN &lt; ERROR &lt; FATAL。如何理解这个日志级别呢？很简单，如果项目中的日志级别设置为INFO，那么比它更低级别的日志信息就看不到了，即是TRACE、DEBUG日志将会不显示。日志框架有哪些？常见的日志框架有log4j、logback、log4j2。log4j这个日志框架显示是耳熟能详了，在Spring开发中是经常使用，但是据说log4j官方已经不再更新了，而且在性能上比logback、log4j2差了很多。logback是由log4j创始人设计的另外一个开源日志框架，logback相比之于log4j性能提升了10以上，初始化内存加载也更小了。作为的Spring Boot默认的日志框架肯定是有着不小的优势。log4j2晚于logback推出，官网介绍性能比logback高，但谁知道是不是王婆卖瓜自卖自夸，坊间流传，log4j2在很多思想理念上都是照抄logback，因此即便log4j2是Apache官方项目，Spring等许多框架项目没有将它纳入主流。此处完全是作者道听途说，不必当真，题外话而已。日志框架很多，究竟如何选择能够适应现在的项目开发，当然不是普通程序员考虑的，但是为了更高的追求，至少应该了解一下，哈哈。Spring Boot 日志框架Spring Boot默认的日志框架是logback，既然Spring Boot能够将其纳入的默认的日志系统，肯定是有一定的考量的，因此实际开发过程中还是不要更换。原则上需要使用logback,需要添加以下依赖，但是既然是默认的日志框架，当然不用重新引入依赖了。&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt;Spring Boot中默认的日志级别是INFO，启动项目日志打印如下：从上图可以看出，输出的日志的默认元素如下：时间日期：精确到毫秒日志级别：ERROR, WARN, INFO, DEBUG , TRACE进程ID分隔符：— 标识实际日志的开始线程名：方括号括起来（可能会截断控制台输出）Logger名：通常使用源代码的类名日志内容代码中如何使用日志？在业务中肯定需要追溯日志，那么如何在自己的业务中输出日志呢？其实常用的有两种方式，下面一一介绍。第一种其实也是很早之前常用的一种方式，只需要在代码添加如下：private final Logger logger= LoggerFactory.getLogger(DemoApplicationTests.class);这种方式显然比较鸡肋，如果每个类中都添加一下岂不是很low。别着急，lombok为我们解决了这个难题。要想使用lombok，需要添加如下依赖： &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt;使用也是很简单，只需要在类上标注一个注解@Slf4j即可，如下：@Slf4jclass DemoApplicationTests { @Test public void test(){ log.debug(“输出DEBUG日志…….”); }}如何定制日志级别？Spring Boot中默认的日志级别是INFO，但是可以自己定制日志级别，如下：logging.level.root=DEBUG上面是将所有的日志的级别都改成了DEBUG，Spring Boot还支持package级别的日志级别调整，格式为：logging.level.xxx=xxx，如下：logging.level.com.example.demo=INFO那么完整的配置如下：logging.level.root=DEBUGlogging.level.com.example.demo=INFO日志如何输出到文件中？Spring Boot中日志默认是输出到控制台的，但是在生产环境中显示不可行的，因此需要配置日志输出到日志文件中。其中有两个重要配置如下：logging.file.path：指定日志文件的路径logging.file.name：日志的文件名，默认为spring.log注意：官方文档说这两个属性不能同时配置，否则不生效，因此只需要配置一个即可。指定输出的文件为当前项目路径的logs文件下，默认生成的日志文件为spring.log，如下：logging.file.path=./logs日志文件中还有一些其他的属性，比如日志文件的最大size，保留几天的日志等等，下面会介绍到。如何定制日志格式？默认的日志格式在第一张图已经看到了，有时我们需要定制自己需要的日志输出格式，这样在排查日志的时候能够一目了然。定制日志格式有两个配置，分别是控制台的输出格式和文件中的日志输出格式，如下：logging.pattern.console：控制台的输出格式logging.pattern.file：日志文件的输出格式例如配置如下：logging.pattern.console=%d{yyyy/MM/dd-HH:mm:ss} [%thread] %-5level %logger- %msg%nlogging.pattern.file=%d{yyyy/MM/dd-HH:mm} [%thread] %-5level %logger- %msg%n上面的配置编码的含义如下：%d{HH:mm:ss.SSS}——日志输出时间%thread——输出日志的进程名字，这在Web应用以及异步任务处理中很有用%-5level——日志级别，并且使用5个字符靠左对齐%logger- ——日志输出者的名字%msg——日志消息%n——平台的换行符如何自定义日志配置？Spring Boot官方文档指出，根据不同的日志系统，可以按照如下的日志配置文件名就能够被正确加载，如下：Logback：logback-spring.xml, logback-spring.groovy, logback.xml, logback.groovyLog4j：log4j-spring.properties, log4j-spring.xml, log4j.properties, log4j.xmlLog4j2：log4j2-spring.xml, log4j2.xmlJDK (Java Util Logging)：logging.propertiesSpring Boot官方推荐优先使用带有-spring的文件名作为你的日志配置。因此只需要在src/resources文件夹下创建logback-spring.xml即可，配置文件内容如下：&lt;?xml version=”1.0” encoding=”UTF-8”?&gt;&lt;configuration scan=“true” scanPeriod=“60 seconds” debug=“false”&gt; &lt;!– 定义日志存放目录 –&gt; &lt;property name=“logPath” value=“logs”/&gt; &lt;!– 日志输出的格式–&gt; &lt;property name=“PATTERN” value=“%d{yyyy-MM-dd HH:mm:ss.SSS} [%t-%L] %-5level %logger{36} %L %M - %msg%xEx%n”/&gt; &lt;contextName&gt;logback&lt;/contextName&gt; &lt;!–输出到控制台 ConsoleAppender–&gt; &lt;appender name=“consoleLog” class=“ch.qos.logback.core.ConsoleAppender”&gt; &lt;!–展示格式 layout–&gt; &lt;layout class=“ch.qos.logback.classic.PatternLayout”&gt; &lt;pattern&gt;${PATTERN}&lt;/pattern&gt; &lt;/layout&gt; &lt;!–过滤器，只有过滤到指定级别的日志信息才会输出，如果level为ERROR，那么控制台只会输出ERROR日志–&gt;&lt;!– &lt;filter class=”ch.qos.logback.classic.filter.ThresholdFilter”&gt;–&gt;&lt;!– &lt;level&gt;ERROR&lt;/level&gt;–&gt;&lt;!– &lt;/filter&gt;–&gt; &lt;/appender&gt; &lt;!–正常的日志文件，输出到文件中–&gt; &lt;appender name=“fileDEBUGLog” class=“ch.qos.logback.core.rolling.RollingFileAppender”&gt; &lt;!–如果只是想要 Info 级别的日志，只是过滤 info 还是会输出 Error 日志，因为 Error 的级别高， 所以我们使用下面的策略，可以避免输出 Error 的日志–&gt; &lt;filter class=“ch.qos.logback.classic.filter.LevelFilter”&gt; &lt;!–过滤 Error–&gt; &lt;level&gt;Error&lt;/level&gt; &lt;!–匹配到就禁止–&gt; &lt;onMatch&gt;DENY&lt;/onMatch&gt; &lt;!–没有匹配到就允许–&gt; &lt;onMismatch&gt;ACCEPT&lt;/onMismatch&gt; &lt;/filter&gt; &lt;!–日志名称，如果没有File 属性，那么只会使用FileNamePattern的文件路径规则 如果同时有&lt;File&gt;和&lt;FileNamePattern&gt;，那么当天日志是&lt;File&gt;，明天会自动把今天 的日志改名为今天的日期。即，&lt;File&gt; 的日志都是当天的。 –&gt; &lt;File&gt;${logPath}/log_demo.log&lt;/File&gt; &lt;!–滚动策略，按照时间滚动 TimeBasedRollingPolicy–&gt; &lt;rollingPolicy class=“ch.qos.logback.core.rolling.TimeBasedRollingPolicy”&gt; &lt;!–文件路径,定义了日志的切分方式——把每一天的日志归档到一个文件中,以防止日志填满整个磁盘空间–&gt; &lt;FileNamePattern&gt;${logPath}/logdemo%d{yyyy-MM-dd}.log&lt;/FileNamePattern&gt; &lt;!–只保留最近90天的日志–&gt; &lt;maxHistory&gt;90&lt;/maxHistory&gt; &lt;!–用来指定日志文件的上限大小，那么到了这个值，就会删除旧的日志–&gt; &lt;!–&lt;totalSizeCap&gt;1GB&lt;/totalSizeCap&gt;–&gt; &lt;/rollingPolicy&gt; &lt;!–日志输出编码格式化–&gt; &lt;encoder&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;pattern&gt;${PATTERN}&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!–输出ERROR日志到指定的文件中–&gt; &lt;appender name=“fileErrorLog” class=“ch.qos.logback.core.rolling.RollingFileAppender”&gt; &lt;!–如果只是想要 Error 级别的日志，那么需要过滤一下，默认是 info 级别的，ThresholdFilter–&gt; &lt;filter class=“ch.qos.logback.classic.filter.ThresholdFilter”&gt; &lt;level&gt;Error&lt;/level&gt; &lt;/filter&gt; &lt;!–日志名称，如果没有File 属性，那么只会使用FileNamePattern的文件路径规则 如果同时有&lt;File&gt;和&lt;FileNamePattern&gt;，那么当天日志是&lt;File&gt;，明天会自动把今天 的日志改名为今天的日期。即，&lt;File&gt; 的日志都是当天的。 –&gt; &lt;File&gt;${logPath}/error.log&lt;/File&gt; &lt;!–滚动策略，按照时间滚动 TimeBasedRollingPolicy–&gt; &lt;rollingPolicy class=“ch.qos.logback.core.rolling.TimeBasedRollingPolicy”&gt; &lt;!–文件路径,定义了日志的切分方式——把每一天的日志归档到一个文件中,以防止日志填满整个磁盘空间–&gt; &lt;FileNamePattern&gt;${logPath}/error_%d{yyyy-MM-dd}.log&lt;/FileNamePattern&gt; &lt;!–只保留最近90天的日志–&gt; &lt;maxHistory&gt;90&lt;/maxHistory&gt; &lt;!–用来指定日志文件的上限大小，那么到了这个值，就会删除旧的日志–&gt; &lt;!–&lt;totalSizeCap&gt;1GB&lt;/totalSizeCap&gt;–&gt; &lt;/rollingPolicy&gt; &lt;!–日志输出编码格式化–&gt; &lt;encoder&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;pattern&gt;${PATTERN}&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!–指定最基础的日志输出级别–&gt; &lt;root level=“DEBUG”&gt; &lt;!–appender将会添加到这个loger–&gt; &lt;appender-ref ref=“consoleLog”/&gt; &lt;appender-ref ref=“fileDEBUGLog”/&gt; &lt;appender-ref ref=“fileErrorLog”/&gt; &lt;/root&gt; &lt;!– 定义指定package的日志级别–&gt; &lt;logger name=“org.springframework” level=“DEBUG”&gt;&lt;/logger&gt; &lt;logger name=“org.mybatis” level=“DEBUG”&gt;&lt;/logger&gt; &lt;logger name=“java.sql.Connection” level=“DEBUG”&gt;&lt;/logger&gt; &lt;logger name=“java.sql.Statement” level=“DEBUG”&gt;&lt;/logger&gt; &lt;logger name=“java.sql.PreparedStatement” level=“DEBUG”&gt;&lt;/logger&gt; &lt;logger name=“io.lettuce.“ level=“INFO”&gt;&lt;/logger&gt; &lt;logger name=“io.netty.“ level=“ERROR”&gt;&lt;/logger&gt; &lt;logger name=“com.rabbitmq.“ level=“DEBUG”&gt;&lt;/logger&gt; &lt;logger name=“org.springframework.amqp.“ level=“DEBUG”&gt;&lt;/logger&gt; &lt;logger name=“org.springframework.scheduling.*” level=“DEBUG”&gt;&lt;/logger&gt; &lt;!–定义com.xxx..xx..xx包下的日志信息不上传，直接输出到fileDEBUGLog和fileErrorLog这个两个appender中，日志级别为DEBUG–&gt; &lt;logger name=“com.xxx.xxx.xx” additivity=“false” level=“DEBUG”&gt; &lt;appender-ref ref=“fileDEBUGLog”/&gt; &lt;appender-ref ref=“fileErrorLog”/&gt; &lt;/logger&gt;&lt;/configuration&gt;当然，如果就不想用Spring Boot推荐的名字，想自己定制也行，只需要在配置文件中指定配置文件名即可，如下：logging.config=classpath:logging-config.xml懵逼了，一堆配置什么意思？别着急，下面一一介绍。configuration节点这是一个根节点，其中的各个属性如下：scan：当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true。scanPeriod：设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。当scan为true时，此属性生效。默认的时间间隔为1分钟。debug：当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。root节点这是一个必须节点，用来指定基础的日志级别，只有一个level属性，默认值是DEBUG。该节点可以包含零个或者多个元素，子节点是appender-ref，标记这个appender将会添加到这个logger中。contextName节点标识一个上下文名称，默认为default，一般用不到property节点标记一个上下文变量，属性有name和value，定义变量之后可以使用${}来获取。appender节点用来格式化日志输出节点，有两个属性name和class，class用来指定哪种输出策略，常用就是控制台输出策略和文件输出策略。这个节点很重要，通常的日志文件需要定义三个appender，分别是控制台输出，常规日志文件输出，异常日志文件输出。该节点有几个重要的子节点，如下：filter：日志输出拦截器，没有特殊定制一般使用系统自带的即可，但是如果要将日志分开，比如将ERROR级别的日志输出到一个文件中，将除了ERROR级别的日志输出到另外一个文件中，此时就要拦截ERROR级别的日志了。encoder： 和pattern节点组合用于具体输出的日志格式和编码方式。file: 节点用来指明日志文件的输出位置，可以是绝对路径也可以是相对路径rollingPolicy: 日志回滚策略，在这里我们用了TimeBasedRollingPolicy，基于时间的回滚策略,有以下子节点fileNamePattern，必要节点，可以用来设置指定时间的日志归档。maxHistory : 可选节点，控制保留的归档文件的最大数量，超出数量就删除旧文件,，例如设置为30的话，则30天之后，旧的日志就会被删除totalSizeCap: 可选节点，用来指定日志文件的上限大小，例如设置为3GB的话，那么到了这个值，就会删除旧的日志logger节点可选节点，用来具体指明包的日志输出级别，它将会覆盖root的输出级别。该节点有几个重要的属性如下：name：指定的包名level：可选，日志的级别addtivity：可选，默认为true，将此logger的信息向上级传递，将有root节点定义日志打印。如果设置为false，将不会上传，此时需要定义一个appender-ref节点才会输出。总结Spring Boot的日志选型以及如何自定义日志配置就介绍到这里，如果觉得有所收获，不妨点个关注，分享一波，将是对作者最大的鼓励！！！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring Boot 配置文件怎么造？]]></title>
      <url>%2F2020%2F10%2F14%2FSpring%20Boot%20%E7%AC%AC%E4%BA%8C%E5%BC%B9%EF%BC%8C%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E6%80%8E%E4%B9%88%E9%80%A0%EF%BC%9F%2F</url>
      <content type="text"><![CDATA[持续原创输出，点击上方蓝字关注我吧 目录 前言properties格式简介YML格式简介 如何使用总结如何从配置文件取值？ @ConfigurationProperties@Value如何从自定义配置文件中取值？ 前言 自从用了Spring Boot，个人最喜欢的就是Spring Boot的配置文件了，和Spring比起，Spring Boot更加灵活，修改的某些配置也是更加得心应手。Spring Boot 官方提供了两种常用的配置文件格式，分别是properties、YML格式。相比于properties来说，YML更加年轻，层级也是更加分明。今天这篇文章就来介绍一下Spring Boot的配置文件的语法以及如何从配置文件中取值。properties格式简介常见的一种配置文件格式，Spring中也是用这种格式，语法结构很简单，结构为：key=value。具体如下：userinfo.name=myjszluserinfo.age=25userinfo.active=trueuserinfo.created-date=2018/03/31 16:54:30userinfo.map.k1=v1userinfo.map.k2=v2上述配置文件中对应的实体类如下：@Data@ToStringpublic class UserInfo { private String name; private Integer age; private Boolean active; private Map&lt;String,Object&gt; map; private Date createdDate; private List&lt;String&gt; hobbies;}结构很简单，无非就是key=value这种形式，也是在开发中用的比较多的一种格式。YML格式简介以空格的缩进程度来控制层级关系。空格的个数并不重要，只要左边空格对齐则视为同一个层级。注意不能用tab代替空格。且大小写敏感。支持字面值，对象，数组三种数据结构，也支持复合结构。字面值：字符串，布尔类型，数值，日期。字符串默认不加引号，单引号会转义特殊字符。日期格式支持yyyy/MM/dd HH:mm:ss对象：由键值对组成，形如 key:(空格)value 的数据组成。冒号后面的空格是必须要有的，每组键值对占用一行，且缩进的程度要一致，也可以使用行内写法：{k1: v1, ….kn: vn}数组：由形如 -(空格)value 的数据组成。短横线后面的空格是必须要有的，每组数据占用一行，且缩进的程度要一致，也可以使用行内写法：[1,2,…n]复合结构：上面三种数据结构任意组合如何使用在src/resources文件夹下创建一个application.yml文件。支持的类型主要有字符串，带特殊字符的字符串，布尔类型，数值，集合，行内集合，行内对象，集合对象这几种常用的数据格式。具体的示例如下：userinfo: age: 25 name: myjszl active: true created-date: 2018/03/31 16:54:30 map: {k1: v1,k2: v2} hobbies: - one - two - three上述配置文件对应的实体类如下：@Data@ToStringpublic class UserInfo { private String name; private Integer age; private Boolean active; private Map&lt;String,Object&gt; map; private Date createdDate; private List&lt;String&gt; hobbies;}总结YML是一种新式的格式，层级鲜明，个人比较喜欢使用的一种格式，注意如下：字符串可以不加引号，若加双引号则输出特殊字符，若不加或加单引号则转义特殊字符数组类型，短横线后面要有空格；对象类型，冒号后面要有空格YAML是以空格缩进的程度来控制层级关系，但不能用tab键代替空格，大小写敏感如何从配置文件取值？一切的配置都是为了取值，Spring Boot也是提供了几种取值的方式，下面一一介绍。@ConfigurationProperties这个注解用于从配置文件中取值，支持复杂的数据类型，但是不支持SPEL表达式。该注解中有一个属性prefix，用于指定获配置的前缀，毕竟配置文件中的属性很多，也有很多重名的，必须用一个前缀来区分下。该注解可以标注在类上也可以标注在方法上，这也注定了它有两种获取值的方式。1. 标注在实体类上这种方式用于从实体类上取值，并且赋值到对应的属性。使用如下：/ @Component ：注入到IOC容器中 @ConfigurationProperties：从配置文件中读取文件 */@Component@ConfigurationProperties(prefix = “userinfo”)@Data@ToStringpublic class UserInfo { private String name; private Integer age; private Boolean active; private Map&lt;String,Object&gt; map; private Date createdDate; private List&lt;String&gt; hobbies;}标注在配置类中的方法上标注在配置类上的方法上，同样是从配置文件中取值赋值到返回值的属性中。使用如下： / @Bean : 将返回的结果注入到IOC容器中 @ConfigurationProperties ：从配置文件中取值 @return / @ConfigurationProperties(prefix = “userinfo”) @Bean public UserInfo userInfo(){ return new UserInfo(); }总结@ConfigurationProperties注解能够很轻松的从配置文件中取值，优点如下：支持批量的注入属性，只需要指定一个前缀prefix支持复杂的数据类型，比如List、Map对属性名匹配的要求较低，比如user-name，user_name，userName，USER_NAME都可以取值支持JAVA的JSR303数据校验注意：@ConfigurationProperties这个注解仅仅是支持从Spring Boot的默认配置文件中取值，比如application.properties、application.yml。@Value@Value这个注解估计很熟悉了，Spring中从属性取值的注解，支持SPEL表达式，不支持复杂的数据类型，比如List。使用如下： @Value(“${userinfo.name}”) private String UserName;如何从自定义配置文件中取值？Spring Boot在启动的时候会自动加载application.xxx和bootsrap.xxx，但是为了区分，有时候需要自定义一个配置文件，那么如何从自定义的配置文件中取值呢？此时就需要配合@PropertySource这个注解使用了。只需要在配置类上标注@PropertySource并指定你自定义的配置文件即可完成。如下：@SpringBootApplication@PropertySource(value = {“classpath:custom.properties”})public class DemoApplication {value属性是一个数组，可以指定多个配置文件同时引入。@PropertySource默认加载xxx.properties类型的配置文件，不能加载YML格式的配置文件，怎么破？？？如何加载自定义YML格式的配置文件？@PropertySource注解有一个属性factory，默认值是PropertySourceFactory.class，这个就是用来加载properties格式的配置文件，我们可以自定义一个用来加载YML格式的配置文件，如下：import org.springframework.beans.factory.config.YamlPropertiesFactoryBean;import org.springframework.core.env.PropertiesPropertySource;import org.springframework.core.env.PropertySource;import org.springframework.core.io.support.DefaultPropertySourceFactory;import org.springframework.core.io.support.EncodedResource;import java.io.IOException;import java.util.Properties;public class YmlConfigFactory extends DefaultPropertySourceFactory { @Override public PropertySource&lt;?&gt; createPropertySource(String name, EncodedResource resource) throws IOException { String sourceName = name != null ? name : resource.getResource().getFilename(); if (!resource.getResource().exists()) { return new PropertiesPropertySource(sourceName, new Properties()); } else if (sourceName.endsWith(“.yml”) || sourceName.endsWith(“.yaml”)) { Properties propertiesFromYaml = loadYml(resource); return new PropertiesPropertySource(sourceName, propertiesFromYaml); } else { return super.createPropertySource(name, resource); } } private Properties loadYml(EncodedResource resource) throws IOException { YamlPropertiesFactoryBean factory = new YamlPropertiesFactoryBean(); factory.setResources(resource.getResource()); factory.afterPropertiesSet(); return factory.getObject(); }}此时只需要将factory属性指定为YmlConfigFactory即可，如下：@SpringBootApplication@PropertySource(value = {“classpath:custom.yml”},factory = YmlConfigFactory.class)public class DemoApplication {总结@PropertySource指定加载自定义的配置文件，默认只能加载properties格式，但是可以指定factory属性来加载YML格式的配置文件。总结以上内容介绍了Spring Boot中的配置文件的语法以及如何从配置文件中取值，这个内容很重要，作者也是尽可能讲的通俗易懂，希望读者能够有所收获。好了，肝了两个多小时，每一篇文章都是作者精心原创制作，读者朋友们的每一个点赞分享都是对我莫大的支持，谢谢！！！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring Boot 第一弹，问候一下世界！！！]]></title>
      <url>%2F2020%2F10%2F14%2FSpring%20Boot%20%E7%AC%AC%E4%B8%80%E5%BC%B9%EF%BC%8C%E9%97%AE%E5%80%99%E4%B8%80%E4%B8%8B%E4%B8%96%E7%95%8C%EF%BC%81%EF%BC%81%EF%BC%81%2F</url>
      <content type="text"><![CDATA[持续原创输出，点击上方蓝字关注我吧 目录前言什么是Spring Boot？如何搭建一个Spring Boot项目？第一个程序 Hello World依赖解读什么是配置文件？什么是启动类？如何进行单元测试？前言相信从事Java开发的朋友都听说过SSM框架，这还算年轻的，老点的甚至经历过SSH，说起来有点恐怖，哈哈。比如我就是经历过SSH那个时代末流，没办法，很无奈。当然无论是SSM还是SSH都不是今天的重点，今天要说的是Spring Boot，一个令人眼前一亮的框架，从大的说，Spring Boot取代了SSM 中的SS的角色。今天这篇文章就来谈谈Spring Boot，这个我第一次使用直呼爽的框架。什么是Spring Boot？Spring Boot 是由 Pivotal 团队提供的全新框架。Spring Boot 是所有基于 Spring Framework 5.0 开发的项目的起点。Spring Boot 的设计是为了让你尽可能快的跑起来Spring 应用程序并且尽可能减少你的配置文件。Spring Boot 的设计目的简单一句话：简化Spring应用的初始搭建以及开发过程。从最根本上来讲，Spring Boot 就是一些库的集合，它能够被任意项目的构建系统所使用。它使用 “约定大于配置” （项目中存在大量的配置，此外还内置一个习惯性的配置）的理念让你的项目快速运行起来。约定大于配置这个如何理解？其实简单的来说就是Spring Boot在搭建之初就内置了许多实际开发中的常用配置，只有少部分的配置需要开发人员自己去配置。如何搭建一个Spring Boot项目？其实搭建一个SpringBoot项目有很多种方式，最常见的两种方式如下：1. 创建Maven项目，自己引入依赖，创建启动类和配置文件。2. 直接IDEA中的Spring Initializr创建项目。第一种方式不适合入门的朋友玩，今天演示第二种方式搭建一个Spring Boot项目。第一步在IDEA中选择File–&gt;NEW–&gt;Project，选择Spring Initializr，指定JDK版本1.8，然后Next。如下图：第二步指定Maven坐标、包名、JDK版等信息，然后Next，如下图：第三步选择自己所需要的依赖、Spring Boot的版本，Spring Boot与各个框架适配都是以starter方式，这里我们选择WEB开发的所需的starter即可，如下图：第四步指定项目的名称，路径即可完成，点击Finish等待创建成功，如下图：创建成功的项目如下图：其中的DemoApplication是项目的启动类，里面有一个main()方法就是用来启动Spring Boot。application.properties是Spring Boot的配置文件。此时可以启动项目，在DemoApplication运行main方法即可启动，启动成功如下图：由于SpringBoot默认内置了Tomcat，因此启动的默认端口就是8080。第一个程序 Hello World学习任何一种技术总是要问候一下世界，哈哈……….既然是WEB开发，就写个接口吧，前面创建的时候已经引用了WEB的starter，如果没有引用，则可以在pom.xml引入以下依赖：&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;下面写一个HelloWorldController如下：package com.example.demo.controller;@RestControllerpublic class HelloWorldController { @RequestMapping(“/hello”) public String helloWorld(){ return “Hello World”; }}@RestController：标记这是一个controller，是@Controller和@ResponseBody这两个注解的集合。@RequestMapping：指定一个映射以上两个注解都是Spring中的，这里就不再细说了。由于内置的Tomcat默认端口是8080，所以启动项目，访问http://127.0.0.1:8080/hello即可。依赖解读Spring Boot项目中的pom.xml中有这么一个依赖，如下：&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.3.4.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt;&lt;parent&gt;这个标签都知道什么意思，父亲是吧，这么个标签主要的作用就是用于版本控制。这也就是引入的WEB模块starter的时候不用指定版本号&lt;version&gt;标签的原因，因为在spring-boot-starter-parent中已经指定了，类似于一种继承的关系，父亲已经为你提供了，你只需要选择用不用就行。为什么引入spring-boot-starter-web就能使用Spring mvc的功能呢？这确实是个难以理解的问题，为了理解这个问题，我们不妨看一下spring-boot-starter-web这个启动器都依赖了什么？如下：&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.3.4.RELEASE&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-json&lt;/artifactId&gt; &lt;version&gt;2.3.4.RELEASE&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;version&gt;2.3.4.RELEASE&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;5.2.9.RELEASE&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.2.9.RELEASE&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;看到这应该明白了吧，spring-boot-starter-web这个starter中其实内部引入了Spring、springmvc、tomcat的相关依赖，当然能够直接使用Spring MVC相关的功能了。什么是配置文件？前面说过application.properties是Spring Boot的配置文件，那么这个配置文件究竟是配置什么的呢？其实Spring Boot为了能够适配每一个组件，都会提供一个starter，但是这些启动器的一些信息不能在内部写死啊，比如数据库的用户名、密码等，肯定要由开发人员指定啊，于是就统一写在了一个Properties类中，在Spring Boot启动的时候根据前缀名+属性名称从配置文件中读取，比如WebMvcProperties，其中定义了一些Spring Mvc相关的配置，前缀是spring.mvc。如下：@ConfigurationProperties(prefix = “spring.mvc”)public class WebMvcProperties {那么我们需要修改Spring Mvc相关的配置，只需要在application.properties文件中指定spring.mvc.xxxx=xxxx即可。其实配置文件这块还是有许多道道儿的，后面文章会详细介绍。什么是启动类？前面说过启动类是DemoApplication，源码如下：@SpringBootApplicationpublic class DemoApplication { public static void main(String[] args) { SpringApplication.run(DemoApplication.class, args); }}@SpringBootApplication是什么？其实一眼看上去，这个类在平常不过了，唯一显眼的就是@SpringBootApplication这个注解了，当然主要的作用还真是它。这个注解的源码如下：@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = { @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) })public @interface SpringBootApplication {}我滴乖乖儿，注解叠加啊，完全是由@SpringBootConfiguration、@EnableAutoConfiguration、@ComponentScan这三个注解叠加而来。ComponentScan：这个注解并不陌生，Spring中的注解，包扫描的注解，这个注解的作用就是在项目启动的时候扫描启动类的同类级以及下级包中的Bean。@SpringBootConfiguration：这个注解使Spring Boot的注解，源码如下：@Target({ElementType.TYPE})@Retention(RetentionPolicy.RUNTIME)@Documented@Configurationpublic @interface SpringBootConfiguration { @AliasFor( annotation = Configuration.class ) boolean proxyBeanMethods() default true;}从源码可以看出，@SpringBootConfiguration完全就是的@Configuration注解，@Configuration是Spring中的注解，表示该类是一个配置类，因此我们可以在启动类中做一些配置类可以做的事，比如注入一个Bean。@EnableAutoConfiguration：这个注解看到这个名字就知道怎么回事了，直接翻译码，开启自动配置，真如其名，源码如下：@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage@Import(AutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration {又是一个熟悉的注解@Import，什么功能呢？快速导入Bean到IOC容器中，有三种方式，这里用的是其中一种ImportSelector方式。不是本文重点，不再细说。@EnableAutoConfiguration这个注解的作用也就一目了然了，无非就是@Import的一种形式而已，在项目启动的时候向IOC容器中快速注入Bean而已。好了，启动类就先介绍到这，后续讲到源码文章才能更清楚的了解到这个类的强大之处。如何进行单元测试？Spring Boot项目创建之处为我们提供了一个单元测试的类，如下：@SpringBootTestclass DemoApplicationTests { @Test void contextLoads() { }}@SpringBootTest：这个注解指定这个类是单元测试的类。在这个类中能够自动的获取IOC容器中的Bean，比如：@SpringBootTestclass DemoApplicationTests { @Autowired private HelloWorldController helloWorldController;简单的介绍下而已，实际开发中用不到，随着项目越来越大，启动的时间越来越长，谁会傻到启动一个测试方法来检验代码，纯粹浪费时间。总结作为Spring Boot的第一弹，写到这儿就结束了，没什么的深入的内容，只是简单的对Spring Boot做了初步的了解。本文使用的开发工具是IDEA，有需要2020版本的公众号回复关键词IDEA2020，有需要IDEA破解包的回复关键词IDEA破解包]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Navicat Premium 12破解版安装]]></title>
      <url>%2F2020%2F08%2F27%2FNavicat%20Premium%2012%E5%85%8D%E8%B4%B9%E7%89%88%E6%9C%AC%E5%AE%89%E8%A3%85%2F</url>
      <content type="text"><![CDATA[前言 这几年的工作过程中使用了很多的数据库工具，比如Sqlyog，DBeaver,sqlplus等工具，但是个人觉得很好用的还是Navicat。 不如人意的就是目前Navicat都在收费，今天就来分享下如何安装免费的Navicat。 免费版本安装 首先去官网下载Navicat_12的安装包，根据自己电脑的配置下载合适的。 下载成功之后，直接安装，启动即可 启动时选择试用版本。 打开神秘的包包，找到匹配的，如下： 将其中的文件全部复制到Navicat_12的根目录，文件如下： 重新启动Navicat，出现以下界面，表示安装成功，如下： 如何连接Oracle 如果本地未安装过Oracle数据库，新安装的Navicat默认是连接不上oracle的，需要配置一下oci.dll。 选择工具-&gt;选项 指定oci.dll的路径，如下： 重新启动，即可连接。 注意：Navicat_12自带的oci.dll如果版本不合适，可以去官网下载对应的版本。 如何连接Sql server 如果本地未安装过SQL Server数据库，Navicat是不能连接上数据库的，具体解决方案如下： 在Navicat的根目录下找到sqlncli_x64.msi双击安装即可，当然如果版本不合适，可以自己去官网下载。 安装成功后，重启启动，即可连接。 总结 安装免费版的Navicat很简单，只需要一个神秘的包包，哈哈。 老规矩，关注公众号【码猿技术专栏】回复关键词Navicat12即可获取。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Mybatis Log plugin破解，亲测可用！！！]]></title>
      <url>%2F2020%2F08%2F26%2Fplugin%E7%A0%B4%E8%A7%A3%EF%BC%8C%E4%BA%B2%E6%B5%8B%E5%8F%AF%E7%94%A8%2F</url>
      <content type="text"><![CDATA[前言 今天重新装了IDEA2020，顺带重装了一些插件，毕竟这些插件都是习惯一直在用，其中一款就是Mybatis Log plugin，按照往常的思路，在IDEA插件市场搜索安装，艹，眼睛一瞟，竟然收费了，对于我这种支持盗版的人来说太难了，于是自己开始捣鼓各种尝试破解，下文分享自己的破解方式。 什么是Mybatis Log plugin 举个栗子，通常在找bug的时候都会查看执行了什么SQL，想把这条SQL拼接出来执行调试，可能有些小白还在傻傻的把各个参数复制出来，补到?占位符中，哈哈。 简单的说就是能根据log4j的打印的sql日志一键生成执行的sql语句。 类似如下一个日志信息： 如果使用Log plugin这个插件，将会很容易的把参数添加到sql语句中得到一条完整的sql，效果如下： 一旦开启了Mybatis Log plugin这个插件，在程序运行过程中只要是有SQL语句都会自动生成在Mybatis Log这个界面，当然也可以自己关掉。 如何安装 Setting-&gt;plugin-&gt;Marketplace搜索框输入Mybatis Log plugin，如下： 很遗憾的是， IDEA2020中已经开始收费了，艹，对于一向支持盗版的我来说，很不爽~ 如何破解 下载jar包plugin.intellij.assistant.mybaitslog-2020.1-1.0.3.jar，文末附有下载方式。 setting-&gt;plguin-&gt;设置-&gt; install plugin from Disk... 如何使用 日志中从Preparing到Parameters这两行的参数选中，右键选择restore sql from Selection 此时将会在Mybatis Log界面出现完整的SQL语句。 总结 对于复杂的SQL语句来说，Mybatis Log plugin这款插件简直是太爱了，能够自动拼接参数生成执行的SQL语句。 老规矩，关注公众号【码猿技术专栏】，公众号回复mybatis log获取破解包。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[select语句做了什么？]]></title>
      <url>%2F2020%2F05%2F08%2Fselect%E8%AF%AD%E5%8F%A5%E5%81%9A%E4%BA%86%E4%BB%80%E4%B9%88%EF%BC%9F%2F</url>
      <content type="text"><![CDATA[导读 Mysql在中小型企业中是个香饽饽，目前主流的数据库之一，几乎没有一个后端开发者不会使用的，但是作为一个老司机，仅仅会用真的不够。今天陈某透过一个简单的查询语句来讲述在Mysql内部的执行过程。select from table where id=10;撸它首先通过一张图片来了解一下Mysql的基础架构，如下：从上图可以看出，Mysql大致分为Server层和存储引擎层两部分。Server层包括连接器、查询缓存、分析器、优化器等，其中包含了Mysql的大多数核心功能以及所有的内置函数（如日期，时间函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。存储引擎层负责数据的存储和提取。它的架构是可插拔式的，支持InnoDB、MyISAM等多个存储引擎。Mysql中主流的存储引擎是InnoDB，由于它对事务的支持让它从Mysql5.5.5版本开始成为了默认的存储引擎。大致了解了整体架构，现在说说每一个基础的模块都承担着怎样的责任。1. 连接器顾名思义，是客户端和Mysql之间连接的媒介，负责登录、获取权限、维持连接和管理连接。连接命令一般如下：mysql [-h] ip [- P] port -u [user] -p在完成经典的TCP握手后，连接器会开始认证身份，要求输入密码。密码认证通过，连接器会查询出拥有的权限，即使管理员修改了权限，也不会影响你这次的连接，只有重新连接才会生效。密码认证失败，会收到提示信息Access denied for user。连接完成后，没有后续动作的连接将会变成空闲连接，你可以输入show processlist命令看到它。如下图，其中的Command这一列显示为sleep的这一行表示在系统里面有一个空闲连接。客户端如果太长时间没有执行动作，连接器将会自动断开，这个时间由参数wait_timeout控制，默认值是8小时。如果在连接被断开之后，客户端再次发送请求的话，就会收到一个错误提醒： Lost connection to MySQL server during query。这时候如果你要继续，就需要重连，然后再执行请求了。2. 查询缓存【废材，8.0 版本完全删除】连接建立完成后，你就可以select语句了，执行之前会查询缓存。查询缓存在Mysql中的是默认关闭的，因为缓存命中率非常低，只要有对表执行一个更新操作，这个表的所有查询缓存都将被清空。怎么样？一句废材足以形容了！！！废材的东西不必多讲，主流的Redis的缓存你不用，别再搞这废材了。3. 分析器如果没有命中查询缓存，就要执行查询了，但是在执行查询之前，需要对SQL语句做解析，判断你这条语句有没有语法错误。分析器会做 ‘词法分析’ ，你输入的无非可就是多个字符串和空格组成的SQL语句，MYSQL需要识别出里面的字符串是什么，代表什么，有没有关键词等。MYSQL会从你输入的select 这个关键字识别出来是一个查询语句，table是表名，id是列名。做完这些会做 ‘语法分析’ ，根据MYSQL定义的规则来判断你的SQL语句有没有语法错误，如果你的语法不对，就会收到类似如下的提醒：ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near ‘elect from t where ID=1’ at line 1一般语法错误会提示第一个出现错误的位置，所以你要关注的是紧接“use near”的内容。4. 优化器经过分析器词法和语法的分析，此时就能知道这条SQL语句是干什么的。但是在开始执行之前，MYSQL底层还要使用优化器对这条SQL语句进行优化处理。MYSQL内部会对这条SQL进行评估，比如涉及到多个索引会比较使用哪个索引代价更小、多表join的时候会考虑决定各个表的连接顺序。优化器的作用一句话总结：根据MYSQL内部的算法决定如何执行这条SQL语句来达到MYSQL认为代价最小目的。优化器阶段完成后，这个语句的执行方案就确定了，接下来就交给执行器执行了。5. 执行器MYSQL通过分析器知道了要做什么，通过优化器知道了如何做，于是就进入了执行器阶段。执行器开始执行之前，需要检查一下用户对表table有没有执行的权限，没有返回权限不足的错误，有的话就执行。执行也是分类的，如果Id不是索引则全表扫描，一行一行的查找，如果是索引则在索引组织表中查询，索引的查询很复杂，其中涉及到B+树等算法，这里不再详细介绍。总结一条SQL语句在MYSQL内部执行的过程涉及到的内部模块有：连接器、查询缓存、分析器、优化器、执行器、存储引擎。至此，MYSQL的基础架构已经讲完了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[IDEA2020永久破解，亲测可用！！！]]></title>
      <url>%2F2020%2F05%2F08%2FIDEA2020%E6%B0%B8%E4%B9%85%E7%A0%B4%E8%A7%A3%EF%BC%8C%E4%BA%B2%E6%B5%8B%E5%8F%AF%E7%94%A8%EF%BC%81%EF%BC%81%EF%BC%81%2F</url>
      <content type="text"><![CDATA[前言 随着 IDEA 的 2020 版本的发布，新增和优化了很多的功能，今天陈某不说新增的功能，来讲一讲如何永久破解。 不说别的，先上破解后的效果图： 如何破解？ 破解过程很简单，基本是傻瓜式的，过程如下。 1. 下载安装 官网下载IDEA 2020.1，下载地址自己动手百度吧。 安装成功后，启动 IDEA，选择试用启动 IDEA。 下载破解包 公众号回复关键词IDEA破解包下载，其实就是一个 jar 包，如下： 开始破解 直接将jetbrains-agent.jar文件用鼠标拖进idea 界面，然后一路重启或者确定，中间出现什么拖放失败不用理会，直接点确定就好是正常现象。如下图： 重启成功后，会跳出如下界面，直接点击为IDEA安装，如下图： 继续点击是安装，如下图： 验证是否破解成功 根据上述的步骤 99%的可能破解成功，此时打开 IDEA，点击help-&gt;Register查看是否破解成功，出现下图将是破解成功，如下： 里面的激活码是重启之上自动填入的，如果不行找到下载的压缩文件 lib 下的 ACTIVATION_CODE.txt 换一个激活码或者查看 README.pdf 帮助。 总结 至此 IDEA 2020 已经破解成功了，按照陈某的步骤 99%的朋友保证能够破解成功，文中的破解文件在公众号回复IDEA破解包即可获取。 另外如果想要 IDEA 2020 的安装包，回复关键词IDEA2020即可获取。 关注我微信公众号【码猿技术专栏】]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[线上Bug无法复现怎么办？老司机教你一招，SpringBoot远程调试不用愁！]]></title>
      <url>%2F2020%2F04%2F28%2F%E7%BA%BF%E4%B8%8ABug%E6%97%A0%E6%B3%95%E5%A4%8D%E7%8E%B0%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F%E8%80%81%E5%8F%B8%E6%9C%BA%E6%95%99%E4%BD%A0%E4%B8%80%E6%8B%9B%EF%BC%8CSpringBoot%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95%E4%B8%8D%E7%94%A8%E6%84%81%EF%BC%81%2F</url>
      <content type="text"><![CDATA[前言 在部署线上项目时，相信大家都会遇到一个问题，线上的 Bug 但是在本地不会复现，多么无奈。 此时最常用的就是取到前端传递的数据用接口测试工具测试，比如 POSTMAN，复杂不，难受不？ 今天陈某教你一招，让你轻松调试线上的 Bug。文章目录如下： 什么是 JPDA？ JPDA(Java Platform Debugger Architecture)，即 Java 平台调试体系，具体结构图如下图所示。 其中实现调试功能的主要协议是JDWP协议，在 Java SE 5 以前版本，JVM 端的实现接口是 JVMPI(Java Virtual Machine Profiler Interface)，而在 Java SE 5 及以后版本，使用 JVMTI(Java Virtual Machine Tool Interface) 来替代 JVMPI。 因此，如果使用 Java SE 5 之前版本，使用调试功能的命令为： 1java -Xdebug -Xrunjdwp:... 而 Java SE 5 及之后版本，使用调试功能的命令为： 1java -agentlib:jdwp=... 调试命令 现在开发中最常见的一条远程调试的的命令如下： 1java -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=9091 -jar xxx.jar 参数说明 基于前面的调试命令，我们来分析一下基本的参数代表什么意思。 transport 指定运行的被调试应用和调试者之间的通信协议，它由几个可选值： dt_socket：主要的方式，采用socket方式连接。 dt_shmem：采用共享内存方式连接，仅支持 Windows 平台。 server 指定当前应用作为调试服务端还是客户端，默认为n。 如果你想将当前应用作为被调试应用，设置该值为 y,如果你想将当前应用作为客户端，作为调试的发起者，设置该值为n。 suspend 当前应用启动后，是否阻塞应用直到被连接，默认值为 y。 在大部分的应用场景，这个值为 n，即不需要应用阻塞等待连接。一个可能为 y的应用场景是，你的程序在启动时出现了一个故障，为了调试，必须等到调试方连接上来后程序再启动。 address 暴露的调试连接端口，默认值为 8000。 此端口一定不能与项目端口重复，且必须是服务器开放的端口。 onthrow 当程序抛出设定异常时，中断调试。 onuncaught 当程序抛出未捕获异常时，是否中断调试，默认值为 n。 launch 当调试中断时，执行的程序。 timeout 该参数限定为java -agentlib:jdwp=…可用，单位为毫秒ms。 当 suspend = y 时，该值表示等待连接的超时；当 suspend = n 时，该值表示连接后的使用超时。 参考命令 -agentlib:jdwp=transport=dt_socket,server=y,address=8000：以 Socket 方式监听 8000 端口，程序启动阻塞（suspend 的默认值为 y）直到被连接。 -agentlib:jdwp=transport=dt_socket,server=y,address=localhost:8000,timeout=5000：以 Socket 方式监听 8000 端口，当程序启动后 5 秒无调试者连接的话终止，程序启动阻塞（suspend 的默认值为 y）直到被连接。 -agentlib:jdwp=transport=dt_shmem,server=y,suspend=n：选择可用的共享内存连接地址并使用 stdout 打印，程序启动不阻塞。 -agentlib:jdwp=transport=dt_socket,address=myhost:8000：以 socket 方式连接到 myhost:8000上的调试程序，在连接成功前启动阻塞。 -agentlib:jdwp=transport=dt_socket,server=y,address=8000,onthrow=java.io.IOException,launch=/usr/local/bin/debugstub：以 Socket 方式监听 8000 端口，程序启动阻塞（suspend 的默认值为 y）直到被连接。当抛出 IOException 时中断调试，转而执行 usr/local/bin/debugstub程序。 IDEA 远程调试示例 首先打包 SpringBoot 项目，在服务器上运行，执行以下命令： 1java -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=9190 -jar debug-demo.jar 出现下图的界面，表示运行成功： 然后在 IDEA 中，点击 Edit Configurations，在弹框中点击 + 号，然后选择Remote。 填写服务器的地址及端口，点击 OK 即可。 配置完毕后，DEBUG 调试运行即可。 配置完毕后点击保存即可，因为我配置的 suspend=n，因此服务端程序无需阻塞等待我们的连接。我们点击 IDEA 调试按钮，当我访问某一接口时，能够正常调试。 小福利 作者为大家准备了接近 10M 的面试题，涵盖后端各个技术维度，老规矩，公众号内回复关键词JAVA面试题即可免费获取。 关注微信公众号回复关键词：]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[大白话布隆过滤器，又能和面试官扯皮了！！！]]></title>
      <url>%2F2020%2F04%2F26%2F%E5%A4%A7%E7%99%BD%E8%AF%9D%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%EF%BC%8C%E5%8F%88%E8%83%BD%E5%92%8C%E9%9D%A2%E8%AF%95%E5%AE%98%E6%89%AF%E7%9A%AE%E4%BA%86%EF%BC%81%EF%BC%81%EF%BC%81%2F</url>
      <content type="text"><![CDATA[前言 文章首发于微信公众号大白话布隆过滤器，又能和面试官扯皮了~ 近期在做推荐系统中已读内容去重的相关内容，刚好用到了布隆过滤器，于是写了一篇文章记录分享一下。 文章的篇幅不是很长，主要讲了布隆过滤器的核心思想，目录如下： 什么是布隆过滤器？ 布隆过滤器是由一个长度为m比特的位数组与k个哈希函数组成的数据结构。比特数组均初始化为0，所有哈希函数都可以分别把输入数据尽量均匀地散列。 当插入一个元素时，将其数据通过k个哈希函数转换成k个哈希值，这k个哈希值将作为比特数组的下标，并将数组中的对应下标的值置为1。 当查询一个元素时，同样会将其数据通过k个哈希函数转换成k个哈希值（数组下标），查询数组中对应下标的值，如果有一个下标的值为0表明该元素一定不在集合中，如果全部下标的值都为1，表明该元素有可能在集合中。至于为什么有可能在集合中？ 因为有可能某个或者多个下标的值为 1 是受到其他元素的影响，这就是所谓的假阳性，下文会详细讲述。 无法删除一个元素，为什么呢？因为你删除的元素的哈希值可能和集合中的某个元素的哈希值有相同的，一旦删除了这个元素会导致其他的元素也被删除。 下图示出一个m=18, k=3的布隆过滤器示例。集合中的 x、y、z 三个元素通过 3 个不同的哈希函数散列到位数组中。当查询元素 w 时，因为有一个比特为 0，因此 w 不在该集合中。 假阳性概率的计算 假阳性是布隆过滤器的一个痛点，因此需要不择一切手段来使假阳性的概率降低，此时就需要计算一下假阳性的概率了。 假设我们的哈希函数选择位数组中的比特时，都是等概率的。当然在设计哈希函数时，也应该尽量满足均匀分布。 在位数组长度m的布隆过滤器中插入一个元素，它的其中一个哈希函数会将某个特定的比特置为1。因此，在插入元素后，该比特仍然为 0 的概率是： 现有k个哈希函数，并插入n个元素，自然就可以得到该比特仍然为 0 的概率是： 反过来讲，它已经被置为1的概率就是： 也就是说，如果在插入n个元素后，我们用一个不在集合中的元素来检测，那么被误报为存在于集合中的概率（也就是所有哈希函数对应的比特都为1的概率）为： 当n比较大时，根据极限公式，可以近似得出假阳性率： 所以，在哈希函数个数k一定的情况下有如下结论： 位数组长度 m 越大，假阳性率越低。 已插入元素的个数 n 越大，假阳性率越高。 优点 用比特数组表示，不用存储数据本身，对空间的节省相比于传统方式占据绝对的优势。 时间效率很高，无论是插入还是查询，只需要简单的经过哈希函数转换，时间复杂度均为O(k)。 缺点 存在假阳性的概率，准确率要求高的场景不太适用。 只能插入和查询，不能删除了元素。 应用场景 布隆过滤器的用途很多，但是主要的作用就是去重，这里列举几个使用场景。 爬虫重复 URL 检测 试想一下，百度是一个爬虫，它会定时搜集各大网站的信息，文章，那么它是如何保证爬取到文章信息不重复，它会将 URL 存放到布隆过滤器中，每次爬取之前先从布隆过滤器中判断这个 URL 是否存在，这样就避免了重复爬取。当然这种存在假阳性的可能，但是只要你的比特数组足够大，假阳性的概率会很低，另一方面，你认为百度会在意这种的误差吗，你的一篇文章可能因为假阳性概率没有收录到，对百度有影响吗？ 抖音推荐功能 读者朋友们应该没人没刷过抖音吧，每次刷的时候抖音给你的视频有重复的吗？他是如何保证推荐的内容不重复的呢？ 最容易想到的就是抖音会记录用户的历史观看记录，然后从历史记录中排除。这是一种解决办法，但是性能呢？不用多说了，有点常识的都知道这不可能。 解决这种重复的问题，布隆过滤器有着绝对的优势，能够很轻松的解决。 防止缓存穿透 缓存穿透是指查询一条数据库和缓存都没有的一条数据，就会一直查询数据库，对数据库的访问压力会一直增大。 布隆过滤器在解决缓存穿透的问题效果也是很好，这里不再细说，后续文章会写。 如何实现布隆过滤器？ 了解布隆过滤器的设计思想之后，想要实现一个布隆过滤器其实很简单，陈某这里就不再搬门弄斧了，介绍一下现成的实现方式吧。 Redis 实现 Redis4.0 之后推出了插件的功能，下面用 docker 安装： 12docker pull redislabs/rebloomdocker run -p6379:6379 redislabs/rebloom 安装完成后连接 redis 即可，运行命令： 1redis-cli 至于具体的使用这里不再演示了，直接看官方文档和教程，使用起来还是很简单的。 Guava 实现 guava 对应布隆过滤器的实现做出了支持，使用 guava 可以很轻松的实现一个布隆过滤器。 1. 创建布隆过滤器 创建布隆过滤器，如下： 12345678BloomFilter&lt;Integer&gt; filter = BloomFilter.create( Funnels.integerFunnel(), 5000, 0.01);//插入IntStream.range(0, 100_000).forEach(filter::put);//判断是否存在boolean b = filter.mightContain(1); arg1：用于将任意类型 T 的输入数据转化为 Java 基本类型的数据，这里转换为 byte arg2：byte 字节数组的基数 arg3：期望的假阳性概率 2.估计最优 m 值和 k 值 guava 在底层对 byte 数组的基数(m)和哈希函数的个数 k 做了自己的算法，源码如下： 12345678910111213//m值的计算static long optimalNumOfBits(long n, double p) &#123; if (p == 0) &#123; p = Double.MIN_VALUE; &#125; return (long) (-n * Math.log(p) / (Math.log(2) * Math.log(2)));&#125;//k值的计算static int optimalNumOfHashFunctions(long n, long m) &#123; // (m / n) * log(2), but avoid truncation due to division! return Math.max(1, (int) Math.round((double) m / n * Math.log(2)));&#125; 想要理解 guava 的计算原理，还要从的上面推导的过程继续。 由假阳性率的近似计算方法可知，如果要使假阳性率尽量小，在 m 和 n 给定的情况下，k值应为： 将 k 代入上一节的式子并化简，我们可以整理出期望假阳性率 p 与 m、n 的关系： 换算而得： 根据以上分析得出以下的结论： 如果指定期望假阳性率 p，那么最优的 m 值与期望元素数 n 呈线性关系。 最优的 k 值实际上只与 p 有关，与 m 和 n 都无关，即： 综上两个结论，在创建布隆过滤器的时候，确定p值和m值很重要。 总结 至此，布隆过滤器的知识介绍到这里，如果觉得陈某写得不错的，转发在看点一波，读者的一份支持将会是我莫大的鼓励。 另外想和陈某私聊或者想要加交流群的朋友，公众号回复关键词加群加陈某微信，陈某会第一时间拉你进群。 巨人的肩膀 https://blog.csdn.net/u012422440/article/details/94088166 https://blog.csdn.net/Revivedsun/article/details/94992323]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[看完这篇缓存穿透的文章，保证你能和面试官互扯！！！]]></title>
      <url>%2F2020%2F04%2F26%2F%E7%9C%8B%E5%AE%8C%E8%BF%99%E7%AF%87%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E7%9A%84%E6%96%87%E7%AB%A0%EF%BC%8C%E4%BF%9D%E8%AF%81%E4%BD%A0%E8%83%BD%E5%92%8C%E9%9D%A2%E8%AF%95%E5%AE%98%E4%BA%92%E6%89%AF%EF%BC%81%EF%BC%81%EF%BC%81%2F</url>
      <content type="text"><![CDATA[前言 昨天有读者朋友留言，想要陈某写一篇防止缓存穿透的文章，今天特意写了一篇。 文章目录如下： 什么是缓存穿透？ 缓存穿透其实是指从缓存中没有查到数据，而不得不从后端系统（比如数据库）中查询的情况。 缓存毕竟是在内存中，不可能所有的数据都存储在 Redis 中，因此少量的缓存穿透是不可避免的，也是系统能够承受的，但是一旦在瞬间发生大量的缓存穿透，数据库的压力会瞬间增大，后果可想而知。 在开发中使用缓存的方案如下图，在查询数据库之前会先查询 Redis： 缓存穿透的整个过程分为如下几个步骤： 应用查询缓存，缓存不命中 DB 层查询不命中，不将空结果缓存 返回空结果 下一个请求继续重复1,2,3步。 解决方案 万事万物都是相生相克，既然出现了缓存穿透，就一定有避免的方案。 下面介绍两种缓存的方案，分别是缓存空值、布隆过滤器。 缓存空值 回顾缓存穿透的定义知道，大量空值没有缓存导致重复的访问 DB 层，由此解决方案也是很明显了，直接将返回的空值也缓存即可。此时的执行步骤如下图： 如上图所示，如果缓存不命中，查询 DB 层之后，直接将空值缓存在 Redis 中。伪代码如下： 123456789101112Object nullValue = new Object();try &#123; Object valueFromDB = getFromDB(uid); //从数据库中查询数据 if (valueFromDB == null) &#123; cache.set(uid, nullValue, 10); //如果从数据库中查询到空值，就把空值写入缓存，设置较短的超时时间 &#125; else &#123; cache.set(uid, valueFromDB, 1000); &#125;&#125; catch(Exception e) &#123; // 出现异常也要写入缓存 cache.set(uid, nullValue, 10);&#125; 通过伪代码可以很清楚的了解了缓存空值的流程，但是需要注意以下问题： 缓存一定要设置过期时间：因为空值并不是准确的业务数据，并且会占用缓存空间，所以要给空值加上一个过期时间，使得能够在短期之内被淘汰。但是随之而来的一个问题就是在一定的时间窗口内缓存的数据和实际数据不一致，比如设置 10 秒钟过期时间，但是在这 10 秒之内业务又写入了数据，那么返回就不应该为空值了，所以还要考虑数据一致的问题，解决方法很简单，利用消息系统或者主动更新的方式清除掉缓存中的数据即可。 布隆过滤器 1970 年布隆提出了一种布隆过滤器的算法，用来判断一个元素是否在一个集合中。这种算法由一个二进制数组和一个 Hash 算法组成。 具体的算法思想这里不再详细解释了，如有不了解的可以看陈某上一篇文章大白话布隆过滤器，又能和面试官扯皮了~。 解决缓存穿透的大致思想：在访问缓存层和存储层之前，可以通过定时任务或者系统任务来初始化布隆过滤器，将存在的 key 用布隆过滤器提前保存起来，做第一层的拦截。例如：一个推荐系统有 4 亿个用户 id， 每个小时算法工程师会根据每个用户之前历史行为计算出推荐数据放到存储层中， 但是最新的用户由于没有历史行为， 就会发生缓存穿透的行为， 为此可以将所有推荐数据的用户做成布隆过滤器。 如果布隆过滤器认为该用户 id 不存在， 那么就不会访问存储层， 在一定程度保护了存储层。此时的结构如下图： 当然布隆过滤器的假阳性的存在导致了误判率，但是我们可以尽量的降低误判率，一个解决方案就是：使用多个 Hash 算法为元素计算出多个 Hash 值，只有所有 Hash 值对应的数组中的值都为 1 时，才会认为这个元素在集合中。 这种方法适用于数据命中不高、 数据相对固定、 实时性低（通常是数据 集较大）的应用场景，代码维护较为复杂，但是缓存空间占用少。为什么呢？因为布隆过滤器不支持删除元素，一旦数据变化，并不能及时的更新布隆过滤器。 两种方案对比 两种方案各有优缺点，具体使用哪种方案还是要根据业务场景和系统体量来定。具体的区别如下表： 方案 适用场景 维护成本 缓存对象 1. 数据命中不高 2. 数据频繁变化，实时性高 代码维护点单、需要过多的缓存空间，数据一致性需要自己实现 布隆过滤器 1. 数据命中不高 2.数据相对固定，实时性低 代码维护复杂、缓存空间占用少 总结 至此，如何解决缓存穿透的问题已经介绍完了，觉得写得不错的，有所收获的朋友，点点在看，分享关注一波。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[《Mybatis进阶》肝了30天专栏文章，整理成册！！！]]></title>
      <url>%2F2020%2F04%2F20%2F%E3%80%8AMybatis%E8%BF%9B%E9%98%B6%E3%80%8B%E8%82%9D%E4%BA%8630%E5%A4%A9%E4%B8%93%E6%A0%8F%E6%96%87%E7%AB%A0%EF%BC%8C%E6%95%B4%E7%90%86%E6%88%90%E5%86%8C%EF%BC%81%EF%BC%81%EF%BC%81%2F</url>
      <content type="text"><![CDATA[持续原创输出，点击上方蓝字关注我吧 目录 前言简介如何获取？总结前言Mybatis专栏文章写到至今已经有一个月了，从基础到源码详细的介绍了每个知识点，没什么多余的废话，全是工作、面试中常用到的姿势。有读者建议将文章汇总，这样方便阅读，于是特意花费了一天时间整理成册。全册总计92页，总计想3万多字，耗时30多天完成。由于作者水平有限，如果书中有不理解和错误的内容，感谢及时把疑惑或意见提交给我，作者会及时修正。简介Mybatis作为一个与数据库交互的轻量级的框架，深受大众喜爱，目前也是主流的框架之一，在平时开发中会经常使用。可能有些朋友已经用了几年了，在此之前也看过许多的书籍，但是真正的讲讲细化的知识点可能并没有那么容易。本册文章页面美观，图文并茂，阅读起来很享受，不像市面上文档形式的书籍。本册纯属个人总结，其中有多地方需要校正，不喜勿喷！！！适合人群具有一定专业基础的程序员，想要系统学习Mybatis。对于Mybatis只是停留在会用的基础，想深入学习的程序员。学习过Mybatis，但是没找到一本合适的书籍系统学习的程序员。如何获取扫描下方二维码，添加作者微信注明来意，或者关注公众号【码猿技术专栏】回复关键词Mybatis进阶即可免费获取。总结至此Mybatis的专栏就结束了，下个征程即将开始，喜欢的朋友关注分享一波。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[面试官：讲一讲Mybatis插件的原理及如何实现？]]></title>
      <url>%2F2020%2F04%2F20%2F%E9%9D%A2%E8%AF%95%E5%AE%98%EF%BC%9A%E8%AE%B2%E4%B8%80%E8%AE%B2Mybatis%E6%8F%92%E4%BB%B6%E7%9A%84%E5%8E%9F%E7%90%86%E5%8F%8A%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%EF%BC%9F%2F</url>
      <content type="text"><![CDATA[持续原创输出，点击上方蓝字关注我吧 目录 前言环境配置什么是插件？如何自定义插件？举个栗子用到哪些注解？如何注入Mybatis？测试插件原理分析如何生成代理对象？如何执行？总结分页插件的原理分析总结前言Mybatis的分页插件相信大家都使用过，那么可知道其中的实现原理？分页插件就是利用的Mybatis中的插件机制实现的，在Executor的query执行前后进行分页处理。此篇文章就来介绍以下Mybatis的插件机制以及在底层是如何实现的。环境配置本篇文章讲的一切内容都是基于Mybatis3.5和SpringBoot-2.3.3.RELEASE。什么是插件？插件是Mybatis中的最重要的功能之一，能够对特定组件的特定方法进行增强。MyBatis 允许你在映射语句执行过程中的某一点进行拦截调用。默认情况下，MyBatis 允许使用插件来拦截的方法调用包括：Executor：update, query, flushStatements, commit, rollback, getTransaction, close, isClosedParameterHandler: getParameterObject, setParametersResultSetHandler：handleResultSets, handleOutputParametersStatementHandler: prepare, parameterize, batch, update, query如何自定义插件？插件的实现其实很简单，只需要实现Mybatis提供的Interceptor这个接口即可，源码如下：public interface Interceptor { //拦截的方法 Object intercept(Invocation invocation) throws Throwable; //返回拦截器的代理对象 Object plugin(Object target); //设置一些属性 void setProperties(Properties properties);}举个栗子有这样一个需求：需要在Mybatis执行的时候篡改selectByUserId的参数值。分析：修改SQL的入参，应该在哪个组件的哪个方法上拦截篡改呢？研究过源码的估计都很清楚的知道，ParameterHandler中的setParameters()方法就是对参数进行处理的。因此肯定是拦截这个方法是最合适。自定义的插件如下：/ @Intercepts 注解标记这是一个拦截器,其中可以指定多个@Signature @Signature 指定该拦截器拦截的是四大对象中的哪个方法 type：拦截器的四大对象的类型 method：拦截器的方法，方法名 args：入参的类型，可以是多个，根据方法的参数指定，以此来区分方法的重载 /@Intercepts( { @Signature(type = ParameterHandler.class,method =“setParameters”,args = {PreparedStatement.class}) })public class ParameterInterceptor implements Interceptor { @Override public Object intercept(Invocation invocation) throws Throwable { System.out.println(“拦截器执行：”+invocation.getTarget()); //目标对象 Object target = invocation.getTarget(); //获取目标对象中所有属性的值，因为ParameterHandler使用的是DefaultParameterHandler，因此里面的所有的属性都封装在其中 MetaObject metaObject = SystemMetaObject.forObject(target); //使用xxx.xxx.xx的方式可以层层获取属性值，这里获取的是mappedStatement中的id值 String value = (String) metaObject.getValue(“mappedStatement.id”); //如果是指定的查询方法 if (“cn.cb.demo.dao.UserMapper.selectByUserId”.equals(value)){ //设置参数的值是admin_1，即是设置id=admin_1，因为这里只有一个参数，可以这么设置，如果有多个需要需要循环 metaObject.setValue(“parameterObject”, “admin_1”); } //执行目标方法 return invocation.proceed(); } @Override public Object plugin(Object target) { //如果没有特殊定制，直接使用Plugin这个工具类返回一个代理对象即可 return Plugin.wrap(target, this); } @Override public void setProperties(Properties properties) { }}intercept方法：最终会拦截的方法，最重要的一个方法。plugin方法：返回一个代理对象，如果没有特殊要求，直接使用Mybatis的工具类Plugin返回即可。setProperties：设置一些属性，不重要。用到哪些注解？自定义插件需要用到两个注解，分别是@Intercepts和@Signature。@Intercepts：标注在实现类上，表示这个类是一个插件的实现类。@Signature：作为@Intercepts的属性，表示需要增强Mybatis的某些组件中的某些方法（可以指定多个）。常用的属性如下：Class&lt;?&gt; type()：指定哪个组件（Executor、ParameterHandler、ResultSetHandler、StatementHandler）String method()：指定增强组件中的哪个方法，直接写方法名称。Class&lt;?&gt;[] args()：方法中的参数，必须一一对应，可以写多个；这个属性非常重用，区分重载方法。如何注入Mybatis？上面已经将插件定义好了，那么如何注入到Mybatis中使其生效呢？前提：由于本篇文章的环境是SpringBoot+Mybatis，因此讲一讲如何在SpringBoot中将插件注入到Mybatis中。在Mybatis的自动配置类MybatisAutoConfiguration中，注入SqlSessionFactory的时候，有如下一段代码：上图中的this.interceptors是什么，从何而来，其实就是从容器中的获取的Interceptor[]，如下一段代码：从上图我们知道，这插件最终还是从IOC容器中获取的Interceptor[]这个Bean，因此我们只需要在配置类中注入这个Bean即可，如下代码：/ @Configuration：这个注解标注该类是一个配置类 /@Configurationpublic class MybatisConfig{ /* @Bean ： 该注解用于向容器中注入一个Bean 注入Interceptor[]这个Bean @return */ @Bean public Interceptor[] interceptors(){ //创建ParameterInterceptor这个插件 ParameterInterceptor parameterInterceptor = new ParameterInterceptor(); //放入数组返回 return new Interceptor[]{parameterInterceptor}; }}测试此时自定义的插件已经注入了Mybatis中了，现在测试看看能不能成功执行呢？测试代码如下： @Test void contextLoads() { //传入的是1222 UserInfo userInfo = userMapper.selectByUserId(“1222”); System.out.println(userInfo); }测试代码传入的是1222，由于插件改变了入参，因此查询出来的应该是admin_1这个人。插件原理分析插件的原理其实很简单，就是在创建组件的时候生成代理对象(Plugin)，执行组件方法的时候拦截即可。下面就来详细介绍一下插件在Mybatis底层是如何工作的？Mybatis的四大组件都是在Mybatis的配置类Configuration中创建的，具体的方法如下：//创建Executorpublic Executor newExecutor(Transaction transaction, ExecutorType executorType) { executorType = executorType == null ? defaultExecutorType : executorType; executorType = executorType == null ? ExecutorType.SIMPLE : executorType; Executor executor; if (ExecutorType.BATCH == executorType) { executor = new BatchExecutor(this, transaction); } else if (ExecutorType.REUSE == executorType) { executor = new ReuseExecutor(this, transaction); } else { executor = new SimpleExecutor(this, transaction); } if (cacheEnabled) { executor = new CachingExecutor(executor); } //调用pluginAll方法，生成代理对象 executor = (Executor) interceptorChain.pluginAll(executor); return executor; } //创建ParameterHandler public ParameterHandler newParameterHandler(MappedStatement mappedStatement, Object parameterObject, BoundSql boundSql) { ParameterHandler parameterHandler = mappedStatement.getLang().createParameterHandler(mappedStatement, parameterObject, boundSql); //调用pluginAll方法，生成代理对象 parameterHandler = (ParameterHandler) interceptorChain.pluginAll(parameterHandler); return parameterHandler; }//创建ResultSetHandler public ResultSetHandler newResultSetHandler(Executor executor, MappedStatement mappedStatement, RowBounds rowBounds, ParameterHandler parameterHandler, ResultHandler resultHandler, BoundSql boundSql) { ResultSetHandler resultSetHandler = new DefaultResultSetHandler(executor, mappedStatement, parameterHandler, resultHandler, boundSql, rowBounds); //调用pluginAll方法，生成代理对象 resultSetHandler = (ResultSetHandler) interceptorChain.pluginAll(resultSetHandler); return resultSetHandler; } //创建StatementHandler public StatementHandler newStatementHandler(Executor executor, MappedStatement mappedStatement, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) { StatementHandler statementHandler = new RoutingStatementHandler(executor, mappedStatement, parameterObject, rowBounds, resultHandler, boundSql); //调用pluginAll方法，生成代理对象 statementHandler = (StatementHandler) interceptorChain.pluginAll(statementHandler); return statementHandler; }从上面的源码可以知道，创建四大组件的方法中都会执行pluginAll()这个方法来生成一个代理对象。具体如何生成的，下面详解。如何生成代理对象？创建四大组件过程中都执行了pluginAll()这个方法，此方法源码如下：public Object pluginAll(Object target) { //循环遍历插件 for (Interceptor interceptor : interceptors) { //调用插件的plugin()方法 target = interceptor.plugin(target); } //返回 return target; }pluginAll()方法很简单，直接循环调用插件的plugin()方法，但是我们调用的是Plugin.wrap(target, this)这行代码，因此要看一下wrap()这个方法的源码，如下：public static Object wrap(Object target, Interceptor interceptor) { //获取注解的@signature的定义 Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap = getSignatureMap(interceptor); //目标类 Class&lt;?&gt; type = target.getClass(); //获取需要拦截的接口 Class&lt;?&gt;[] interfaces = getAllInterfaces(type, signatureMap); if (interfaces.length &gt; 0) { //生成代理对象 return Proxy.newProxyInstance( type.getClassLoader(), interfaces, new Plugin(target, interceptor, signatureMap)); } return target; }Plugin.wrap()这个方法的逻辑很简单，判断这个插件是否是拦截对应的组件，如果拦截了，生成代理对象（Plugin）返回，没有拦截直接返回，上面例子中生成的代理对象如下图：如何执行？上面讲了Mybatis启动的时候如何根据插件生成代理对象的(Plugin)。现在就来看看这个代理对象是如何执行的？既然是动态代理，肯定会执行的invoke()这个方法，Plugin类中的invoke()源码如下：@Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { try { //获取@signature标注的方法 Set&lt;Method&gt; methods = signatureMap.get(method.getDeclaringClass()); //如果这个方法被拦截了 if (methods != null &amp;&amp; methods.contains(method)) { //直接执行插件的intercept()这个方法 return interceptor.intercept(new Invocation(target, method, args)); } //没有被拦截，执行原方法 return method.invoke(target, args); } catch (Exception e) { throw ExceptionUtil.unwrapThrowable(e); } }逻辑很简单，这个方法被拦截了就执行插件的intercept()方法，没有被拦截，则执行原方法。还是以上面自定义的插件来看看执行的流程：setParameters()这个方法在PreparedStatementHandler中被调用，如下图：执行invoke()方法，发现setParameters()这个方法被拦截了，因此直接执行的是intercept()方法。总结Mybatis中插件的原理其实很简单，分为以下几步：在项目启动的时候判断组件是否有被拦截，如果没有直接返回原对象。如果有被拦截，返回动态代理的对象（Plugin）。执行到的组件的中的方法时，如果不是代理对象，直接执行原方法如果是代理对象，执行Plugin的invoke()方法。分页插件的原理分析此处安利一款经常用的分页插件pagehelper，Maven依赖如下： &lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt; &lt;version&gt;5.1.6&lt;/version&gt; &lt;/dependency&gt;分页插件很显然也是根据Mybatis的插件来定制的，来看看插件PageInterceptor的源码如下：@Intercepts( { @Signature(type = Executor.class, method = “query”, args = {MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class}), @Signature(type = Executor.class, method = “query”, args = {MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class, CacheKey.class, BoundSql.class}), })public class PageInterceptor implements Interceptor {}既然是分页功能，肯定是在query()的时候拦截，因此肯定是在Executor这个组件中。分页插件的原理其实很简单，不再一一分析源码了，根据的自己定义的分页数据重新赋值RowBounds来达到分页的目的，当然其中涉及到数据库方言等等内容，不是本章重点，有兴趣可以看一下GitHub上的文档。总结对于业务开发的程序员来说，插件的这个功能很少用到，但是不用就不应该了解吗？做人要有追求，哈哈。欢迎关注作者的微信公众号码猿技术专栏，作者为你们精心准备了springCloud最新精彩视频教程、精选500本电子书、架构师免费视频教程等等免费资源，让我们一起进阶，一起成长。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[面试官问：Mybatis中的TypeHandler你用过吗？]]></title>
      <url>%2F2020%2F04%2F20%2F%E9%9D%A2%E8%AF%95%E5%AE%98%E9%97%AE%EF%BC%9AMybatis%E4%B8%AD%E7%9A%84TypeHandler%E4%BD%A0%E7%94%A8%E8%BF%87%E5%90%97%EF%BC%9F%2F</url>
      <content type="text"><![CDATA[持续原创输出，点击上方蓝字关注我吧 目录 前言环境配置什么是TypeHandler？如何自定义？如何将其添加到Mybatis中？XML文件中如何指定TypeHandler？源码中如何执行TypeHandler？入参如何转换？结果如何转换？总结总结前言相信大家用Mybatis这个框架至少一年以上了吧，有没有思考过这样一个问题：数据库有自己的数据类型，Java有自己的数据类型，那么Mybatis是如何把数据库中的类型和Java的数据类型对应的呢？本篇文章就来讲讲Mybatis中的黑匣子TypeHandler(类型处理器)，说它是黑匣子一点都不为过，总是在默默的奉献着，但是不为人知。环境配置本篇文章讲的一切内容都是基于Mybatis3.5和SpringBoot-2.3.3.RELEASE。什么是TypeHandler？顾名思义，类型处理器，将入参和结果转换为所需要的类型，Mybatis中对于内置了许多类型处理器，实际开发中已经足够使用了，如下图：类型处理器这个接口其实很简单，总共四个方法，一个方法将入参的Java类型的数据转换为JDBC类型，三个方法将返回结果转换为Java类型。源码如下：public interface TypeHandler&lt;T&gt; { //设置参数，java类型转换为jdbc类型 void setParameter(PreparedStatement ps, int i, T parameter, JdbcType jdbcType) throws SQLException; //将查询的结果转换为java类型 T getResult(ResultSet rs, String columnName) throws SQLException; T getResult(ResultSet rs, int columnIndex) throws SQLException; T getResult(CallableStatement cs, int columnIndex) throws SQLException;}如何自定义并使用TypeHandler？实际应用开发中的难免会有一些需求要自定义一个TypeHandler，比如这样一个需求：前端传来的年龄是男,女，但是数据库定义的字段却是int类型（1男2女）。此时可以自定义一个年龄的类型处理器，进行转换。如何自定义？自定义的方式有两种，一种是实现TypeHandler这个接口，另一个就是继承BaseTypeHandler这个便捷的抽象类。下面直接继承BaseTypeHandler这个抽象类，定义一个年龄的类型处理器，如下：@MappedJdbcTypes(JdbcType.INTEGER)@MappedTypes(String.class)public class GenderTypeHandler extends BaseTypeHandler { //设置参数，这里将Java的String类型转换为JDBC的Integer类型 @Override public void setNonNullParameter(PreparedStatement ps, int i, Object parameter, JdbcType jdbcType) throws SQLException { ps.setInt(i, StringUtils.equals(parameter.toString(),“男”)?1:2); } //以下三个参数都是将查询的结果转换 @Override public Object getNullableResult(ResultSet rs, String columnName) throws SQLException { return rs.getInt(columnName)==1?“男”:“女”; } @Override public Object getNullableResult(ResultSet rs, int columnIndex) throws SQLException { return rs.getInt(columnIndex)==1?“男”:“女”; } @Override public Object getNullableResult(CallableStatement cs, int columnIndex) throws SQLException { return cs.getInt(columnIndex)==1?“男”:“女”; }}这里涉及到两个注解，如下：@MappedTypes：指定与其关联的 Java 类型列表。 如果在 javaType 属性中也同时指定，则注解上的配置将被忽略。@MappedJdbcTypes：指定与其关联的 JDBC 类型列表。 如果在 jdbcType 属性中也同时指定，则注解上的配置将被忽略。如何将其添加到Mybatis中？Mybatis在与SpringBoot整合之后一切都变得很简单了，其实这里有两种配置方式，下面将会一一介绍。第一种：只需要在配置文件application.properties中添加一行配置即可，如下：## 设置自定义的Typehandler所在的包，启动的时候会自动扫描配置到Mybatis中mybatis.type-handlers-package=cn.cb.demo.typehandler第二种：其实任何框架与Springboot整合之后，只要配置文件中能够配置的，在配置类中都可以配置（除非有特殊定制，否则不要轻易覆盖自动配置）。如下：@Bean(“sqlSessionFactory”) public SqlSessionFactory sqlSessionFactory(DataSource dataSource) throws Exception { SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean(); sqlSessionFactoryBean.setDataSource(dataSource); sqlSessionFactoryBean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(MAPPER_LOCATOIN)); org.apache.ibatis.session.Configuration configuration = new org.apache.ibatis.session.Configuration(); // 自动将数据库中的下划线转换为驼峰格式 configuration.setMapUnderscoreToCamelCase(true); configuration.setDefaultFetchSize(100); configuration.setDefaultStatementTimeout(30); sqlSessionFactoryBean.setConfiguration(configuration); //将typehandler注册到mybatis GenderTypeHandler genderTypeHandler = new GenderTypeHandler(); TypeHandler[] typeHandlers=new TypeHandler[]{genderTypeHandler}; sqlSessionFactoryBean.setTypeHandlers(typeHandlers); return sqlSessionFactoryBean.getObject(); }第二种方式的思想其实就是重写自动配置类MybatisAutoConfiguration中的方法。注意：除非自己有特殊定制，否则不要轻易重写自动配置类中的方法。XML文件中如何指定TypeHandler？上面的两个步骤分别是自定义和注入到Mybatis中，那么如何在XML文件中使用呢？使用其实很简单，分为两种，一种是更新，一种查询，下面将会一一介绍。更新：删除自不必说了，这里讲的是update和insert两种，只需要在#{}中指定的属性typeHandler为自定义的全类名即可，代码如下：&lt;insert id=“insertUser”&gt; insert into user_info(user_id,his_id,name,gender,password,create_time) values(#{userId,jdbcType=VARCHAR},#{hisId,jdbcType=VARCHAR},#{name,jdbcType=VARCHAR}, #{gender,jdbcType=INTEGER,typeHandler=cn.cb.demo.typehandler.GenderTypeHandler},#{password,jdbcType=VARCHAR},now()) &lt;/insert&gt;查询：查询的时候类型处理会将JDBC类型的转化为Java类型，因此也是需要指定typeHandler，需要在resultMap中指定typeHandler这个属性，值为全类名，如下：&lt;resultMap id=“userResultMap” type=“cn.cb.demo.domain.UserInfo”&gt; &lt;id column=“id” property=“id”/&gt; &lt;result column=“user_id” property=“userId”/&gt; &lt;result column=“his_id” property=“hisId”/&gt; &lt;!– 指定typeHandler属性为全类名–&gt; &lt;result column=“gender” property=“gender” typeHandler=“cn.cb.demo.typehandler.GenderTypeHandler”/&gt; &lt;result column=“name” property=“name”/&gt; &lt;result column=“password” property=“password”/&gt; &lt;/resultMap&gt; &lt;select id=“selectList” resultMap=“userResultMap”&gt; select * from user_info where status=1 and user_id in &lt;foreach collection=“userIds” item=“item” open=“(“ separator=“,” close=“)” &gt; #{item} &lt;/foreach&gt; &lt;/select&gt;源码中如何执行TypeHandler？既然会使用TypeHandler了，那么肯定要知道其中的执行原理了，在Mybatis中类型处理器是如何在JDBC类型和Java类型进行转换的，下面的将从源码角度详细介绍。入参如何转换？这个肯定是发生在设置参数的过程中，详细的代码在PreparedStatementHandler中的parameterize()方法中，这个方法就是设置参数的方法。源码如下： @Override public void parameterize(Statement statement) throws SQLException { //实际调用的是DefaultParameterHandler parameterHandler.setParameters((PreparedStatement) statement); }实际执行的是DefaultParameterHandler中的setParameters方法，如下：public void setParameters(PreparedStatement ps) { ErrorContext.instance().activity(“setting parameters”).object(mappedStatement.getParameterMap().getId()); //获取参数映射 List&lt;ParameterMapping&gt; parameterMappings = boundSql.getParameterMappings(); //遍历参数映射，一一设置 if (parameterMappings != null) { for (int i = 0; i &lt; parameterMappings.size(); i++) { ParameterMapping parameterMapping = parameterMappings.get(i); if (parameterMapping.getMode() != ParameterMode.OUT) { Object value; String propertyName = parameterMapping.getProperty(); if (boundSql.hasAdditionalParameter(propertyName)) { // issue #448 ask first for additional params value = boundSql.getAdditionalParameter(propertyName); } else if (parameterObject == null) { value = null; } else if (typeHandlerRegistry.hasTypeHandler(parameterObject.getClass())) { value = parameterObject; } else { MetaObject metaObject = configuration.newMetaObject(parameterObject); value = metaObject.getValue(propertyName); } //获取类型处理器，如果不存在，使用默认的 TypeHandler typeHandler = parameterMapping.getTypeHandler(); //JdbcType JdbcType jdbcType = parameterMapping.getJdbcType(); if (value == null &amp;&amp; jdbcType == null) { jdbcType = configuration.getJdbcTypeForNull(); } try { //调用类型处理器中的方法设置参数，将Java类型转换为JDBC类型 typeHandler.setParameter(ps, i + 1, value, jdbcType); } catch (TypeException e) { throw new TypeException(“Could not set parameters for mapping: “ + parameterMapping + “. Cause: “ + e, e); } catch (SQLException e) { throw new TypeException(“Could not set parameters for mapping: “ + parameterMapping + “. Cause: “ + e, e); } } } } }从上面的源码中可以知道这行代码typeHandler.setParameter(ps, i + 1, value, jdbcType);就是调用类型处理器中的设置参数的方法，将Java类型转换为JDBC类型。结果如何转换？这一过程肯定是发生在执行查询语句的过程中，之前也是介绍过Mybatis的六大剑客，其中的ResultSetHandler这个组件就是对查询的结果进行处理的，那么肯定是发生在这一组件中的某个方法。在PreparedStatementHandler执行查询结束之后，调用的是ResultSetHandler中的handleResultSets()方法，对结果进行处理，如下：public &lt;E&gt; List&lt;E&gt; query(Statement statement, ResultHandler resultHandler) throws SQLException { PreparedStatement ps = (PreparedStatement) statement; //执行SQL ps.execute(); //处理结果 return resultSetHandler.handleResultSets(ps); }最终的在DefaultResultHandler中的getPropertyMappingValue()方法中调用了TypeHandler中的getResult()方法，如下：private Object getPropertyMappingValue(ResultSet rs, MetaObject metaResultObject, ResultMapping propertyMapping, ResultLoaderMap lazyLoader, String columnPrefix) throws SQLException { if (propertyMapping.getNestedQueryId() != null) { return getNestedQueryMappingValue(rs, metaResultObject, propertyMapping, lazyLoader, columnPrefix); } else if (propertyMapping.getResultSet() != null) { addPendingChildRelation(rs, metaResultObject, propertyMapping); // TODO is that OK? return DEFERRED; } else { final TypeHandler&lt;?&gt; typeHandler = propertyMapping.getTypeHandler(); final String column = prependPrefix(propertyMapping.getColumn(), columnPrefix); //执行typeHandler中的方法获取结果并且转换为对应的Java类型 return typeHandler.getResult(rs, column); } }总结上述只是简要的介绍了类型处理器如何在Mybatis中执行的，可能其中有些概念东西如果不清楚的，可以看一下作者前面的文章，如下：Mybatis源码解析之六剑客Mybatis源码如何阅读，教你一招！！！Mybatis如何执行Select语句，你知道吗？总结本文详细的介绍了TypeHandler在Mybatis中的应用、自定义使用以及从源码角度分析了类型处理器的执行流程，如果觉得作者写的不错，有所收获的话，不妨点点关注，分享一波。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Mybatis的Mapper中的方法为什么不能重载？]]></title>
      <url>%2F2020%2F04%2F20%2FMybatis%E7%9A%84Mapper%E4%B8%AD%E7%9A%84%E6%96%B9%E6%B3%95%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E8%83%BD%E9%87%8D%E8%BD%BD%2F</url>
      <content type="text"><![CDATA[持续原创输出，点击上方蓝字关注我吧 作者：不才陈某博客：https://chenjiabing666.github.io/ 目录 前言环境配置错误示范为什么不能重载？如何找到XML中对应的SQL？总结前言在初入门Mybatis的时候可能都犯过一个错误，那就是在写Mapper接口的时候都重载过其中的方法，但是运行起来总是报错，那时候真的挺郁闷的，但是自己也查不出来原因，只能默默的改了方法名，哈哈，多么卑微的操作。今天就写一篇文章从源码角度为大家解惑为什么Mybatis中的方法不能重载？环境配置本篇文章讲的一切内容都是基于Mybatis3.5和SpringBoot-2.3.3.RELEASE。错误示范举个栗子：假设现在有两个需求，一个是根据用户的id筛选用户，一个是根据用户的性别筛选，此时在Mapper中重载的方法如下：public interface UserMapper { List&lt;UserInfo&gt; selectList(@Param(“userIds”) List&lt;String&gt; userIds); List&lt;UserInfo&gt; selectList(Integer gender); }这个并没有什么错误，但是启动项目，报出如下的错误：Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name ‘sqlSessionFactory’ defined in class path resource [org/mybatis/spring/boot/autoconfigure/MybatisAutoConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.apache.ibatis.session.SqlSessionFactory]: Factory method ‘sqlSessionFactory’ threw exception; nested exception is org.springframework.core.NestedIOException: Failed to parse mapping resource: ‘file [H:\work_project\demo\target\classes\mapper\UserInfoMapper.xml]’; nested exception is org.apache.ibatis.builder.BuilderException: Error parsing Mapper XML. The XML location is ‘file [H:\work_project\demo\target\classes\mapper\UserInfoMapper.xml]’. Cause: java.lang.IllegalArgumentException: Mapped Statements collection already contains value for cn.cb.demo.dao.UserMapper.selectList. please check file [H:\work_project\demo\target\classes\mapper\UserInfoMapper.xml] and file [H:\work_project\demo\target\classes\mapper\UserInfoMapper.xml] at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:655) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:635) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1336) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1176) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:556) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:516) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:324) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:226) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:322) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1307) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1227) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireByType(AbstractAutowireCapableBeanFactory.java:1509) … 81 more这么一大串什么意思？懵逼了~大致的意思：cn.cb.demo.dao.UserMapper.selectList这个id已经存在了，导致创建sqlSessionFactory失败。为什么不能重载？通过上面的异常提示可以知道创建sqlSessionFactory失败了，这个想必已经不陌生吧，顾名思义，就是创建SqlSession的工厂。Springboot与Mybatis会有一个启动器的自动配置类MybatisAutoConfiguration，其中有一段代码就是创建sqlSessionFactory，如下图：既然是创建失败，那么肯定是这里出现异常了，这里的大致思路就是：解析XML文件和Mapper接口，将Mapper中的方法与XML文件中&lt;select&gt;、&lt;insert&gt;等标签一一对应，那么Mapper中的方法如何与XML中&lt;select&gt;这些标签对应了，当然是唯一的id对应了，具体如何这个id的值是什么，如何对应？下面一一讲解。如上图的SqlSessionFactory的创建过程中，前面的部分代码都是设置一些配置，并没有涉及到解析XML的内容，因此答案肯定是在最后一行return factory.getObject();，于是此处打上断点，一点点看。于是一直到了org.mybatis.spring.SqlSessionFactoryBean#buildSqlSessionFactory这个方法中，其中一段代码如下：这里的xmlMapperBuilder.parse();就是解析XML文件与Mapper接口，继续向下看。略过不重要的代码，在org.apache.ibatis.builder.xml.XMLMapperBuilder#configurationElement这个方法中有一行重要的代码，如下图：此处就是根据XML文件中的select|insert|update|delete这些标签开始构建MappedStatement了。继续跟进去看。略过不重要的代码，此时看到org.apache.ibatis.builder.MapperBuilderAssistant#addMappedStatement这个方法返回值就是MappedStatement，不用多说，肯定是这个方法了，仔细一看，很清楚的看到了构建id的代码，如下图：从上图可以知道，创建id的代码就是id = applyCurrentNamespace(id, false);，具体实现如下图：上图的代码已经很清楚了，MappedStatement中的id=Mapper的全类名+’.’+方法名。如果重载话，肯定会存在id相同的MappedStatement。到了这其实并不能说明方法不能重载啊，重复就重复呗，并没有冲突啊。这里需要看一个结构，如下：protected final Map&lt;String, MappedStatement&gt; mappedStatements = new StrictMap&lt;MappedStatement&gt;(“Mapped Statements collection”) .conflictMessageProducer((savedValue, targetValue) -&gt; “. please check “ + savedValue.getResource() + “ and “ + targetValue.getResource());构建好的MappedStatement都会存入mappedStatements中，如下代码：public void addMappedStatement(MappedStatement ms) { //key 是id mappedStatements.put(ms.getId(), ms); }StrictMap的put(k,v)方法如下图：到了这里应该理解了吧，这下抛出的异常和上面的异常信息对应起来了吧。这个StrictMap不允许有重复的key，而存入的key就是id。因此Mapper中的方法不能重载。如何找到XML中对应的SQL？在使用Mybatis的时候只是简单的调用Mapper中的方法就可以执行SQL，如下代码：List&lt;UserInfo&gt; userInfos = userMapper.selectList(Arrays.asList(“192”,“198”));一行简单的调用到底如何找到对应的SQL呢？其实就是根据id从Map&lt;String, MappedStatement&gt; mappedStatements中查找对应的MappedStatement。在org.apache.ibatis.session.defaults.DefaultSqlSession#selectList方法有这一行代码如下图：MappedStatement ms = configuration.getMappedStatement(statement);这行代码就是根据id从mappedStatements获取对应的MappedStatement，源码如下:public MappedStatement getMappedStatement(String id) { return this.getMappedStatement(id, true); }总结文章写到这，想必已经很清楚Mapper中的方法为什么不能重载了，归根到底就是因为这个这个id=Mapper的全类名+’.’+方法名。如果觉得作者写的不错，有所收获的话，点点关注，分享一波，关注微信公众号码猿技术专栏第一手文章推送！！！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Mybatis如何执行Select语句，你真的知道吗？]]></title>
      <url>%2F2020%2F04%2F20%2FMybatis%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8CSelect%E8%AF%AD%E5%8F%A5%EF%BC%8C%E4%BD%A0%E7%9C%9F%E7%9A%84%E7%9F%A5%E9%81%93%E5%90%97%EF%BC%9F%2F</url>
      <content type="text"><![CDATA[持续原创输出，点击上方蓝字关注我吧 作者：不才陈某 博客：https://chenjiabing666.github.io 前言 本篇文章是Myabtis源码分析的第三篇，前两篇分别介绍了Mybatis的重要组件和围绕着Mybatis中的重要组件教大家如何阅读源码的一些方法，有了前面两篇文章的基础，来看这篇文章的才不会觉得吃力，如果没有看过的朋友，陈某建议去看看，两篇文章分别是Mybatis源码解析之六剑客和Mybatis源码如何阅读，教你一招！！！。今天接上一篇，围绕Mybatis中的selectList()来看一看Mybatis底层到底做了什么，有什么高级的地方。环境准备本篇文章讲的一切内容都是基于Mybatis3.5和SpringBoot-2.3.3.RELEASE。由于此篇文章是基于前两篇文章的基础之上，因此重复的内容不再详细赘述了。撸起袖子就是干二话不说，先来一张流程图，Mybatis六剑客，如下：上图中的这六剑客在前面两篇文章中已经介绍的非常清楚了，此处略过。为什么源码解析的每一篇文章中都要放一张这个流程图呢？因为Mybatis底层就是围绕着这六剑客展开的，我们需要从全局掌握Mybatis的源码究竟如何执行的。测试环境搭建举个栗子：根据用户id查询用户信息，Mapper定义如下：List&lt;UserInfo&gt; selectList(@Param(“userIds”) List&lt;String&gt; userIds);对应XML配置如下：&lt;mapper namespace=“cn.cb.demo.dao.UserMapper”&gt; &lt;!–开启二级缓存–&gt; &lt;cache/&gt; &lt;select id=“selectList” resultType=“cn.cb.demo.domain.UserInfo”&gt; select * from user_info where status=1 and user_id in &lt;foreach collection=“userIds” item=“item” open=“(“ separator=“,” close=“)” &gt; #{item} &lt;/foreach&gt; &lt;/select&gt;&lt;/mapper&gt;单元测试如下： @Test void contextLoads() { List&lt;UserInfo&gt; userInfos = userMapper.selectList(Arrays.asList(“192”,“198”)); System.out.println(userInfos); }DEBUG走起具体在哪里打上断点，上篇文章已经讲过了，不再赘述了。由于SpringBoot与Mybatis整合之后，自动注入的是SqlSessionTemplate，因此代码执行到org.mybatis.spring.SqlSessionTemplate#selectList(java.lang.String, java.lang.Object)，如图1：从源码可以看到，实际调用的还是DefaultSqlSession中的selectList方法。如下图2：具体的逻辑如下：根据Mapper方法的全类名从Mybatis的配置中获取到这条SQL的详细信息，比如paramterType,resultMap等等。既然开启了二级缓存，肯定先要判断这条SQL是否缓存过，因此实际调用的是CachingExecutor这个缓存执行器。DefaultSqlSession只是简单的获取SQL的详细配置，最终还是把任务交给了Executor（当然这里走的是二级缓存，因此交给了缓存执行器）。下面DEBUG走到CachingExecutor#query(MappedStatement, java.lang.Object, RowBounds,ResultHandler)，源码如下图3：上图中的query方法实际做了两件事，实际执行的查询还是其中重载的方法List&lt;E&gt; query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql)，如下图4：根据上图源码的分析，其实CachingExecutor执行的逻辑并不是很难，反倒很容易理解，具体的逻辑如下：如果开启了二级缓存，先根据cacheKey从二级缓存中查询，如果查询到了直接返回如果未开启二级缓存，再执行BaseExecutor中的query方法从一级缓存中查询。如果二级缓存中未查询到数据，再执行BaseExecutor中的query方法从一级缓存中查询。将查询到的结果存入到二级缓存中。BaseExecutor中的query方法无非就是从一级缓存中取数据，没查到再从数据库中取数据，一级缓存实际就是一个Map结构，这里不再细说，真正执行SQL从数据库中取数据的是SimpleExecutor中的public &lt;E&gt; List&lt;E&gt; doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql)方法，源码如下图5：从上面的源码也是可以知道，在真正执行SQL之前，是要调用prepareStatement(handler, ms.getStatementLog())方法做一些参数的预处理的，其中涉及到了六大剑客的另外两位，分别是ParameterHandler和TypeHandler，源码如图6：从上图可以知道设置SQL参数的真正方法是handler.parameterize(stmt)，真正执行的是DefaultParameterHandler中的setParameters方法，由于篇幅较长，简单的说一下思路：获取所有参数的映射循环遍历，获取参数的值，使用对应的TypeHandler将其转换成相应类型的参数。真正的设置参数的方法是TypeHandler中setParameter方法继续图6的逻辑，参数已经设置完了，此时就该执行SQL了，真正执行SQL的是PreparedStatementHandler中的&lt;E&gt; List&lt;E&gt; query(Statement statement, ResultHandler resultHandler)方法，源码如下图7：上图的逻辑其实很简单，一个是JDBC执行SQL语句，一个是调用六剑客之一的ResultSetHandler对结果进行处理。真正对结果进行处理的是DefaultResultSetHandler中的handleResultSets方法，源码比较复杂，这里就不再展示了，具体的逻辑如下：获取结果映射(resultMap)，如果没有指定，使用内置的结果映射遍历结果集，对SQL返回的每个结果通过结果集和TypeHandler进行结果映射。返回结果ResultSetHandler对结果处理结束之后就会返回。至此一条selectList()如何执行的大概心里已经有了把握，其他的更新，删除都是大同小异。总结Mybatis的源码算是几种常用框架中比较简单的，都是围绕六大组件进行的，只要搞懂了每个组件是什么角色，有什么作用，一切都会很简单。一条select语句简单执行的逻辑总结如下（前提：默认配置）：SqlSesion：#SqlSessionTemplate.selectList()实际调用#DefaultSqlSession.selectList()Executor：#DefaultSqlSession.quer()实际调用的是#CachingExecutor().query()，如果二级缓存中存在直接返回，不存在调用#BaseExecutor.quer()查询一级缓存，如果一级缓存中存在直接返回。不存在调用#SimpleExecutor.doQuery()方法查询数据库。StatementHandler：#SimpleExecutor.doQuery()生成StatementHandler实例，执行#PreparedStatementHandler.parameterize()方法设置参数，实际调用的是#ParamterHandler.setParameters()方法，该方法内部调用TypeHandler.setParameter()方法进行类型转换;参数设置成功后，调用#PreparedStatementHandler.parameterize().query()方法执行SQL，返回结果ResultSetHandler：#DefaultResultSetHandler.handleResultSets()对返回的结果进行处理，内部调用#TypeHandler.getResult()对结果进行类型转换。全部映射完成，返回结果。以上就是六剑客在Select的执行流程，如果有错误之处欢迎指正，如果觉得陈某写得不错，有所收获，关注分享一波。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Mybatis如何阅读源码，教你一招？]]></title>
      <url>%2F2020%2F04%2F20%2FMybatis%E5%A6%82%E4%BD%95%E9%98%85%E8%AF%BB%E6%BA%90%E7%A0%81%EF%BC%8C%E6%95%99%E4%BD%A0%E4%B8%80%E6%8B%9B%2F</url>
      <content type="text"><![CDATA[持续原创输出，点击上方蓝字关注我吧 前言 前一篇文章简单的介绍了Mybatis的六个重要组件，这六剑客占据了Mybatis的半壁江山，和六剑客搞了基友，那么Mybatis就是囊中之物了。对六剑客感兴趣的朋友，可以看看这篇文章：Mybatis源码解析篇之六剑客有些初入门的朋友可能很害怕阅读源码，不知道如何阅读源码，与其我一篇文章按照自己的思路写完Mybatis的源码，但是你们又能理解多少呢？不如教会你们思路，让你们能够自己知道如何阅读源码。环境配置本篇文章讲的一切内容都是基于Mybatis3.5和SpringBoot-2.3.3.RELEASE。从哪入手？还是要说一说六剑客的故事，既然是Mybatis的重要组件，当然要从六剑客下手了，沿用上篇文章的一张图，此图记录了六剑客先后执行的顺序，如下：阅读源码最重要的一点不能忘了，就是开启DEBUG模式，重要方法打上断点，重要语句打上断点，先把握整体，再研究细节，基本就不难了。下面就以Myabtis的查询语句selectList()来具体分析下如何阅读。总体把握六剑客从六剑客开整，既然是重要组件，源码执行流程肯定都是围绕着六剑客，下面来对六剑客一一分析，如何打断点。下面只是简单的教你如何打断点，对于六剑客是什么不再介绍，请看上篇文章。SqlSession既然是接口，肯定不能在接口方法上打断点，上文介绍有两个实现类，分别是DefaultSqlSession、SqlSessionTemplate。那么SpringBoot在初始化的时候到底注入的是哪一个呢？这个就要看Mybatis的启动器的自动配置类了，其中有一段这样的代码，如下： //如果容器中没有SqlSessionTemplate这个Bean，则注入 @Bean @ConditionalOnMissingBean public SqlSessionTemplate sqlSessionTemplate(SqlSessionFactory sqlSessionFactory) { ExecutorType executorType = this.properties.getExecutorType(); if (executorType != null) { return new SqlSessionTemplate(sqlSessionFactory, executorType); } else { return new SqlSessionTemplate(sqlSessionFactory); } }从上面的代码可以知道，SpringBoot启动时注入了SqlSessionTemplate，此时就肯定从SqlSessionTemplate入手了。它的一些方法如下图：从上图的标记可以知道，首当其冲的就是构造方法了;既然是分析selectList()的查询流程，当然全部的selectList()方法要打上断点了;上篇文章也讲了Mapper的接口最终是走的动态代理生成的实例，因此此处的getMapper()也打上断点。对于初入门的来说，上面三处打上断点已经足够了，但是如果你仔细看一眼selectList()方法，如下： @Override public &lt;E&gt; List&lt;E&gt; selectList(String statement) { //此处的sqlSessionProxy是什么，也是SqlSession类型的，此处断点运行到这里可以知道，就是DefaultSqlSession实例 return this.sqlSessionProxy.selectList(statement); }sqlSessionProxy是什么，没关系，这个不能靠猜，那么此时断点走一波，走到selectList()方法内部，如下图：从上图可以很清楚的看到了，其实就是DefaultSqlSession。哦，明白了，原来SqlSessionTemplate把过甩给了DefaultSqlSession了，太狡诈了。DefaultSqlSession如何打断点就不用说了吧，自己搞搞吧。Executor上面文章讲过执行器是什么作用，也讲过Mybatis内部是根据什么创建执行器的。此处不再赘述了。SpringBoot整合各种框架有个特点，万变不离自动配置类，框架的一些初始化动作基本全是在自动配置类中完成，于是我们在配置类找一找在哪里注入了Executor的Bean，于是找到了如下的一段代码：从上面的代码可以知道默认创建了CachingExecutor，二级缓存的执行器，别管那么多，看看它重写了Executor的哪些接口，与selectList()相关的方法打上断点，如下图：从上图也知道哪些方法和selectList()相关了，显然的query是查询的意思，别管那么多，先打上断点。此时再仔细瞅一眼query()的方法怎么执行的，哦？发现了什么，如下：@Override public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException { //先尝试从缓存中获取 Cache cache = ms.getCache(); if (cache != null) { flushCacheIfRequired(ms); if (ms.isUseCache() &amp;&amp; resultHandler == null) { ensureNoOutParams(ms, boundSql); @SuppressWarnings(“unchecked”) List&lt;E&gt; list = (List&lt;E&gt;) tcm.getObject(cache, key); if (list == null) { list = delegate.query(ms, parameterObject, rowBounds, resultHandler, key, boundSql); tcm.putObject(cache, key, list); // issue #578 and #116 } return list; } } //没有缓存，直接调用delegate的query方法 return delegate.query(ms, parameterObject, rowBounds, resultHandler, key, boundSql); }从上面的代码知道，有缓存了，直接返回了，没有缓存，调用了delegate中的query方法，那么这个delegate是哪个类的对象呢？参照sqlSession的分析的方法，调试走起，可以知道是SimpleExecutor的实例，如下图：后面的SimpleExecutor如何打断点就不再说了，自己尝试找找。StatementHandler很熟悉的一个接口，在学JDBC的时候就接触过类似的，执行语句和设置参数的作用。这个接口很简单，大佬写的代码，看到方法名就知道这个方法是干什么的，如下图：最重要的实现类是什么？当然是PreparedStatementHandler，因此在对应的方法上打上断点即可。ParameterHandler这个接口很简单，也别选择了，总共两个方法，一个设置，一个获取，在实现类DefaultParameterHandler中对应的方法上打上断点即可。TypeHandler类型处理器，也是一个简单的接口，总共’两个’方法，一个设置参数的转换，一个对结果的转换，啥也别说了，自己找到对应参数类型的处理器，在其中的方法打上断点。ResultSetHandler结果处理器，负责对结果的处理，总共三个方法，一个实现类DefaultResultSetHandler，全部安排断点。总结授人以鱼不授人以渔，与其都分析了给你看，不如教会你阅读源码的方式，先自己去研究，不仅仅是阅读Mybatis的源码是这样，阅读任何框架的源码都是如此，比如Spring的源码，只要找到其中重要的组件，比如前置处理器，后置处理器，事件触发器等等，一切都迎刃而解。如果你觉得作者写的不错，有所收获，不妨关注分享一波，后续更多精彩内容更新。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Mybatis源码阅读之六剑客]]></title>
      <url>%2F2020%2F04%2F20%2FMybatis%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E4%B9%8B%E5%85%AD%E5%89%91%E5%AE%A2%2F</url>
      <content type="text"><![CDATA[持续原创输出，点击上方蓝字关注我吧 目录 前言环境版本Mybatis的六剑客SqlSession有何方法语句执行方法立即批量更新方法事务控制方法本地缓存方法获取映射方法有何实现类？Executor实现类BaseExecutorCachingExecutorSimpleExecutorBatchExecutorReuseExecutorSpringBoot中如何创建？StatementHandler实现类SimpleStatementHandlerPreparedStatementHandlerCallableStatementHandlerRoutingStatementHandlerParameterHandlerTypeHandlerResultSetHandler总结前言Mybatis的专题文章写到这里已经是第四篇了，前三篇讲了Mybatis的基本使用，相信只要认真看了的朋友，在实际开发中正常使用应该不是问题。没有看过的朋友，作者建议去看一看，三篇文章分别是Mybatis入门之基本操作、Mybatis结果映射，你射准了吗？、Mybatis动态SQL，你真的会了吗？。当然，任何一个技术都不能浅藏辄止，今天作者就带大家深入底层源码看一看Mybatis的基础架构。此篇文章只是源码的入门篇，讲一些Mybatis中重要的组件，作者称之为六剑客。环境版本本篇文章讲的一切内容都是基于Mybatis3.5和SpringBoot-2.3.3.RELEASE。Myabtis的六剑客其实Mybatis的底层源码和Spring比起来还是非常容易读懂的，作者将其中六个重要的接口抽离出来称之为Mybatis的六剑客，分别是SqlSession、Executor、StatementHandler、ParameterHandler、ResultSetHandler、TypeHandler。六剑客在Mybatis中分别承担着什么角色？下面将会逐一介绍。介绍六剑客之前，先来一张六剑客执行的流程图，如下：SqlSessionSqlSession是Myabtis中的核心API，主要用来执行命令，获取映射，管理事务。它包含了所有执行语句、提交或回滚事务以及获取映射器实例的方法。有何方法其中定义了将近20个方法，其中涉及的到语句执行，事务提交回滚等方法。下面对于这些方法进行分类总结。语句执行方法这些方法被用来执行定义在 SQL 映射 XML 文件中的 SELECT、INSERT、UPDATE 和 DELETE 语句。你可以通过名字快速了解它们的作用，每一方法都接受语句的 ID 以及参数对象，参数可以是原始类型（支持自动装箱或包装类）、JavaBean、POJO 或 Map。&lt;T&gt; T selectOne(String statement, Object parameter)&lt;E&gt; List&lt;E&gt; selectList(String statement, Object parameter)&lt;T&gt; Cursor&lt;T&gt; selectCursor(String statement, Object parameter)&lt;K,V&gt; Map&lt;K,V&gt; selectMap(String statement, Object parameter, String mapKey)int insert(String statement, Object parameter)int update(String statement, Object parameter)int delete(String statement, Object parameter)其中的最容易误解的就是selectOne和selectList，从方法名称就很容易知道区别，一个是查询单个，一个是查询多个。如果你对自己的SQL无法确定返回一个还是多个结果的时候，建议使用selectList。insert，update，delete方法返值是受影响的行数。select还有几个重用的方法，用于限制返回行数，在Mysql中对应的就是limit，如下：&lt;E&gt; List&lt;E&gt; selectList (String statement, Object parameter, RowBounds rowBounds)&lt;T&gt; Cursor&lt;T&gt; selectCursor(String statement, Object parameter, RowBounds rowBounds)&lt;K,V&gt; Map&lt;K,V&gt; selectMap(String statement, Object parameter, String mapKey, RowBounds rowbounds)void select (String statement, Object parameter, ResultHandler&lt;T&gt; handler)void select (String statement, Object parameter, RowBounds rowBounds, ResultHandler&lt;T&gt; handler)其中的RowBounds参数中保存了限制的行数，起始行数。立即批量更新方法当你将 ExecutorType 设置为 ExecutorType.BATCH 时，可以使用这个方法清除（执行）缓存在 JDBC 驱动类中的批量更新语句。List&lt;BatchResult&gt; flushStatements()事务控制方法有四个方法用来控制事务作用域。当然，如果你已经设置了自动提交或你使用了外部事务管理器，这些方法就没什么作用了。然而，如果你正在使用由 Connection 实例控制的 JDBC 事务管理器，那么这四个方法就会派上用场：void commit()void commit(boolean force)void rollback()void rollback(boolean force)默认情况下 MyBatis 不会自动提交事务，除非它侦测到调用了插入、更新或删除方法改变了数据库。如果你没有使用这些方法提交修改，那么你可以在commit 和 rollback 方法参数中传入 true 值，来保证事务被正常提交（注意，在自动提交模式或者使用了外部事务管理器的情况下，设置 force 值对 session 无效）。大部分情况下你无需调用 rollback()，因为 MyBatis 会在你没有调用 commit 时替你完成回滚操作。不过，当你要在一个可能多次提交或回滚的 session 中详细控制事务，回滚操作就派上用场了。本地缓存方法Mybatis 使用到了两种缓存：本地缓存（local cache）和二级缓存（second level cache）。默认情况下，本地缓存数据的生命周期等同于整个 session 的周期。由于缓存会被用来解决循环引用问题和加快重复嵌套查询的速度，所以无法将其完全禁用。但是你可以通过设置 localCacheScope=STATEMENT 来只在语句执行时使用缓存。可以调用以下方法清除本地缓存。void clearCache()获取映射器在SqlSession中你也可以获取自己的映射器，直接使用下面的方法，如下：&lt;T&gt; T getMapper(Class&lt;T&gt; type)比如你需要获取一个UserMapper，如下：UserMapper mapper = sqlSessionTemplate.getMapper(UserMapper.class);有何实现类在Mybatis中有三个实现类，分别是DefaultSqlSession，SqlSessionManager、SqlSessionTemplate，其中重要的就是DefaultSqlSession，这个后面讲到Mybatis执行源码的时候会一一分析。在与SpringBoot整合时，Mybatis的启动器配置类会默认注入一个SqlSessionTemplate，源码如下：@Bean @ConditionalOnMissingBean public SqlSessionTemplate sqlSessionTemplate(SqlSessionFactory sqlSessionFactory) //根据执行器的类型创建不同的执行器，默认CachingExecutor ExecutorType executorType = this.properties.getExecutorType(); if (executorType != null) { return new SqlSessionTemplate(sqlSessionFactory, executorType); } else { return new SqlSessionTemplate(sqlSessionFactory); } }ExecutorMybatis的执行器，是Mybatis的调度核心，负责SQL语句的生成和缓存的维护，SqlSession中的crud方法实际上都是调用执行器中的对应方法执行。继承结构如下图：实现类下面我们来看看都有哪些实现类，分别有什么作用。BaseExecutor这是一个抽象类，采用模板方法的模式，有意思的是这个老弟模仿Spring的方式，真正的执行的方法都是doxxx()。其中有一个方法值得注意，查询的时候走的一级缓存，因此这里注意下，既然这是个模板类，那么Mybatis执行select的时候默认都会走一级缓存。代码如下：private &lt;E&gt; List&lt;E&gt; queryFromDatabase(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException { List&lt;E&gt; list; //此处的localCache即是一级缓存，是一个Map的结构 localCache.putObject(key, EXECUTION_PLACEHOLDER); try { //执行真正的查询 list = doQuery(ms, parameter, rowBounds, resultHandler, boundSql); } finally { localCache.removeObject(key); } localCache.putObject(key, list); if (ms.getStatementType() == StatementType.CALLABLE) { localOutputParameterCache.putObject(key, parameter); } return list; }CachingExecutor这个比较有名了，二级缓存的维护类，与SpringBoot整合默认创建的就是这个家伙。下面来看一下如何走的二级缓存，源码如下：@Override public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException { //查看当前Sql是否使用了二级缓存 Cache cache = ms.getCache(); //使用缓存了，直接从缓存中取 if (cache != null) { flushCacheIfRequired(ms); if (ms.isUseCache() &amp;&amp; resultHandler == null) { ensureNoOutParams(ms, boundSql); @SuppressWarnings(“unchecked”) //从缓存中取数据 List&lt;E&gt; list = (List&lt;E&gt;) tcm.getObject(cache, key); if (list == null) { //没取到数据，则执行SQL从数据库查询 list = delegate.query(ms, parameterObject, rowBounds, resultHandler, key, boundSql); //查到了，放入缓存中 tcm.putObject(cache, key, list); // issue #578 and #116 } //直接返回 return list; } } //没使用二级缓存，直接执行SQL从数据库查询 return delegate.query(ms, parameterObject, rowBounds, resultHandler, key, boundSql); }这玩意就是走个二级缓存，其他没什么。SimpleExecutor这个类像个直男，最简单的一个执行器，就是根据对应的SQL执行，不会做一些额外的操作。BatchExecutor通过批量操作来优化性能。通常需要注意的是批量更新操作，由于内部有缓存的实现，使用完成后记得调用flushStatements来清除缓存。ReuseExecutor可重用的执行器，重用的对象是Statement，也就是说该执行器会缓存同一个sql的Statement，省去Statement的重新创建，优化性能。内部的实现是通过一个HashMap来维护Statement对象的。由于当前Map只在该session中有效，所以使用完成后记得调用flushStatements来清除Map。SpringBoot中如何创建在SpringBoot到底创建的是哪个执行器呢？其实只要阅读一下源码可以很清楚的知道，答案就在org.apache.ibatis.session.Configuration类中，其中创建执行器的源码如下：public Executor newExecutor(Transaction transaction, ExecutorType executorType) { //没有指定执行器的类型，创建默认的，即是SimpleExecutor executorType = executorType == null ? defaultExecutorType : executorType; executorType = executorType == null ? ExecutorType.SIMPLE : executorType; Executor executor; //类型是BATCH，创建BatchExecutor if (ExecutorType.BATCH == executorType) { executor = new BatchExecutor(this, transaction); //类型为REUSE，创建ReuseExecutor } else if (ExecutorType.REUSE == executorType) { executor = new ReuseExecutor(this, transaction); } else { //除了上面两种，创建的都是SimpleExecutor executor = new SimpleExecutor(this, transaction); } //如果全局配置了二级缓存，则创建CachingExecutor，SpringBoot中这个参数默认是true，可以自己设置为false if (cacheEnabled) { //创建CachingExecutor executor = new CachingExecutor(executor); } executor = (Executor) interceptorChain.pluginAll(executor); return executor; }显而易见，SpringBoot中默认创建的是CachingExecutor，因为默认的cacheEnabled的值为true。StatementHandler熟悉JDBC的朋友应该都能猜到这个接口是干嘛的，很显然，这个是对SQL语句进行处理和参数赋值的。实现类该接口也是有很多的实现类，如下图：SimpleStatementHandler这个很简单了，就是对应我们JDBC中常用的Statement接口，用于简单SQL的处理PreparedStatementHandler这个对应JDBC中的PreparedStatement，预编译SQL的接口。CallableStatementHandler这个对应JDBC中CallableStatement，用于执行存储过程相关的接口。RoutingStatementHandler这个接口是以上三个接口的路由，没有实际操作，只是负责上面三个StatementHandler的创建及调用。ParameterHandlerParameterHandler在Mybatis中负责将sql中的占位符替换为真正的参数，它是一个接口，有且只有一个实现类DefaultParameterHandler。setParameters是处理参数最核心的方法。这里不再详细的讲，后面会讲到。TypeHandler这位大神应该都听说过，也都自定义过吧，简单的说就是在预编译设置参数和取出结果的时候将Java类型和JDBC的类型进行相应的转换。当然，Mybatis内置了很多默认的类型处理器，基本够用，除非有特殊的定制，我们才会去自定义，比如需要将Java对象以JSON字符串的形式存入数据库，此时就可以自定义一个类型处理器。很简单的东西，此处就不再详细的讲了，后面会单独出一篇如何自定义类型处理器的文章。ResultSetHandler结果处理器，负责将JDBC返回的ResultSet结果集对象转换成List类型的集合或者Cursor。具体实现类就是DefaultResultSetHandler，其实现的步骤就是将Statement执行后的结果集，按照Mapper文件中配置的ResultType或ResultMap来封装成对应的对象，最后将封装的对象返回。源码及其复杂，尤其是其中对嵌套查询的解析，这里只做个了解，后续会专门写一篇文章介绍。总结至此，Mybatis源码第一篇就已经讲完了，本篇文章对Mybatis中的重要组件做了初步的了解，为后面更深入的源码阅读做了铺垫，如果觉得作者写的不错，在看分享一波，谢谢支持。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Mybatis的几种传参方式，你了解吗？]]></title>
      <url>%2F2020%2F04%2F20%2FMybatis%E7%9A%84%E5%87%A0%E7%A7%8D%E4%BC%A0%E5%8F%82%E6%96%B9%E5%BC%8F%EF%BC%8C%E4%BD%A0%E4%BA%86%E8%A7%A3%E5%90%97%EF%BC%9F%2F</url>
      <content type="text"><![CDATA[持续原创输出，点击上方蓝字关注我 目录 前言单个参数多个参数使用索引【不推荐】使用@Param使用MapPOJO【推荐】List传参数组传参总结前言前几天恰好面试一个应届生，问了一个很简单的问题：你了解过Mybatis中有几种传参方式吗？没想到其他问题回答的很好，唯独这个问题一知半解，勉强回答了其中两种方式。于是这篇文章就来说一说Mybatis传参的几种常见方式，给正在面试或者准备面试的朋友巩固一下。单个参数单个参数的传参比较简单，可以是任意形式的，比如#{a}、#{b}或者#{param1}，但是为了开发规范，尽量使用和入参时一样。Mapper如下：UserInfo selectByUserId(String userId);XML如下：&lt;select id=“selectByUserId” resultType=“cn.cb.demo.domain.UserInfo”&gt; select from user_info where user_id=#{userId} and status=1 &lt;/select&gt;多个参数多个参数的情况下有很多种传参的方式，下面一一介绍。使用索引【不推荐】多个参数可以使用类似于索引的方式传值，比如#{param1}对应第一个参数，#{param2}对应第二个参数…….Mapper方法如下：UserInfo selectByUserIdAndStatus(String userId,Integer status);XML如下：&lt;select id=“selectByUserIdAndStatus” resultType=“cn.cb.demo.domain.UserInfo”&gt; select from user_info where user_id=#{param1} and status=#{param2} &lt;/select&gt;注意：由于开发规范，此种方式不推荐开发中使用。使用@Param@Param这个注解用于指定key，一旦指定了key，在SQL中即可对应的key入参。Mapper方法如下：UserInfo selectByUserIdAndStatus(@Param(“userId”) String userId,@Param(“status”) Integer status);XML如下：&lt;select id=“selectByUserIdAndStatus” resultType=“cn.cb.demo.domain.UserInfo”&gt; select from user_info where user_id=#{userId} and status=#{status} &lt;/select&gt;使用MapMybatis底层就是将入参转换成Map，入参传Map当然也行，此时#{key}中的key就对应Map中的key。Mapper中的方法如下：UserInfo selectByUserIdAndStatusMap(Map&lt;String,Object&gt; map);XML如下：&lt;select id=“selectByUserIdAndStatusMap” resultType=“cn.cb.demo.domain.UserInfo”&gt; select from user_info where user_id=#{userId} and status=#{status} &lt;/select&gt;测试如下：@Test void contextLoads() { Map&lt;String,Object&gt; map=new HashMap&lt;&gt;(); map.put(“userId”,“1222”); map.put(“status”,1); UserInfo userInfo = userMapper.selectByUserIdAndStatusMap(map); System.out.println(userInfo); }POJO【推荐】多个参数可以使用实体类封装，此时对应的key就是属性名称，注意一定要有get方法。Mapper方法如下：UserInfo selectByEntity(UserInfoReq userInfoReq);XML如下：&lt;select id=“selectByEntity” resultType=“cn.cb.demo.domain.UserInfo”&gt; select from user_info where user_id=#{userId} and status=#{status} &lt;/select&gt;实体类如下：@Datapublic class UserInfoReq { private String userId; private Integer status;}List传参List传参也是比较常见的，通常是SQL中的in。Mapper方法如下：List&lt;UserInfo&gt; selectList( List&lt;String&gt; userIds);XML如下：&lt;select id=“selectList” resultMap=“userResultMap”&gt; select from user_info where status=1 and user_id in &lt;foreach collection=“list” item=“item” open=“(“ separator=“,” close=“)” &gt; #{item} &lt;/foreach&gt; &lt;/select&gt;数组传参这种方式类似List传参，依旧使用foreach语法。Mapper方法如下：List&lt;UserInfo&gt; selectList( String[] userIds);XML如下：&lt;select id=“selectList” resultMap=“userResultMap”&gt; select * from user_info where status=1 and user_id in &lt;foreach collection=“array” item=“item” open=“(“ separator=“,” close=“)” &gt; #{item} &lt;/foreach&gt; &lt;/select&gt;总结以上几种传参的方式在面试或者工作中都会用到，不了解的朋友可以收藏下。Mybatis专题文章写到这里也算是到了尾声，后期准备再写写Mybatis的面经，如果觉得作者写的不错，欢迎关注分享。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Mybatis.动态SQL，你真的会了吗？]]></title>
      <url>%2F2020%2F04%2F20%2FMybatis.%E5%8A%A8%E6%80%81SQL%EF%BC%8C%E4%BD%A0%E7%9C%9F%E7%9A%84%E4%BC%9A%E4%BA%86%E5%90%97%EF%BC%9F%2F</url>
      <content type="text"><![CDATA[持续原创输出，点击上方蓝字关注我吧 作者：不才陈某独立博客：https://chenjiabing666.github.io 目录 前言什么是动态SQL？常用的标签ifchoose、when、otherwisewhereforeachsetsqlinclude总结拓展一下Mybatis中如何避免魔数？如何引用其他XML中的SQL片段？总结前言通过前两篇的文章我们了解了Mybatis基本的CRUD操作、一些基本标签的属性以及如何映射结果，感兴趣的可以看我的前两篇文章，分别是Mybatis入门之基础操作和Mybatis结果映射，你射准了吗？，如果有什么疑问的地方可以在文章下方留言，作者统一回复。这篇文章就来聊一聊Mybatis的动态SQL，在实际的开发中Mybatis的这项功能是非常重要的，至于什么是动态SQL？如何实现动态SQL？下面文章将会详细介绍。什么是动态SQL？动态 SQL 是 MyBatis 的强大特性之一。顾名思义，就是会动的SQL，即是能够灵活的根据某种条件拼接出完整的SQL语句。这种类似于MySQL中的case when then else then end….这种语法，能够根据某种条件动态的拼接出需要的SQL。至于Mybatis如何实现动态SQL呢，Mybatis提供了非常多的标签，能够让我们在XML文件中灵活的运用这些标签达到拼接SQL的目的。常用的标签Mybatis为了能够让开发者灵活的写SQL也是费了一番功夫，定义了很多的标签和语法，下面将会一一介绍。if虽然英文不太好，但是在这么简单的不会不知道是如果的意思吧，Java语法中也有，只有判断条件为true才会执行其中的SQL语句。举个栗子：HIS系统中医护人员需要根据特定条件筛选患者，比如住院号，床位，性别等。当然这些条件并不是必填的，具体的功能截图如下:以上截图中的条件筛选并不是必填的，因此我们不能在SQL中固定，要根据前端是否传值来判断是否需要加上这个条件。那么此时查询语句如何写呢？如下：&lt;select id =‘selectPats’ resultType=‘com.xxx.domain.PatientInfo’&gt; select from patient_info where status=1 &lt;!–前端传来的住院号不为null，表示需要根据住院号筛选，此时Where语句就需要加上这个条件–&gt; &lt;if test=“iptNum!=null”&gt; and ipt_num=#{iptNum} &lt;/if&gt; &lt;!–床位号筛选–&gt; &lt;if test=“bedNum!=null”&gt; and bed_num=#{bedNum} &lt;/if&gt;&lt;/select&gt;&lt;if&gt;标签中的属性test用来指定判断条件，那么问题来了，上面的例子中的test中判断条件都是一个条件，如果此时变成两个或者多个条件呢？和SQL的语法类似，and连接即可，如下： &lt;if test=“bedNum!=null and bedNum!=’’ “&gt; and bed_num=#{bedNum} &lt;/if&gt;choose、when、otherwise有时候，我们不想使用所有的条件，而只是想从多个条件中选择一个使用。针对这种情况，MyBatis 提供了 choose 元素，它有点像 Java 中的 switch 语句。还是上面的例子改变一下：此时只能满足一个筛选条件，如果前端传来住院号就只按照住院号查找，如果传来床位号就只按照床位号筛选，如果什么都没传，就筛选所有在院的。此时的查询如下：&lt;select id=“selectPats” resultType=“com.xxx.domain.PatientInfo”&gt; select from patient_info where 1=1 &lt;choose&gt; &lt;!–住院号不为null时，根据住院号查找–&gt; &lt;when test=“iptNum != null”&gt; AND ipt_num=#{iptNum} &lt;/when&gt; &lt;!–床位号不是NUll–&gt; &lt;when test=“bedNum != null”&gt; AND bed_num = #{bedNum} &lt;/when&gt; &lt;otherwise&gt; AND status=1 &lt;/otherwise&gt; &lt;/choose&gt;&lt;/select&gt;MyBatis 提供了 choose 元素，按顺序判断 when 中的条件出否成立，如果有一个成立，则 choose 结束。当 choose 中所有 when 的条件都不满则时，则执行 otherwise 中的 sql。类似于 Java 的 switch 语句，choose 为 switch，when 为 case，otherwise 则为default。where举个栗子：对于choose标签的例子中的查询，如果去掉where后的1=1此时的SQL语句会变成什么样子，有三种可能的SQL，如下：select from patient_info where AND ipt_num=#{iptNum};select from patient_info where AND bed_num = #{bedNum};select from patient_info where AND status=1;发生了什么，以上三条SQL语句对吗？很显然是不对的，显然where后面多了个AND。如何解决呢？此时就要用到where这个标签了。where 元素只会在子元素返回任何内容的情况下才插入 WHERE 子句。而且，若子句的开头为 AND 或 OR，where 元素也会将它们去除。此时的查询改造如下：&lt;select id=“selectPats” resultType=“com.xxx.domain.PatientInfo”&gt; select from patient_info &lt;where&gt; &lt;choose&gt; &lt;!–住院号不为null时，根据住院号查找–&gt; &lt;when test=“iptNum != null”&gt; AND ipt_num=#{iptNum} &lt;/when&gt; &lt;!–床位号不是NUll–&gt; &lt;when test=“bedNum != null”&gt; AND bed_num = #{bedNum} &lt;/when&gt; &lt;otherwise&gt; AND status=1 &lt;/otherwise&gt; &lt;/choose&gt; &lt;/where&gt;&lt;/select&gt;foreachforeach是用来对集合的遍历，这个和Java中的功能很类似。通常处理SQL中的in语句。foreach 元素的功能非常强大，它允许你指定一个集合，声明可以在元素体内使用的集合项（item）和索引（index）变量。它也允许你指定开头与结尾的字符串以及集合项迭代之间的分隔符。这个元素也不会错误地添加多余的分隔符你可以将任何可迭代对象（如 List、Set 等）、Map 对象或者数组对象作为集合参数传递给 foreach。当使用可迭代对象或者数组时，index 是当前迭代的序号，item 的值是本次迭代获取到的元素。当使用 Map 对象（或者 Map.Entry 对象的集合）时，index 是键，item 是值。例子如下：&lt;select id=“selectPats” resultType=“com.xxx.domain.PatientInfo”&gt; SELECT * FROM patient_info WHERE ID in &lt;foreach item=“item” index=“index” collection=“list” open=“(“ separator=“,” close=“)”&gt; #{item} &lt;/foreach&gt;&lt;/select&gt;改标签中的各个属性的含义如下：属性含义item表示在迭代过程中每一个元素的别名index表示在迭代过程中每次迭代到的位置（下标）open前缀close后缀separator分隔符，表示迭代时每个元素之间以什么分隔set讲这个标签之前，先看下面这个例子：&lt;update id=“updateStudent” parameterType=“Object”&gt; UPDATE STUDENT SET NAME = #{name}, MAJOR = #{major}, HOBBY = #{hobby} WHERE ID = #{id};&lt;/update&gt;&lt;update id=“updateStudent” parameterType=“Object”&gt; UPDATE STUDENT SET &lt;if test=“name!=null and name!=’’ “&gt; NAME = #{name}, &lt;/if&gt; &lt;if test=“hobby!=null and hobby!=’’ “&gt; MAJOR = #{major}, &lt;/if&gt; &lt;if test=“hobby!=null and hobby!=’’ “&gt; HOBBY = #{hobby} &lt;/if&gt; WHERE ID = #{id};&lt;/update&gt;上面的例子中没有使用 if 标签时，如果有一个参数为 null，都会导致错误。当在 update 语句中使用 if 标签时，如果最后的 if 没有执行，则或导致逗号多余错误。使用 set 标签可以将动态的配置 set 关键字，和剔除追加到条件末尾的任何不相关的逗号。使用 set+if 标签修改后，如果某项为 null 则不进行更新，而是保持数据库原值。此时的查询如下：&lt;update id=“updateStudent” parameterType=“Object”&gt; UPDATE STUDENT &lt;set&gt; &lt;if test=“name!=null and name!=’’ “&gt; NAME = #{name}, &lt;/if&gt; &lt;if test=“hobby!=null and hobby!=’’ “&gt; MAJOR = #{major}, &lt;/if&gt; &lt;if test=“hobby!=null and hobby!=’’ “&gt; HOBBY = #{hobby} &lt;/if&gt; &lt;/set&gt; WHERE ID = #{id};&lt;/update&gt;sql在实际开发中会遇到许多相同的SQL，比如根据某个条件筛选，这个筛选很多地方都能用到，我们可以将其抽取出来成为一个公用的部分，这样修改也方便，一旦出现了错误，只需要改这一处便能处处生效了，此时就用到了&lt;sql&gt;这个标签了。当多种类型的查询语句的查询字段或者查询条件相同时，可以将其定义为常量，方便调用。为求 &lt;select&gt; 结构清晰也可将 sql 语句分解。如下：&lt;!– 查询字段 –&gt;&lt;sql id=“Base_Column_List”&gt; ID,MAJOR,BIRTHDAY,AGE,NAME,HOBBY&lt;/sql&gt;&lt;!– 查询条件 –&gt;&lt;sql id=“Example_Where_Clause”&gt; where 1=1 &lt;trim suffixOverrides=“,”&gt; &lt;if test=“id != null and id !=’’”&gt; and id = #{id} &lt;/if&gt; &lt;if test=“major != null and major != ‘’”&gt; and MAJOR = #{major} &lt;/if&gt; &lt;if test=“birthday != null “&gt; and BIRTHDAY = #{birthday} &lt;/if&gt; &lt;if test=“age != null “&gt; and AGE = #{age} &lt;/if&gt; &lt;if test=“name != null and name != ‘’”&gt; and NAME = #{name} &lt;/if&gt; &lt;if test=“hobby != null and hobby != ‘’”&gt; and HOBBY = #{hobby} &lt;/if&gt; &lt;/trim&gt;&lt;/sql&gt;include这个标签和&lt;sql&gt;是天仙配，是共生的，include用于引用sql标签定义的常量。比如引用上面sql标签定义的常量，如下：&lt;select id=“selectAll” resultMap=“BaseResultMap”&gt; SELECT &lt;include refid=“Base_Column_List” /&gt; FROM student &lt;include refid=“Example_Where_Clause” /&gt;&lt;/select&gt;refid这个属性就是指定&lt;sql&gt;标签中的id值（唯一标识）。总结至此，Mybatis动态SQL中常用的标签就已经介绍完了，这部分的内容在实际工作中是必须会用到的，除非你们公司不用Mybatis。拓展一下前面介绍了动态SQL的一些标签以及属性，相信看完之后应该能够灵活的应用了，但是在实际开发中还是有一些奇技淫巧的，陈某今天简单的讲几个。Mybatis中如何避免魔数开过阿里巴巴开发手册的大概都知道代码中是不允许出现魔数的，何为魔数？简单的说就是一个数字，一个只有你知道，别人不知道这个代表什么意思的数字。通常我们在Java代码中都会定义一个常量类专门定义这些数字。比如获取医生和护士的权限，但是医生和护士的权限都不相同，在这条SQL中肯定需要根据登录的类型type来区分，比如type=1是医生，type=2是护士，估计一般人会这样写：&lt;if test=“type!=null and type==1”&gt; – ….获取医生的权限&lt;/if&gt;&lt;if test=“type!=null and type==2”&gt; – ….获取护士的权限&lt;/if&gt;这样写也没什么错，但是一旦这个type代表的含义变了，那你是不是涉及到的SQL都要改一遍。开发中通常定义一个常量类，如下：package com.xxx.core.Constants;public class CommonConstants{ //医生 public final static int DOC_TYPE=1; //护士 public final static int NUR_TYPE=2;}那么此时的SQL应该如何写呢？如下：&lt;if test=“type!=null and type==@com.xxx.core.Constants.CommonConstants@DOC_TYPE”&gt; – ….获取医生的权限&lt;/if&gt;&lt;if test=“type!=null and type==@com.xxx.core.Constants.CommonConstants@NUR_TYPE”&gt; – ….获取护士的权限&lt;/if&gt;就是这么简单，就是@+全类名+@+常量。除了调用常量类中的常量，还可以类中的方法，很少用到，不再介绍了，感兴趣的可以问下度娘。如何引用其他XML中的SQL片段实际开发中你可能遇到一个问题，比如这个resultMap或者这个&lt;sql&gt;片段已经在另外一个xxxMapper.xml中已经定义过了，此时当前的xml还需要用到，难不成我复制一份？小白什么也不问上来就复制了，好吧，后期修改来了，每个地方都需要修改了。难受不？其实Mybatis中也是支持引用其他Mapper文件中的SQL片段的。其实很简单，比如你在com.xxx.dao.xxMapper这个Mapper的XML中定义了一个SQL片段如下：&lt;sql id=“Base_Column_List”&gt; ID,MAJOR,BIRTHDAY,AGE,NAME,HOBBY&lt;/sql&gt;此时我在com.xxx.dao.PatinetMapper中的XML文件中需要引用，如下： &lt;include refid=“com.xxx.dao.xxMapper.Base_Column_List”&gt;&lt;/include&gt;如此简单，类似于Java中的全类名。&lt;select&gt;标签中的resultMap同样可以这么引用，和上面引用的方式一样，不再赘述了。总结好了，Myabtis的动态SQL的内容已经介绍完了，你会了吗？每日来看看，下面会有更多精彩的内容！！！如果 觉得写的不错的，点点在看，关注一波不迷路，每天都会有精彩内容分享。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Mybatis入门之结果映射]]></title>
      <url>%2F2020%2F04%2F20%2FMybatis%E5%85%A5%E9%97%A8%E4%B9%8B%E7%BB%93%E6%9E%9C%E6%98%A0%E5%B0%84%2F</url>
      <content type="text"><![CDATA[持续原创输出，点击上方蓝字关注我吧 目录 前言什么是结果映射？如何映射？别名映射驼峰映射配置文件开启驼峰映射配置类中开启驼峰映射resultMap映射总结高级结果映射关联(association)例子关联的嵌套 Select 查询关联的嵌套结果映射总结集合collection集合的嵌套 Select 查询集合的嵌套结果映射总结前言上一篇文章介绍了Mybatis基础的CRUD操作、常用的标签、属性等内容，如果对部分不熟悉的朋友可以看Mybatis入门之基本操作。本篇文章继续讲解Mybatis的结果映射的内容，想要在企业开发中灵活的使用Mybatis，这部分的内容是必须要精通的。什么是结果映射？简单的来说就是一条SQL查询语句返回的字段如何与Java实体类中的属性相对应。如下一条SQL语句，查询患者的用户id，科室id，主治医生id： &lt;select id=‘selectPatientInfos’ resultType=‘com.xxx.domain.PatientInfo’&gt; select user_id,dept_id,doc_id from patient_info; &lt;/select&gt;Java实体类PatientInfo如下：@Datapublic class PatientInfo{ private String userId; private String deptId; private String docId;}程序员写这条SQL的目的就是想查询出来的user_id,dept_id,doc_id分别赋值给实体类中的userId,deptId,docId。这就是简单的结果映射。如何映射？Myabtis中的结果映射有很多种方式，下面会逐一介绍。别名映射这个简单，保持查询的SQL返回的字段和Java实体类一样即可，比如上面例子的SQL可以写成：&lt;select id=‘selectPatientInfos’ resultType=‘com.xxx.domain.PatientInfo’&gt; select user_id as userId, dept_id as deptId, doc_id as docId from patient_info;&lt;/select&gt;这样就能和实体类中的属性映射成功了。驼峰映射Mybatis提供了驼峰命名映射的方式，比如数据库中的user_id这个字段，能够自动映射到userId属性。那么此时的查询的SQL变成如下即可：&lt;select id=‘selectPatientInfos’ resultType=‘com.xxx.domain.PatientInfo’&gt; select user_id,dept_id,doc_id from patient_info; &lt;/select&gt;如何开启呢？与SpringBoot整合后开启其实很简单，有两种方式，一个是配置文件中开启，一个是配置类开启。配置文件开启驼峰映射只需要在application.properties文件中添加如下一行代码即可：mybatis.configuration.map-underscore-to-camel-case=true配置类中开启驼峰映射【简单了解，后续源码章节着重介绍】这种方式需要你对源码有一定的了解，上一篇入门教程中有提到，Mybatis与Springboot整合后适配了一个starter，那么肯定会有自动配置类，Mybatis的自动配置类是MybatisAutoConfiguration，其中有这么一段代码，如下：@ConditionalOnMissingBean这个注解的意思就是当IOC容器中没有SqlSessionFactory这个Bean对象这个配置才会生效;applyConfiguration(factory)这行代码就是创建一个org.apache.ibatis.session.Configuration赋值给SqlSessionFactoryBean。源码分析到这，应该很清楚了，无非就是自己在容器中创建一个SqlSessionFactory，然后设置属性即可，如下代码： @Bean(“sqlSessionFactory”) public SqlSessionFactory sqlSessionFactory(DataSource dataSource) throws Exception { SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean(); //设置数据源 sqlSessionFactoryBean.setDataSource(dataSource); //设置xml文件的位置 sqlSessionFactoryBean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(MAPPER_LOCATOIN)); //创建Configuration org.apache.ibatis.session.Configuration configuration = new org.apache.ibatis.session.Configuration(); // 开启驼峰命名映射 configuration.setMapUnderscoreToCamelCase(true); configuration.setDefaultFetchSize(100); configuration.setDefaultStatementTimeout(30); sqlSessionFactoryBean.setConfiguration(configuration); //将typehandler注册到mybatis sqlSessionFactoryBean.setTypeHandlers(typeHandlers()); return sqlSessionFactoryBean.getObject(); }注意：如果对SqlSessionFactory没有特殊定制，不介意重写，因为这会自动覆盖自动配置类中的配置。resultMap映射什么是resultMap？简单的说就是一个类似Map的结构，将数据库中的字段和JavaBean中的属性字段对应起来，这样就能做到一一映射了。上述的例子使用resultMap又会怎么写呢？如下：&lt;!–创建一个resultMap映射–&gt;&lt;resultMap id=“patResultMap” type=“com.xxx.domain.PatientInfo”&gt; &lt;id property=“userId” column=“user_id” /&gt; &lt;result property=“docId” column=“doc_id”/&gt; &lt;result property=“deptId” column=“dept_id”/&gt;&lt;/resultMap&gt;&lt;!–使用resultMap映射结果到com.xxx.domain.PatientInfo这个Bean中–&gt;&lt;select id=‘selectPatientInfos’ resultMap=‘patResultMap’&gt; select user_id,dept_id,doc_id from patient_info; &lt;/select&gt;其实很简单，就是创建一个&lt;resultMap&gt;，然后&lt;select&gt;标签指定这个resultMap即可。&lt;resultMap&gt;的属性如下：id：唯一标识这个resultMap，同一个Mapper.xml中不能重复type：指定JavaBean的类型，可以是全类名，也可以是别名子标签&lt;result&gt;的属性如下：column：SQL返回的字段名称property：JavaBean中属性的名称javaType：一个 Java 类的全限定名，或一个类型别名（关于内置的类型别名，可以参考上面的表格）。 如果你映射到一个 JavaBean，MyBatis 通常可以推断类型。然而，如果你映射到的是 HashMap，那么你应该明确地指定 javaType 来保证行为与期望的相一致。jdbcType：JDBC 类型，所支持的 JDBC 类型参见这个表格之后的“支持的 JDBC 类型”。 只需要在可能执行插入、更新和删除的且允许空值的列上指定 JDBC 类型。这是 JDBC 的要求而非 MyBatis 的要求。如果你直接面向 JDBC 编程，你需要对可以为空值的列指定这个类型。typeHandler： 这个属性值是一个类型处理器实现类的全限定名，或者是类型别名。resultMap：结果映射的 ID，可以将此关联的嵌套结果集映射到一个合适的对象树中。 它可以作为使用额外 select 语句的替代方案。总结以上列举了三种映射的方式，分别是别名映射，驼峰映射、resultMap映射。你以为这就结束了？要是世界这么简单多好，做梦吧，哈哈！！！高级结果映射MyBatis 创建时的一个思想是：数据库不可能永远是你所想或所需的那个样子。 我们希望每个数据库都具备良好的第三范式或 BCNF 范式，可惜它们并不都是那样。 如果能有一种数据库映射模式，完美适配所有的应用程序，那就太好了，但可惜也没有。 而 ResultMap 就是 MyBatis 对这个问题的答案。我们知道在数据库的关系中一对一，多对一，一对多，多对多的关系，那么这种关系如何在Mybatis中体现并映射成功呢？关联(association)关联（association）元素处理有一个类型的关系。 比如，在我们的示例中，一个员工属于一个部门。关联结果映射和其它类型的映射工作方式差不多。 你需要指定目标属性名以及属性的javaType（很多时候 MyBatis 可以自己推断出来），在必要的情况下你还可以设置 JDBC 类型，如果你想覆盖获取结果值的过程，还可以设置类型处理器。关联的不同之处是，你需要告诉 MyBatis 如何加载关联。MyBatis 有两种不同的方式加载关联：嵌套 Select 查询：通过执行另外一个 SQL 映射语句来加载期望的复杂类型。嵌套结果映射：使用嵌套的结果映射来处理连接结果的重复子集。首先，先让我们来看看这个元素的属性。你将会发现，和普通的结果映射相比，它只在 select 和 resultMap 属性上有所不同。property： 映射到列结果的字段或属性。如果用来匹配的 JavaBean 存在给定名字的属性，那么它将会被使用。javaType：一个 Java 类的完全限定名，或一个类型别名（关于内置的类型别名，可以参考上面的表格）jdbcType： JDBC 类型， 只需要在可能执行插入、更新和删除的且允许空值的列上指定 JDBC 类型typeHandler：使用这个属性，你可以覆盖默认的类型处理器。 这个属性值是一个类型处理器实现类的完全限定名，或者是类型别名。column： 数据库中的列名，或者是列的别名。一般情况下，这和传递给 resultSet.getString(columnName) 方法的参数一样。 注意：在使用复合主键的时候，你可以使用 column=”{prop1=col1,prop2=col2}” 这样的语法来指定多个传递给嵌套 Select 查询语句的列名。这会使得prop1和 prop2 作为参数对象，被设置为对应嵌套 Select 语句的参数。select：用于加载复杂类型属性的映射语句的 ID，它会从 column 属性指定的列中检索数据，作为参数传递给目标 select 语句。 具体请参考下面的例子。注意：在使用复合主键的时候，你可以使用column=”{prop1=col1,prop2=col2}” 这样的语法来指定多个传递给嵌套 Select 查询语句的列名。这会使得 prop1 和 prop2 作为参数对象，被设置为对应嵌套 Select 语句的参数。fetchType：可选的。有效值为 lazy 和 eager。 指定属性后，将在映射中忽略全局配置参数 lazyLoadingEnabled，使用属性的值。例子一对一的关系比如：一个员工属于一个部门，那么数据库表就会在员工表中加一个部门的id作为逻辑外键。创建员工JavaBean@Datapublic class User { private Integer id; private String username; private String password; private Integer age; private Integer deptId; //部门 private Department department;}部门JavaBean@Datapublic class Department { private Integer id; private String name;}那么我们想要查询所有的用户信息和其所在的部门信息，此时的sql语句为:select from user u left join department d on u.department_id=d.id;。但是我们在mybaits中如果使用这条语句查询，那么返回的结果类型是什么呢？如果是User类型的，那么查询结果返回的还有Department类型的数据，那么肯定会对应不上的。此时&lt;resultMap&gt;来了，它来了!!!关联的嵌套 Select 查询【可以忽略】查询员工和所在的部门在Mybatis如何写呢？代码如下：&lt;resultMap id=“userResult” type=“com.xxx.domain.User”&gt; &lt;id column=“id” property=“id”/&gt; &lt;result column=“password” property=“password”/&gt; &lt;result column=“age” property=“age”/&gt; &lt;result column=“username” property=“username”/&gt; &lt;result column=“dept_id” property=“deptId”/&gt; &lt;!–关联查询，select嵌套查询–&gt; &lt;association property=“department” column=“dept_id” javaType=“com.xxx.domain.Department” select=“selectDept”/&gt;&lt;/resultMap&gt;&lt;!–查询员工–&gt;&lt;select id=“selectUser” resultMap=“userResult”&gt; SELECT FROM user WHERE id = #{id}&lt;/select&gt;&lt;!–查询部门–&gt;&lt;select id=“selectDept” resultType=“com.xxx.domain.Department “&gt; SELECT FROM department WHERE ID = #{id}&lt;/select&gt;就是这么简单，两个select语句，一个用来加载员工，一个用来加载部门。这种方式虽然很简单，但在大型数据集或大型数据表上表现不佳。这个问题被称为N+1 查询问题。 概括地讲，N+1 查询问题是这样子的：你执行了一个单独的 SQL 语句来获取结果的一个列表（就是+1）。对列表返回的每条记录，你执行一个 select 查询语句来为每条记录加载详细信息（就是N）。这个问题会导致成百上千的 SQL 语句被执行。有时候，我们不希望产生这样的后果。关联的嵌套结果映射【重点】&lt;association &gt;标签中还可以直接嵌套结果映射，此时的Mybatis的查询如下：&lt;!– 定义resultMap –&gt;&lt;resultMap id=“UserDepartment” type=“com.xxx.domain.User” &gt; &lt;id column=“user_id” property=“id”/&gt; &lt;result column=“password” property=“password”/&gt; &lt;result column=“age” property=“age”/&gt; &lt;result column=“username” property=“username”/&gt; &lt;result column=“dept_id” property=“deptId”/&gt; &lt;!– property: 指定User中对应的部门属性名称 javaType: 指定类型，可以是全类名或者别名 –&gt; &lt;association property=“department” javaType=“com.xx.domain.Department”&gt; &lt;!–指定Department中的属性映射，这里也可以使用单独拎出来，然后使用association中的resultMap属性指定–&gt; &lt;id column=“id” property=“id”/&gt; &lt;result column=“dept_name” property=“name”/&gt; &lt;/association&gt;&lt;/resultMap&gt;&lt;!– resultMap: 指定上面resultMap的id的值 –&gt; &lt;select id=“findUserAndDepartment” resultMap=“UserDepartment”&gt; select u.id as user_id, u.dept_id, u.name, u.password, u.age, d.id, d.name as dept_name from user u left join department d on u.department_id=d.id &lt;/select&gt;总结至此有一个类型的关联已经完成了，学会一个&lt;association&gt;使用即能完成。注意： 关联的嵌套 Select 查询不建议使用，N+1是个重大问题，虽说Mybatis提供了延迟加载的功能，但是仍然不建议使用，企业开发中也是不常用的。集合collection集合，顾名思义，就是处理有很多个类型的关联。其中的属性和association中的属性类似，不再重复了。比如这样一个例子：查询一个部门中的全部员工，查询SQL如何写呢？如下：select from department d left join user u on u.department_id=d.id;此时的User实体类如下：@Datapublic class User { private Integer id; private String username; private String password; private Integer age; private Integer deptId;}此时的Department实体类如下：@Datapublic class Department { private Integer id; private String name; private List&lt;User&gt; users;}和association类似，同样有两种方式，我们可以使用嵌套 Select 查询，或基于连接的嵌套结果映射集合。集合的嵌套 Select 查询【可以忽略】不太重要，查询如下：&lt;resultMap id=“deptResult” type=“com.xxx.domain.Department”&gt; &lt;!–指定Department中的属性映射，这里也可以使用单独拎出来，然后使用association中的resultMap属性指定–&gt; &lt;id column=“id” property=“id”/&gt; &lt;result column=“name” property=“name”/&gt; &lt;!– ofType：指定实际的JavaBean的全类型或者别名 select：指定嵌套的select查询 javaType：集合的类型，可以不写，Mybatis可以推测出来–&gt; &lt;collection property=“users” javaType=“java.util.ArrayList” column=“id” ofType=“com.xxx.doamin.User” select=“selectByDeptId”/&gt;&lt;/resultMap&gt;&lt;select id=“selectDept” resultMap=“deptResult”&gt; SELECT FROM department WHERE ID = #{id}&lt;/select&gt;&lt;select id=“selectByDeptId” resultType=“com.xxx.domain.User”&gt; SELECT FROM user WHERE dept_id = #{id}&lt;/select&gt;注意：这里出现了一个不同于association的属性ofType，这个属性非常重要，它用来将 JavaBean（或字段）属性的类型和集合存储的类型区分开来。集合的嵌套结果映射【重点】现在你可能已经猜到了集合的嵌套结果映射是怎样工作的——除了新增的 ofType 属性，它和关联的完全相同。此时的Mybatis查询如下：&lt;!–部门的resultMap–&gt;&lt;resultMap id=“deptResult” type=“com.xxx.domain.Department”&gt; &lt;!–指定Department中的属性映射，这里也可以使用单独拎出来，然后使用association中的resultMap属性指定–&gt; &lt;id column=“dept_id” property=“id”/&gt; &lt;result column=“dept_name” property=“name”/&gt; &lt;!– ofType：指定实际的JavaBean的全类型或者别名 resultMap：指定员工的resultMap–&gt; &lt;collection property=“users” ofType=“com.xxx.doamin.User” resultMap=‘userResult’/&gt;&lt;/resultMap&gt;&lt;!–员工的resultMap–&gt;&lt;resultMap id=“userResult” type=“com.xxx.domain.User”&gt; &lt;id column=“user_id” property=“id”/&gt; &lt;result column=“password” property=“password”/&gt; &lt;result column=“age” property=“age”/&gt; &lt;result column=“username” property=“username”/&gt;&lt;/resultMap&gt;&lt;select id=“selectDeptById” resultType=“com.xxx.domain.Department”&gt; select d.id as dept_id, d.name as dept_name, u.id as user_id, u.password, u.name from department d left join user u on u.department_id=d.id where d.id=#{id}&lt;/select&gt;总结至此Mybatis第二弹之结果映射已经写完了，如果觉得作者写的不错，给个在看关注一波，后续还有更多精彩内容推出。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[吐血总结：MySQL性能如何优化？]]></title>
      <url>%2F2020%2F04%2F20%2F%E5%90%90%E8%A1%80%E6%80%BB%E7%BB%93%EF%BC%9AMySQL%E6%80%A7%E8%83%BD%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96%EF%BC%9F%2F</url>
      <content type="text"><![CDATA[前言上篇讲了MySQL的索引优化，此篇文章从大范围讲一下MySQL数据库到底该如何优化？这个问题在面试中时常被问到，今天陈某来总结下。SQL 优化的几个步骤1. 通过show status 命令了解各种 SQL 的执行效率show [session | global] status;可以根据需要加上参数来显示session级（当前连接，默认）和global级（自数据库上次启动至今）的统计结果。show status like ‘Com_%’; —显示当前连接所有统计参数的值。Com_xxx表示每个xxx语句执行的次数，通常需要注意的是下面几个参数：Com_select/Com_insert/Com_update/Com_delete。2. 定位执行效率较低的 SQL 语句通过show processlist命令实时查看当前 SQL 的执行情况；通过慢查询日志定位出现的问题。3. 通过explain 或 desc分析低效 SQL 的执行计划可以参考上篇文章Mysql 探索之 Explain 执行计划详解4. 通过show profile 分析 SQL。show profile 能帮我们了解时间都耗费到哪里去了。通过show profiles我们能够更清楚了解 SQL 执行的过程；5. 通过trace分析优化器如何选择执行计划MySQL5.6提供了对 SQL 的跟踪trace,能帮我们了解为什么优化器选择执行 A 计划而不是 B 计划，进一步理解优化器的行为。6. 确定问题并采取相应的优化措施。MySQL 常用的 SQL 语句优化方法应尽量避免在 where 子句中使用!=或&lt;&gt;操作符，否则将引擎放弃使用索引而进行全表扫描。对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。应尽量避免在where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描。如：select id from t where num is null可以在 num 上设置默认值 0，确保表中 num 列没有 null 值，然后这样查询：select id from t where num=0避免在where子句中使用or来连接条件，如果一个字段有索引，一个字段没有索引，将导致引擎放弃使用索引而进行全表扫描。前导模糊查询将导致全表扫描 select id from t where name like ‘%c%’下面使用索引select id from t where name like ‘c%’not in 也要慎用，否则会导致全表扫描；对于连续的数值，能用between 就不要用 in 了，尽量使用exists代替in。如果在 where 子句中使用参数，也会导致全表扫描。因为 SQL 只有在运行时才会解析局部变量，但优化程序不能将访问计划的选择推迟到运行时；它必须在编译时进行选择。然而，如果在编译时建立访问计划，变量的值还是未知的，因而无法作为索引选择的输入项。如下面语句将进行全表扫描： select id from t where num=@num可以改为强制查询使用索引： select id from t with(index(索引名)) where num=@num应尽量避免在 where 子句中对字段进行表达式与函数或其他表达式运算操作，这将导致引擎放弃使用索引而进行全表扫描。如：select id from t where num/2=100，应改为：select id from t where num=1002select id from t where substring(name,1,3)=’abc’;name以abc开头的id,应改为：select id from t where name like ‘abc%’select id from t where datediff(day,createdate,’2005-11-30’)=0 –’2005-11-30′生成的 id,应改为：select id from t where createdate&gt;=’2005-11-30′ and createdate&lt;’2005-12-01’Update 语句，如果只更改 1、2 个字段，不要 Update 全部字段，否则频繁调用会引起明显的性能消耗，同时带来大量日志。在使用索引字段作为条件时，如果该索引是复合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使用，并且应尽可能的让字段顺序与索引顺序相一致。并不是所有索引对查询都有效，SQL 是根据表中数据来进行查询优化的，当索引列有大量数据重复时，SQL 查询可能不会去利用索引。如一表中有字段 sex，male、female 几乎各一半，那么即使在 sex 上建了索引也对查询效率起不了作用。索引并不是越多越好，索引固然可以提高相应的 select 的效率，但同时也降低了 insert 及 update 的效率，因为 insert 或 update 时有可能会重建索引。一个表的索引数较好不要超过 6 个。应尽可能的避免更新 clustered 索引数据列，因为 clustered 索引数据列的顺序就是表记录的物理存储顺序，一旦该列值改变将导致整个表记录的顺序的调整，会耗费相当大的资源。尽量使用数字型字段，若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。这是因为引擎在处理查询和连接时会逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了。任何地方都不要使用 select from t ，用具体的字段列表代替，不要返回用不到的任何字段。对于多张大数据量（这里几百条就算大了）的表JOIN，要先分页再JOIN，否则逻辑读会很高，性能很差。尽量使用表变量来代替临时表。考虑使用临时表暂存中间结果。临时表并不是不可使用，适当地使用它们可以使某些查询更有效，例如，当需要重复引用大型表或常用表中的某个数据集时。将临时结果暂存在临时表，后面的查询就在tempdb中查询了，这可以避免程序中多次扫描主表，也大大减少了程序执行中共享锁阻塞更新锁，减少了阻塞，提高了并发性能。但是，对于一次性事件，较好使用导出表。在新建临时表时，如果一次性插入数据量很大，那么可以使用 select into 代替 create table，避免造成大量 log ，以提高速度；如果数据量不大，为了缓和系统表的资源，应先create table，然后insert。如果使用到了临时表，在存储过程的最后务必将所有的临时表显式删除，先 truncate table ，然后 drop table ，这样可以避免系统表的较长时间锁定。避免频繁创建和删除临时表，以减少系统表资源的消耗。尽量避免使用游标，因为游标的效率较差。与临时表一样，游标并不是不可使用。对小型数据集使用 FAST_FORWARD 游标通常要优于其他逐行处理方法，尤其是在必须引用几个表才能获得所需的数据时。在结果集中包括“合计”的例程通常要比使用游标执行的速度快。在所有的存储过程和触发器的开始处设置 SET NOCOUNT ON ，在结束时设置 SET NOCOUNT OFF 。尽量避免向客户端返回大数据量。尽量避免大事务操作，提高系统并发能力。用where子句替换Having子句避免使用 having 子句，having 只会在检索出所有记录之后才会对结果集进行过滤，这个处理需要排序，如果能通过 where 子句限制记录的数目，就可以减少这方面的开销。on、where、having 这三个都可以加条件的子句，on 是最先执行，where 次之，having 最后。使用 Truncate 替代 delete当需要删除全表的记录时使用Truncate替代delete。在通常情况下, 回滚段(rollback segments ) 用来存放可以被恢复的信息. 如果你没有COMMIT事务,ORACLE 会将数据恢复到删除之前的状态(准确地说是恢复到执行删除命令之前的状况) 而当运用 TRUNCATE 时, 回滚段不再存放任何可被恢复的信息.当命令运行后,数据不能被恢复.因此很少的资源被调用,执行时间也会很短。使用表的别名:当在 SQL 语句中连接多个表时, 请使用表的别名并把别名前缀于每个 Column 上.这样一来,就可以减少解析的时间并减少那些由 Column 歧义引起的语法错误。使用union all 替换 union当 SQL 语句需要union两个查询结果集合时，这两个结果集合会以 union all 的方式被合并，然后再输出最终结果前进行排序。如果用 union all 替代料 union，这样排序就不是不要了，效率就会因此得到提高. 需要注意的是，UNION ALL 将重复输出两个结果集合中相同记录。用 where 替代 order by：ORDER BY 子句只在两种严格的条件下使用索引：①ORDER BY中所有的列必须包含在相同的索引中并保持在索引中的排列顺序；②ORDER BY中所有的列必须定义为非空；低效: (索引不被使用)SELECT DEPT_CODE FROM DEPT ORDER BY DEPT_TYPE高效: (使用索引)SELECT DEPT_CODE FROM DEPT WHERE DEPT_TYPE &gt; 0避免索引列的类型转换：假设 EMP_TYPE 是一个字符类型的索引列.SELECT … FROM EMP WHERE EMP_TYPE = 123这个语句被转换为:SELECT … FROM EMP WHERE EMP_TYPE=’123’;因为内部发生的类型转换, 这个索引将不会被用到! 为了避免 ORACLE 对你的 SQL 进行隐式的类型转换, 最好把类型转换用显式表现出来. 注意当字符和数值比较时, ORACLE 会优先转换数值类型到字符类型。优化 Group by提高GROUP BY 语句的效率, 可以通过将不需要的记录在GROUP BY 之前过滤掉。下面两个查询返回相同结果但第二个明显就快了许多。低效:SELECT JOB , AVG(SAL) FROM EMP GROUP by JOB HAVING JOB = ‘PRESIDENT’ OR JOB = ‘MANAGER’高效:SELECT JOB , AVG(SAL) FROM EMP WHERE JOB = ‘PRESIDENT’ OR JOB = ‘MANAGER’ GROUP by JOB避免使用耗费资源的操作：带有DISTINCT,UNION,MINUS,INTERSECT,ORDER BY的 SQL 语句会启动 SQL 引擎执行耗费资源的排序(SORT)功能. DISTINCT需要一次排序操作, 而其他的至少需要执行两次排序. 通常, 带有UNION, MINUS , INTERSECT的 SQL 语句都可以用其他方式重写. 如果你的数据库的 SORT_AREA_SIZE 调配得好, 使用 UNION , MINUS, INTERSECT 也是可以考虑的, 毕竟它们的可读性很强。在运行代码中，尽量使用PreparedStatement来查询，不要用Statement。MySQL 常用的索引优化方法关于索引的优化，前面的文章已经详细的讲了二十条铁则，感兴趣的可以看一文带你搞懂索引如何优化！MySQL 数据库的优化目标、常见误区和基本原则优化目标MySQL 数据库是常见的两个瓶颈是 CPU 和 I/O 的瓶颈，CPU 在饱和的时候一般发生在数据装入内存或从磁盘上读取数据时候。磁盘 I/O 瓶颈发生在装入数据远大于内存容量的时候。减少 I/O 次数：I/O 永远是数据库最容易瓶颈的地方，这是由数据库的职责所决定的，大部分数据库操作中超过 90%的时间都是 IO 操作所占用的，减少 IO 次数是 SQL 优化中需要第一优先考虑，当然，也是收效最明显的优化手段。降低 CPU 计算：除了 IO 瓶颈之外，SQL 优化中需要考虑的就是 CPU 运算量的优化了。order by, group by,distinct … 都是消耗 CPU 的大户（这些操作基本上都是 CPU 处理内存中的数据比较运算）。当我们的 IO 优化做到一定阶段之后，降低 CPU 计算也就成为了我们 SQL 优化的重要目标。常见误区count(1)和count(primary_key) 优于 count():很多人为了统计记录条数，就使用 count(1) 和 count(primary_key) 而不是 count()，他们认为这样性能更好，其实这是一个误区。对于有些场景，这样做可能性能会更差，应为数据库对 count() 计数操作做了一些特别的优化。如在 MyISAM 引擎中，会对表的总行数进行记录，使用count（）可以直接取出该值。count(column) 和 count() 是一样的实际上，count(column) 和 count() 是一个完全不一样的操作，所代表的意义也完全不一样。count(column) 是表示结果集中有多少个column字段不为空的记录，只处理非空值。count() 是表示整个结果集有多少条记录，不会跳过null值。select a,b from …比 select a,b,c from …可以让数据库访问更少的数据量实际上，大多数关系型数据库都是按照行（row）的方式存储，而数据存取操作都是以一个固定大小的 IO 单元（被称作 block 或者 page）为单位，一般为 4KB，8KB… 大多数时候，每个 IO 单元中存储了多行，每行都是存储了该行的所有字段（lob 等特殊类型字段除外）。所以，我们是取一个字段还是多个字段，实际上数据库在表中需要访问的数据量其实是一样的。当然，也有例外情况，那就是我们的这个查询在索引中就可以完成，也就是说当只取 a,b 两个字段的时候，不需要回表，而 c 这个字段不在使用的索引中，需要回表取得其数据。在这样的情况下，二者的 IO 量会有较大差异。order by 一定需要排序操作我们知道索引数据实际上是有序的，如果我们的需要的数据和某个索引的顺序一致，而且我们的查询又通过这个索引来执行，那么数据库一般会省略排序操作，而直接将数据返回，因为数据库知道数据已经满足我们的排序需求了。实际上，利用索引来优化有排序需求的 SQL，是一个非常重要的优化手段。执行计划中有 filesort 就会进行磁盘文件排序有这个误区其实并不能怪我们，而是因为 MySQL 开发者在用词方面的问题。filesort 是我们在使用 explain 命令查看一条 SQL 的执行计划的时候可能会看到在 “Extra” 一列显示的信息。实际上，只要一条 SQL 语句需要进行排序操作，都会显示Using filesort，这并不表示就会有文件排序操作。基本原则尽量少 joinMySQL 的优势在于简单，但这在某些方面其实也是其劣势。MySQL 优化器效率高，但是由于其统计信息的量有限，优化器工作过程出现偏差的可能性也就更多。对于复杂的多表 Join，一方面由于其优化器受限，再者在 Join 这方面所下的功夫还不够，所以性能表现离 Oracle 等关系型数据库前辈还是有一定距离。但如果是简单的单表查询，这一差距就会极小甚至在有些场景下要优于这些数据库前辈。尽量少排序排序操作会消耗较多的 CPU 资源，所以减少排序可以在缓存命中率高等 IO 能力足够的场景下会较大影响 SQL 的响应时间。对于 MySQL 来说，减少排序有多种办法，比如：上面误区中提到的通过利用索引来排序的方式进行优化;减少参与排序的记录条数；非必要不对数据进行排序。尽量避免 select *很多人看到这一点后觉得比较难理解，上面不是在误区中刚刚说 select 子句中字段的多少并不会影响到读取的数据吗？是的，大多数时候并不会影响到 IO 量，但是当我们还存在 order by 操作的时候，select 子句中的字段多少会在很大程度上影响到我们的排序效率，此外，上面误区中不是也说了，只是大多数时候是不会影响到 IO 量，当我们的查询结果仅仅只需要在索引中就能找到的时候，还是会极大减少 IO 量的。尽量用 join 代替子查询虽然 Join 性能并不佳，但是和 MySQL 的子查询比起来还是有非常大的性能优势。尽量少 or当 where 子句中存在多个条件以“或”并存的时候，MySQL 的优化器并没有很好的解决其执行计划优化问题，再加上 MySQL 特有的 SQL 与 Storage 分层架构方式，造成了其性能比较低下，很多时候使用 union all 或者是union（必要的时候）的方式来代替or会得到更好的效果。尽量用 union all 代替 unionunion 和 union all 的差异主要是前者需要将两个（或者多个）结果集合并后再进行唯一性过滤操作，这就会涉及到排序，增加大量的 CPU 运算，加大资源消耗及延迟。所以当我们可以确认不可能出现重复结果集或者不在乎重复结果集的时候，尽量使用 union all 而不是 union。尽量早过滤这一优化策略其实最常见于索引的优化设计中（将过滤性更好的字段放得更靠前）。在 SQL 编写中同样可以使用这一原则来优化一些 Join 的 SQL。比如我们在多个表进行分页数据查询的时候，我们最好是能够在一个表上先过滤好数据分好页，然后再用分好页的结果集与另外的表 Join，这样可以尽可能多的减少不必要的 IO 操作，大大节省 IO 操作所消耗的时间。避免类型转换这里所说的“类型转换”是指 where 子句中出现 column 字段的类型和传入的参数类型不一致的时候发生的类型转换优先优化高并发的 SQL，而不是执行频率低某些“大”SQL对于破坏性来说，高并发的 SQL 总是会比低频率的来得大，因为高并发的 SQL 一旦出现问题，甚至不会给我们任何喘息的机会就会将系统压跨。而对于一些虽然需要消耗大量 IO 而且响应很慢的 SQL，由于频率低，即使遇到，最多就是让整个系统响应慢一点，但至少可能撑一会儿，让我们有缓冲的机会。从全局出发优化，而不是片面调整SQL 优化不能是单独针对某一个进行，而应充分考虑系统中所有的 SQL，尤其是在通过调整索引优化 SQL 的执行计划的时候，千万不能顾此失彼，因小失大。尽可能对每一条运行在数据库中的 SQL 进行 explain优化 SQL，需要做到心中有数，知道 SQL 的执行计划才能判断是否有优化余地，才能判断是否存在执行计划问题。在对数据库中运行的 SQL 进行了一段时间的优化之后，很明显的问题 SQL 可能已经很少了，大多都需要去发掘，这时候就需要进行大量的 explain 操作收集执行计划，并判断是否需要进行优化。MySQL 数据库的表结构优化由于 MySQL 数据库是基于行（Row）存储的数据库，而数据库操作 IO 的时候是以 page（block）的方式，也就是说，如果我们每条记录所占用的空间量减小，就会使每个 page 中可存放的数据行数增大，那么每次 IO 可访问的行数也就增多了。反过来说，处理相同行数的数据，需要访问的 page 就会减少，也就是 IO 操作次数降低，直接提升性能。此外，由于我们的内存是有限的，增加每个 page 中存放的数据行数，就等于增加每个内存块的缓存数据量，同时还会提升内存换中数据命中的几率，也就是缓存命中率。数据类型选择数据库操作中最为耗时的操作就是 IO 处理，大部分数据库操作 90% 以上的时间都花在了 IO 读写上面。所以尽可能减少 IO 读写量，可以在很大程度上提高数据库操作的性能。我们无法改变数据库中需要存储的数据，但是我们可以在这些数据的存储方式方面花一些心思。下面的这些关于字段类型的优化建议主要适用于记录条数较多，数据量较大的场景，因为精细化的数据类型设置可能带来维护成本的提高，过度优化也可能会带来其他的问题：数字类型：非万不得已不要使用DOUBLE，不仅仅只是存储长度的问题，同时还会存在精确性的问题。同样，固定精度的小数，也不建议使用DECIMAL，建议乘以固定倍数转换成整数存储，可以大大节省存储空间，且不会带来任何附加维护成本。对于整数的存储，在数据量较大的情况下，建议区分开 TINYINT / INT / BIGINT 的选择，因为三者所占用的存储空间也有很大的差别，能确定不会使用负数的字段，建议添加 unsigned 定义。当然，如果数据量较小的数据库，也可以不用严格区分三个整数类型。int类型只增主键字段=&gt;4 字节=&gt;每个字节 8 位=&gt;32 位，在 CPU 加载一条指令的时候，4 字节是和 CPU 寄存器的运算有关，如：64 位，由于之前的系统一般都是 32 位的，所以在运算 4 字节的数据是刚好的，效率最高，而现今我们系统基本都是 64 位的时候，其实没有更好的利用好 CPU 运算，所以在设计表字段建议，使用 8 字节的主键bigint，而不是直接使用 int 来做主键。字符类型：非万不得已不要使用 TEXT 数据类型，其处理方式决定了他的性能要低于 char 或者是 varchar 类型的处理。定长字段，建议使用 CHAR 类型，不定长字段尽量使用 VARCHAR，且仅仅设定适当的最大长度，而不是非常随意的给一个很大的最大长度限定，因为不同的长度范围，MySQL 也会有不一样的存储处理。`char(10)`` 不管该字段是否存储数据，都占 10 个字符的存储空间，char(10) 同时存在一个坑，就是存储 abc 数据后改数据库字段的值为“abc 7 个空格 ”，在精准查询（where）就必须带上后面的 7 个空格。varchar 不存的时候不占空间，存多长数据就占多少空间。时间类型：尽量使用TIMESTAMP类型，因为其存储空间只需要 DATETIME 类型的一半。对于只需要精确到某一天的数据类型，建议使用 DATE 类型，因为他的存储空间只需要 3 个字节，比 TIMESTAMP 还少。不建议通过 INT 类型类存储一个 unix timestamp 的值，因为这太不直观，会给维护带来不必要的麻烦，同时还不会带来任何好处。ENUM &amp; SET：对于状态字段，可以尝试使用 ENUM 来存放，因为可以极大的降低存储空间，而且即使需要增加新的类型，只要增加于末尾，修改结构也不需要重建表数据。如果是存放可预先定义的属性数据呢？可以尝试使用 SET 类型，即使存在多种属性，同样可以游刃有余，同时还可以节省不小的存储空间。LOB类型：强烈反对在数据库中存放 LOB 类型数据，虽然数据库提供了这样的功能，但这不是他所擅长的，我们更应该让合适的工具做他擅长的事情，才能将其发挥到极致。在数据库中存储 LOB 数据就像让一个多年前在学校学过一点 Java 的营销专业人员来写 Java 代码一样。字符编码：字符集直接决定了数据在 MySQL 中的存储编码方式，由于同样的内容使用不同字符集表示所占用的空间大小会有较大的差异，所以通过使用合适的字符集，可以帮助我们尽可能减少数据量，进而减少 IO 操作次数。① 纯拉丁字符能表示的内容，没必要选择 latin1 之外的其他字符编码，因为这会节省大量的存储空间；② 如果我们可以确定不需要存放多种语言，就没必要非得使用 UTF8 或者其他 UNICODE 字符类型，这回造成大量的存储空间浪费；③MySQL 的数据类型可以精确到字段，所以当我们需要大型数据库中存放多字节数据的时候，可以通过对不同表不同字段使用不同的数据类型来较大程度减小数据存储量，进而降低 IO 操作次数并提高缓存命中率。适当拆分：有些时候，我们可能会希望将一个完整的对象对应于一张数据库表，这对于应用程序开发来说是很有好的，但是有些时候可能会在性能上带来较大的问题。当我们的表中存在类似于 TEXT 或者是很大的 VARCHAR 类型的大字段的时候，如果我们大部分访问这张表的时候都不需要这个字段，我们就该义无反顾的将其拆分到另外的独立表中，以减少常用数据所占用的存储空间。这样做的一个明显好处就是每个数据块中可以存储的数据条数可以大大增加，既减少物理 IO 次数，也能大大提高内存中的缓存命中率。上面几点的优化都是为了减少每条记录的存储空间大小，让每个数据库中能够存储更多的记录条数，以达到减少 IO 操作次数，提高缓存命中率。下面这个优化建议可能很多开发人员都会觉得不太理解，因为这是典型的反范式设计，而且也和上面的几点优化建议的目标相违背。适度冗余：为什么我们要冗余？这不是增加了每条数据的大小，减少了每个数据块可存放记录条数吗？确实，这样做是会增大每条记录的大小，降低每条记录中可存放数据的条数，但是在有些场景下我们仍然还是不得不这样做：① 被频繁引用且只能通过 Join 2 张（或者更多）大表的方式才能得到的独立小字段：这样的场景由于每次 Join 仅仅只是为了取得某个小字段的值，Join 到的记录又大，会造成大量不必要的 IO，完全可以通过空间换取时间的方式来优化。不过，冗余的同时需要确保数据的一致性不会遭到破坏，确保更新的同时冗余字段也被更新。尽量使用 NOT NULL：NULL 类型比较特殊，SQL 难优化。虽然 MySQL NULL 类型和 Oracle 的 NULL 有差异，会进入索引中，但如果是一个组合索引，那么这个 NULL 类型的字段会极大影响整个索引的效率。很多人觉得 NULL 会节省一些空间，所以尽量让 NULL 来达到节省 IO 的目的，但是大部分时候这会适得其反，虽然空间上可能确实有一定节省，倒是带来了很多其他的优化问题，不但没有将 IO 量省下来，反而加大了 SQL 的 IO 量。所以尽量确保 DEFAULT 值不是 NULL，也是一个很好的表结构设计优化习惯。MySQL 数据库的缓存参数优化用处不大，忽略总结数据库最常用的优化方式有：SQL 语句和索引、数据库表结构、系统配置、硬件。优化效果：SQL 语句和索引 &gt; 数据库表结构 &gt; 系统配置 &gt; 硬件，但成本从低到高。数据库的优化方法小结：设计符合范式的数据库选择合适的存储引擎SQL 语句优化索引优化：高分离字段建立索引SQL 表结构、字段优化数据库参数优化：IO 参数、CPU 参数分库分表：垂直切分与水平切分分区：将表的数据按照特定的规则放在不同的分区，提高磁盘的 IO 效率，提高数据库的性能主从复制与读写分离：三个主要线程与 bin-log 文件、relay_log 文件，主数据库负责写操作，从数据库负责读操作负载均衡数据库集群硬件更多文章欢迎关注微信公众号【码猿技术专栏】; line-height: 1.75em; margin-top: 20px !important;”&gt;本文使用 mdnice 排版]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Mybatis入门之基本操作！！！]]></title>
      <url>%2F2020%2F04%2F20%2FMybatis%E5%85%A5%E9%97%A8%E4%B9%8B%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%EF%BC%81%EF%BC%81%EF%BC%81%2F</url>
      <content type="text"><![CDATA[前言作为一个资深后端码农天天都要和数据库打交道，最早使用的是 Hiberate，一个封装性极强的持久性框架。自从接触到 Mybatis 就被它的灵活性所折服了，可以自己写 SQL，虽然轻量级，但是麻雀虽小，五脏俱全。这篇文章就来讲讲什么是 Mybatis，如何简单的使用 Mybatis。什么是 MybatisMyBatis 是一款优秀的持久层框架，它支持自定义 SQL、存储过程以及高级映射。MyBatis 免除了几乎所有的 JDBC 代码以及设置参数和获取结果集的工作。MyBatis 可以通过简单的 XML 或注解来配置和映射原始类型、接口和 Java POJO（Plain Old Java Objects，普通老式 Java 对象）为数据库中的记录。环境搭建本篇文章使用的环境是SpringBoot+Mybatis+MysqlMaven 依赖MySQL 驱动依赖和 Druid 连接池的依赖 &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.40&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;!–druid连接池–&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.9&lt;/version&gt; &lt;/dependency&gt;Mybatis 启动包依赖，此处导入的是 SpringBoot 和 Mybatis 整合启动器的依赖，点击去可以看到，这个启动包依赖了mybatis和mybatis-spring（Mybatis 和 Spring 整合的 Jar 包），因此使用 SpringBoot 之后只需要导入这个启动器的依赖即可。 &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt; &lt;/dependency&gt;以上两个依赖添加成功后，Maven 环境就已经配置完了。数据库连接池配置（Druid）这个不是本文的重点，而且网上很多教程，我就简单的配置一下，在 SpringBoot 的application.properties中配置即可。##单一数据源spring.datasource.url=jdbc\:mysql\://127.0.0.1\:3306/vivachekcloud_pzhdermyy?useUnicode\=true&amp;characterEncoding\=UTF-8&amp;zeroDateTimeBehavior\=convertToNull&amp;useSSL\=falsespring.datasource.username=rootspring.datasource.password=123456spring.datasource.type=com.alibaba.druid.pool.DruidDataSourcespring.datasource.driver-class-name=com.mysql.jdbc.Driver#初始化连接大小spring.datasource.druid.initial-size=0#连接池最大使用连接数量spring.datasource.druid.max-active=20#连接池最小空闲spring.datasource.druid.min-idle=0#获取连接最大等待时间spring.datasource.druid.max-wait=6000spring.datasource.druid.validation-query=SELECT 1#spring.datasource.druid.validation-query-timeout=6000spring.datasource.druid.test-on-borrow=falsespring.datasource.druid.test-on-return=falsespring.datasource.druid.test-while-idle=true#配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒spring.datasource.druid.time-between-eviction-runs-millis=60000#置一个连接在池中最小生存的时间，单位是毫秒spring.datasource.druid.min-evictable-idle-time-millis=25200000#spring.datasource.druid.max-evictable-idle-time-millis=#打开removeAbandoned功能,多少时间内必须关闭连接spring.datasource.druid.removeAbandoned=true#1800秒，也就是30分钟spring.datasource.druid.remove-abandoned-timeout=1800#&lt;!– 1800秒，也就是30分钟 –&gt;spring.datasource.druid.log-abandoned=truespring.datasource.druid.filters=mergeStat#spring.datasource.druid.verifyServerCertificate#spring.datasource.filters=stat,wall,log4j# 通过connectProperties属性来打开mergeSql功能；慢SQL记录spring.datasource.connectionProperties=druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000基础概念dao层：用于存放和数据库交互的文件，Mybatis 的interface都放在此层service层：用于存放业务逻辑的文件。配置 xml 文件存放的位置Mybatis 中xml的文件默认是要和interface放在一个包下的，并且文件的名称要一样。在和 SpringBoot 整合后有两种配置方式，下面详细介绍。application.properties 中设置既然是和 SpringBoot 整合，那么万变不离xxxAutoConfiguration这个配置类了，Mybatis 的配置类就是MybatisAutoConfiguration，如下：@org.springframework.context.annotation.Configuration@ConditionalOnClass({ SqlSessionFactory.class, SqlSessionFactoryBean.class })@ConditionalOnSingleCandidate(DataSource.class)@EnableConfigurationProperties(MybatisProperties.class)@AutoConfigureAfter(DataSourceAutoConfiguration.class)public class MybatisAutoConfiguration implements InitializingBean {}可以看到@EnableConfigurationProperties(MybatisProperties.class)这行代码，就是将 properties 中的属性映射到 MybatisProperties 这个成员属性中，因此设置的方式就要看其中的属性。public class MybatisProperties { //前缀 public static final String MYBATIS_PREFIX = “mybatis”; / Mybatis配置文件的位置 / private String configLocation; / Mybatis的Mapper的xml文件的位置 / private String[] mapperLocations;因此设置的方式很简单，如下：## xml文件放置在/src/main/resource/mapper/文件夹下mybatis.mapper-locations=classpath:/mapper/**/.xml配置类中设置不是本章重点，后面在讲 Mybatis 和 SpringBoot 整合的文章会涉及到该内容。配置扫描 Mybatis 的 interface在和 SpringBoot 整合后，扫描 Mybatis 的接口，生成代理对象是一件很简单的事，只需要一个注解即可。@Mapper该注解标注在 Mybatis 的interface类上，SpringBoot 启动之后会扫描后会自动生成代理对象。实例如下：@Mapperpublic interface UserInfoMapper { int insert(UserInfo record); int insertSelective(UserInfo record); }缺点：每个interface都要标注一个，很鸡肋，一个项目中的 interface 少说也有上百个吧。@MapperScan@Mapper注解的升级版，标注在配置类上，用于一键扫描 Mybatis 的interface。使用也是很简单的，直接指定接口所在的包即可，如下：@MapperScan({“com.xxx.dao”})public class ApiApplication {}@MapperScan和@Mapper这两个注解千万不要重复使用。优点：一键扫描，不用每个 interface 配置。基本的 crud既然和数据库交互，避免不了 crud 操作，就安心做一个妥妥的crud boy吧。针对 Mybatis 其实有两套方法映射，一个是 XML 文件的方式，一个是注解的方式。但是今天只讲 XML 文件的方式，原因很简单，注解的方式企业不用，谁用谁倒霉，哈哈。查询查询语句是 MyBatis 中最常用的元素之一——光能把数据存到数据库中价值并不大，还要能重新取出来才有用，多数应用也都是查询比修改要频繁。 MyBatis 的基本原则之一是：在每个插入、更新或删除操作之间，通常会执行多个查询操作。因此，MyBatis 在查询和结果映射做了相当多的改进。一个简单查询的 select 元素是非常简单的。&lt;select id=“selectPersonById” parameterType=“int” resultType=“com.myjszl.domain.Person”&gt; SELECT name,age,id FROM PERSON WHERE ID = #{id}&lt;/select&gt;对应的interface的方法如下：Person selectPersonById(int id);&lt;select&gt;这个标签有很多属性，比较常用的属性如下：id（必填）：在命名空间中唯一的标识符，可以被用来引用这条语句。和interface中的方法名要一致。parameterType（可选）：将会传入这条语句的参数的类全限定名或别名。这个属性是可选的，因为 MyBatis 可以通过类型处理器（TypeHandler）推断出具体传入语句的参数，默认值为未设置（unset）。resultType：期望从这条语句中返回结果的类全限定名或别名。 注意，如果返回的是集合，那应该设置为集合包含的类型，而不是集合本身的类型。 resultType 和 resultMap 之间只能同时使用一个。resultMap：对外部 resultMap 的命名引用。结果映射是 MyBatis 最强大的特性，如果你对其理解透彻，许多复杂的映射问题都能迎刃而解。 resultType 和 resultMap 之间只能同时使用一个。变更数据变更语句 insert，update 和 delete 的实现非常接近。下面是 insert，update 和 delete 语句的示例：&lt;insert id=“insertAuthor”&gt; insert into Author (id,username,password,email,bio) values (#{id},#{username},#{password},#{email},#{bio})&lt;/insert&gt;&lt;update id=“updateAuthor”&gt; update Author set username = #{username}, password = #{password}, email = #{email}, bio = #{bio} where id = #{id}&lt;/update&gt;&lt;delete id=“deleteAuthor”&gt; delete from Author where id = #{id}&lt;/delete&gt;#{}和${}的区别上面的例子中我们可以看到使用的都是#{}，关于#{}和${}的区别也是在很多初级工程师的面试最常被问到的，现在只需要记住区别就是#{}使用了 JDBC 的预编译，可以防止 SQL 注入，提高了安全性，${}并没有预编译，安全性不够。在后面 Mybatis 的源码讲解中将会涉及到为什么一个用了预编译，一个没用。自增 ID 的返回关于 Mysql 的文章中有提到，设计一个表最好要有一个自增 ID，无论这个 ID 你是否用到，具体原因不在解释，可以翻看之前的文章。有了自增 ID，插入之后并不能自动返回，但是我们又需要这个 ID 值，那么如何返回呢？&lt;insert&gt;标签提供了两个属性用来解决这个问题，如下：useGeneratedKeys：设置为 true，表示使用自增主键返回keyProperty：指定返回的自增主键映射到parameterType的哪个属性中。假设插入Person，并且 person 表中的自增主键 id 需要返回，XML 文件如下：&lt;?xml version=”1.0” encoding=”UTF-8”?&gt;&lt;!DOCTYPE mapper PUBLIC “-//mybatis.org//DTD Mapper 3.0//EN” “http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&amp;gt;&lt;mapper namespace=“com.xxx.dao.PersonMapper”&gt; &lt;insert id=‘addPerson’ parameterType=‘com.xxx.domain.Person’ useGeneratedKeys=“true” keyProperty=“id” &gt; insert into person(name,age) values(#{name},#{age}); &lt;/insert&gt;&lt;/mapper&gt;SQL 代码片段这个元素可以用来定义可重用的 SQL 代码片段，以便在其它语句中使用。 参数可以静态地（在加载的时候）确定下来，并且可以在不同的 include 元素中定义不同的参数值。比如：&lt;sql id=“userColumns”&gt; ${alias}.id,${alias}.username,${alias}.password &lt;/sql&gt;这个 SQL 片段可以在其它语句中使用，例如：&lt;select id=“selectUsers” resultType=“map”&gt; select &lt;include refid=“userColumns”&gt;&lt;property name=“alias” value=“t1”/&gt;&lt;/include&gt;, &lt;include refid=“userColumns”&gt;&lt;property name=“alias” value=“t2”/&gt;&lt;/include&gt; from some_table t1 cross join sometable t2&lt;/select&gt;开启驼峰映射DBA 在设计数据库的时候，往往使用的是下划线()的方式，比如user_id。但是 Java 是不规范的，我们通常将它转换为userId，这就是驼峰命名方法。但是在使用 Mybatis 查询的时候，比如：&lt;select id=‘selectById’ resultType=‘com.xxx.doamin.User’&gt; select user_id from user_info&lt;/select&gt;上面的user_id和User中的userId根本不对应，也就映射不进去，此时查询的结果就是 userId 是 null，当然我们可以使用别名的方式，SQL 可以改写为select user_id as userId from user_info另外一种方式是不用别名，直接开启 Mybatis 的驼峰映射规则，会自动映射，开启的方式很简单，就是在application.properties文件配置一下，如下：mybatis.configuration.map-underscore-to-camel-case=true总结本文主要讲了 Mybatis 与 SpringBoot 的整合过程，基本的 crud，各种标签的属性等内容，属于一个入门级别的教程，后续的内容会逐渐深入。另外，MySQL 进阶的教程已经写了五篇文章了，每一篇都是经典，已经出了一个专辑，感兴趣的可以收藏一下MySQL 进阶。感谢你的阅读，作者会定时的更新原创文章，如果觉得写的不错的话，可以关注一下本公众号。本文使用 mdnice 排版]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MySQL中索引如何优化？]]></title>
      <url>%2F2020%2F04%2F20%2F%E7%B4%A2%E5%BC%95%E7%9A%84%E4%BC%98%E5%8C%96%2F</url>
      <content type="text"><![CDATA[前言索引的相信大家都听说过，但是真正会用的又有几人？平时工作中写SQL真的会考虑到这条SQL如何能够用上索引，如何能够提升执行效率？此篇文章详细的讲述了索引优化的几个原则，只要在工作中能够随时应用到，相信你写出的SQL一定是效率最高，最牛逼的。文章的脑图如下：索引优化规则1、like语句的前导模糊查询不能使用索引select from doc where title like ‘%XX’； –不能使用索引select from doc where title like ‘XX%’； –非前导模糊查询，可以使用索引因为页面搜索严禁左模糊或者全模糊，如果需要可以使用搜索引擎来解决。2、union、in、or 都能够命中索引，建议使用 inunion能够命中索引，并且MySQL 耗费的 CPU 最少。select from doc where status=1union allselect from doc where status=2;in能够命中索引，查询优化耗费的 CPU 比 union all 多，但可以忽略不计，一般情况下建议使用 in。select from doc where status in (1, 2);or 新版的 MySQL 能够命中索引，查询优化耗费的 CPU 比 in多，不建议频繁用or。select from doc where status = 1 or status = 2补充：有些地方说在where条件中使用or，索引会失效，造成全表扫描，这是个误区：①要求where子句使用的所有字段，都必须建立索引；②如果数据量太少，mysql制定执行计划时发现全表扫描比索引查找更快，所以会不使用索引；③确保mysql版本5.0以上，且查询优化器开启了index_merge_union=on, 也就是变量optimizer_switch里存在index_merge_union且为on。3、负向条件查询不能使用索引负向条件有：!=、&lt;&gt;、not in、not exists、not like 等。例如下面SQL语句：select from doc where status != 1 and status != 2;可以优化为 in 查询：select from doc where status in (0,3,4);4、联合索引最左前缀原则如果在(a,b,c)三个字段上建立联合索引，那么他会自动建立 a| (a,b) | (a,b,c)组索引。登录业务需求，SQL语句如下：select uid, login_time from user where login_name=? andpasswd=?可以建立(login_name, passwd)的联合索引。因为业务上几乎没有passwd 的单条件查询需求，而有很多login_name 的单条件查询需求，所以可以建立(login_name, passwd)的联合索引，而不是(passwd, login_name)。建立联合索引的时候，区分度最高的字段在最左边存在非等号和等号混合判断条件时，在建立索引时，把等号条件的列前置。如 where a&gt;? and b=?，那么即使a 的区分度更高，也必须把 b 放在索引的最前列。最左前缀查询时，并不是指SQL语句的where顺序要和联合索引一致。下面的 SQL 语句也可以命中 (login_name, passwd) 这个联合索引：select uid, login_time from user where passwd=? andlogin_name=?但还是建议 where 后的顺序和联合索引一致，养成好习惯。假如index(a,b,c), where a=3 and b like ‘abc%’ and c=4，a能用，b能用，c不能用。5、不能使用索引中范围条件右边的列（范围列可以用到索引），范围列之后列的索引全失效范围条件有：&lt;、&lt;=、&gt;、&gt;=、between等。索引最多用于一个范围列，如果查询条件中有两个范围列则无法全用到索引。假如有联合索引 (empno、title、fromdate)，那么下面的 SQL 中 emp_no 可以用到索引，而title 和 from_date 则使用不到索引。select from employees.titles where emp_no &lt; 10010‘ and title=’Senior Engineer‘and from_date between ‘1986-01-01‘ and ‘1986-12-31‘6、不要在索引列上面做任何操作（计算、函数），否则会导致索引失效而转向全表扫描例如下面的 SQL 语句，即使 date 上建立了索引，也会全表扫描：select from doc where YEAR(create_time) &lt;= ‘2016’;可优化为值计算，如下：select from doc where create_time &lt;= ‘2016-01-01’;比如下面的 SQL 语句：select from order where date &lt; = CURDATE()；可以优化为：select from order where date &lt; = ‘2018-01-2412:00:00’;7、强制类型转换会全表扫描字符串类型不加单引号会导致索引失效，因为mysql会自己做类型转换,相当于在索引列上进行了操作。如果 phone 字段是 varchar 类型，则下面的 SQL 不能命中索引。select from user where phone=13800001234可以优化为：select from user where phone=‘13800001234’;8、更新十分频繁、数据区分度不高的列不宜建立索引更新会变更 B+ 树，更新频繁的字段建立索引会大大降低数据库性能。“性别”这种区分度不大的属性，建立索引是没有什么意义的，不能有效过滤数据，性能与全表扫描类似。一般区分度在80%以上的时候就可以建立索引，区分度可以使用 count(distinct(列名))/count() 来计算。9、利用覆盖索引来进行查询操作，避免回表，减少select 的使用覆盖索引：查询的列和所建立的索引的列个数相同，字段相同。被查询的列，数据能从索引中取得，而不用通过行定位符 row-locator 再到 row 上获取，即“被查询列要被所建的索引覆盖”，这能够加速查询速度。例如登录业务需求，SQL语句如下。Select uid, login_time from user where login_name=? and passwd=?可以建立(login_name, passwd, login_time)的联合索引，由于 login_time 已经建立在索引中了，被查询的 uid 和 login_time 就不用去 row 上获取数据了，从而加速查询。10、索引不会包含有NULL值的列只要列中包含有NULL值都将不会被包含在索引中，复合索引中只要有一列含有NULL值，那么这一列对于此复合索引就是无效的。所以我们在数据库设计时，尽量使用not null 约束以及默认值。11、is null, is not null无法使用索引12、如果有order by、group by的场景，请注意利用索引的有序性order by 最后的字段是组合索引的一部分，并且放在索引组合顺序的最后，避免出现file_sort 的情况，影响查询性能。例如对于语句 where a=? and b=? order by c，可以建立联合索引(a,b,c)。如果索引中有范围查找，那么索引有序性无法利用，如WHERE a&gt;10 ORDER BY b;，索引(a,b)无法排序。13、使用短索引（前缀索引）对列进行索引，如果可能应该指定一个前缀长度。例如，如果有一个CHAR(255)的列，如果该列在前10个或20个字符内，可以做到既使得前缀索引的区分度接近全列索引，那么就不要对整个列进行索引。因为短索引不仅可以提高查询速度而且可以节省磁盘空间和I/O操作，减少索引文件的维护开销。可以使用count(distinct leftIndex(列名, 索引长度))/count() 来计算前缀索引的区分度。但缺点是不能用于 ORDER BY 和 GROUP BY 操作，也不能用于覆盖索引。不过很多时候没必要对全字段建立索引，根据实际文本区分度决定索引长度即可。14、利用延迟关联或者子查询优化超多分页场景MySQL 并不是跳过 offset 行，而是取 offset+N 行，然后返回放弃前 offset 行，返回 N 行，那当 offset 特别大的时候，效率就非常的低下，要么控制返回的总页数，要么对超过特定阈值的页数进行 SQL 改写。示例如下，先快速定位需要获取的id段，然后再关联:selecta. from 表1 a,(select id from 表1 where 条件 limit100000,20 ) b where a.id=b.id；15、如果明确知道只有一条结果返回，limit 1 能够提高效率比如如下 SQL 语句：select from user where login_name=?;可以优化为：select from user where login_name=? limit 1自己明确知道只有一条结果，但数据库并不知道，明确告诉它，让它主动停止游标移动。16、超过三个表最好不要 join需要 join 的字段，数据类型必须一致，多表关联查询时，保证被关联的字段需要有索引。例如：left join是由左边决定的，左边的数据一定都有，所以右边是我们的关键点，建立索引要建右边的。当然如果索引在左边，可以用right join。17、单表索引建议控制在5个以内18、SQL 性能优化 explain 中的 type：至少要达到 range 级别，要求是 ref 级别，如果可以是 consts 最好consts：单表中最多只有一个匹配行（主键或者唯一索引），在优化阶段即可读取到数据。ref：使用普通的索引（Normal Index）。range：对索引进行范围检索。当 type=index 时，索引物理文件全扫，速度非常慢。19、业务上具有唯一特性的字段，即使是多个字段的组合，也必须建成唯一索引不要以为唯一索引影响了 insert 速度，这个速度损耗可以忽略，但提高查找速度是明显的。另外，即使在应用层做了非常完善的校验控制，只要没有唯一索引，根据墨菲定律，必然有脏数据产生。20.创建索引时避免以下错误观念索引越多越好，认为需要一个查询就建一个索引。宁缺勿滥，认为索引会消耗空间、严重拖慢更新和新增速度。抵制惟一索引，认为业务的惟一性一律需要在应用层通过“先查后插”方式解决。过早优化，在不了解系统的情况下就开始优化。索引选择性与前缀索引既然索引可以加快查询速度，那么是不是只要是查询语句需要，就建上索引？答案是否定的。因为索引虽然加快了查询速度，但索引也是有代价的：索引文件本身要消耗存储空间，同时索引会加重插入、删除和修改记录时的负担，另外，MySQL在运行时也要消耗资源维护索引，因此索引并不是越多越好。一般两种情况下不建议建索引。第一种情况是表记录比较少，例如一两千条甚至只有几百条记录的表，没必要建索引，让查询做全表扫描就好了。至于多少条记录才算多，这个个人有个人的看法，我个人的经验是以2000作为分界线，记录数不超过 2000可以考虑不建索引，超过2000条可以酌情考虑索引。另一种不建议建索引的情况是索引的选择性较低。所谓索引的选择性（Selectivity），是指不重复的索引值（也叫基数，Cardinality）与表记录数（#T）的比值：Index Selectivity = Cardinality / #T显然选择性的取值范围为(0, 1]`，选择性越高的索引价值越大，这是由&lt;/code&gt;B+Tree&lt;code style=&quot;font-size: 14px; word-wrap: break-word; padding: 2px 4px; border-radius: 4px; margin: 0 2px; background-color: rgba(27,31,35,.05); font-family: Operator Mono, Consolas, Monaco, Menlo, monospace; word-break: break-all; color: #28ca71;&quot;&gt;的性质决定的。例如，&lt;/code&gt;employees.titles&lt;code style=&quot;font-size: 14px; word-wrap: break-word; padding: 2px 4px; border-radius: 4px; margin: 0 2px; background-color: rgba(27,31,35,.05); font-family: Operator Mono, Consolas, Monaco, Menlo, monospace; word-break: break-all; color: #28ca71;&quot;&gt;表，如果&lt;/code&gt;title字段经常被单独查询，是否需要建索引，我们看一下它的选择性：SELECT count(DISTINCT(title))/count() AS Selectivity FROM employees.titles;+————-+| Selectivity |+————-+| 0.0000 |+————-+title的选择性不足0.0001（精确值为0.00001579），所以实在没有什么必要为其单独建索引。有一种与索引选择性有关的索引优化策略叫做前缀索引，就是用列的前缀代替整个列作为索引key，当前缀长度合适时，可以做到既使得前缀索引的选择性接近全列索引，同时因为索引key变短而减少了索引文件的大小和维护开销。下面以employees.employees表为例介绍前缀索引的选择和使用。假设employees表只有一个索引&lt;emp_no&gt;，那么如果我们想按名字搜索一个人，就只能全表扫描了：EXPLAIN SELECT FROM employees.employees WHERE first_name=‘Eric’ AND last_name=‘Anido’;+—-+————-+———–+——+—————+——+———+——+——–+————-+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+—-+————-+———–+——+—————+——+———+——+——–+————-+| 1 | SIMPLE | employees | ALL | NULL | NULL | NULL | NULL | 300024 | Using where |+—-+————-+———–+——+—————+——+———+——+——–+————-+如果频繁按名字搜索员工，这样显然效率很低，因此我们可以考虑建索引。有两种选择，建&lt;first_name&gt;或&lt;first_name, last_name&gt;，看下两个索引的选择性：SELECT count(DISTINCT(first_name))/count() AS Selectivity FROM employees.employees;+————-+| Selectivity |+————-+| 0.0042 |+————-+SELECT count(DISTINCT(concat(first_name, last_name)))/count() AS Selectivity FROM employees.employees;+————-+| Selectivity |+————-+| 0.9313 |+————-+&lt;first_name&gt;显然选择性太低，`&amp;lt;first_name, last_name&amp;gt;&lt;code style=&quot;font-size: 14px; word-wrap: break-word; padding: 2px 4px; border-radius: 4px; margin: 0 2px; background-color: rgba(27,31,35,.05); font-family: Operator Mono, Consolas, Monaco, Menlo, monospace; word-break: break-all; color: #28ca71;&quot;&gt;选择性很好，但是&lt;/code&gt;first_name&lt;code style=&quot;font-size: 14px; word-wrap: break-word; padding: 2px 4px; border-radius: 4px; margin: 0 2px; background-color: rgba(27,31,35,.05); font-family: Operator Mono, Consolas, Monaco, Menlo, monospace; word-break: break-all; color: #28ca71;&quot;&gt;和&lt;/code&gt;last_name&lt;code style=&quot;font-size: 14px; word-wrap: break-word; padding: 2px 4px; border-radius: 4px; margin: 0 2px; background-color: rgba(27,31,35,.05); font-family: Operator Mono, Consolas, Monaco, Menlo, monospace; word-break: break-all; color: #28ca71;&quot;&gt;加起来长度为&lt;/code&gt;30&lt;code style=&quot;font-size: 14px; word-wrap: break-word; padding: 2px 4px; border-radius: 4px; margin: 0 2px; background-color: rgba(27,31,35,.05); font-family: Operator Mono, Consolas, Monaco, Menlo, monospace; word-break: break-all; color: #28ca71;&quot;&gt;，有没有兼顾长度和选择性的办法？可以考虑用first_name和last_name的前几个字符建立索引，例如&lt;/code&gt;&amp;lt;first_name, left(last_name, 3)&amp;gt;，看看其选择性：SELECT count(DISTINCT(concat(first_name, left(last_name, 3))))/count() AS Selectivity FROM employees.employees;+————-+| Selectivity |+————-+| 0.7879 |+————-+选择性还不错，但离0.9313还是有点距离，那么把last_name前缀加到4：SELECT count(DISTINCT(concat(first_name, left(last_name, 4))))/count() AS Selectivity FROM employees.employees;+————-+| Selectivity |+————-+| 0.9007 |+————-+这时选择性已经很理想了，而这个索引的长度只有18，比&lt;first_name, last_name&gt;短了接近一半，我们把这个前缀索引建上：ALTER TABLE employees.employeesADD INDEX first_name_last_name4 (first_name, last_name(4));此时再执行一遍按名字查询，比较分析一下与建索引前的结果：SHOW PROFILES;+———-+————+———————————————————————————+| Query_ID | Duration | Query |+———-+————+———————————————————————————+| 87 | 0.11941700 | SELECT FROM employees.employees WHERE first_name=‘Eric’ AND last_name=‘Anido’ || 90 | 0.00092400 | SELECT * FROM employees.employees WHERE first_name=‘Eric’ AND last_name=‘Anido’ |+———-+————+———————————————————————————+性能的提升是显著的，查询速度提高了120多倍。前缀索引兼顾索引大小和查询速度，但是其缺点是不能用于ORDER BY和GROUP BY操作，也不能用于Covering index（即当索引本身包含查询所需全部数据时，不再访问数据文件本身）。总结本文主要讲了索引优化的二十个原则，希望读者喜欢。本篇文章脑图和PDF文档已经准备好，有需要的伙伴可以回复关键词索引优化获取。本文使用 mdnice 排版]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[索引的概念和数据结构]]></title>
      <url>%2F2020%2F04%2F20%2F%E7%B4%A2%E5%BC%95%E7%9A%84%E6%A6%82%E5%BF%B5%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
      <content type="text"><![CDATA[前言索引是什么？有什么利弊？一旦在面试中被问道，对于新入门的小白可能是个棘手的问题。本篇文章将会详细讲述什么是索引、索引的优缺点、数据结构等等常见的知识。什么是索引索引就是一种的数据结构，存储表中特定列的值并对值进行排序，所以是在表的列上面创建的。索引将通过缩小一张表中需要查询的记录的数目来加快搜索的速度。如果没有索引，数据库不得不进行全表扫描。索引就好比一本书的目录，它会让你更快的找到内容。索引的优点通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。可以大大加快数据的检索速度，避免进行全表的数据扫描，大大减少遍历匹配的行数，这也是创建索引的最主要的原因。可以加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义。在使用分组和排序子句进行数据检索时，同样可以显著减少查询中分组和排序的时间。通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。索引的缺点创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加。索引需要占物理空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果要建立聚簇索引，那么需要的空间就会更大。当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度。在哪些列建立索引在经常需要搜索的列上，可以加快搜索的速度；在作为主键的列上，强制该列的唯一性和组织表中数据的排列结构；在经常用在连接的列上，这些列主要是一些外键，可以加快连接的速度；在经常需要根据范围进行搜索的列上创建索引，因为索引已经排序，其指定的范围是连续的；在经常需要排序的列上创建索引，因为索引已经排序，这样查询可以利用索引的排序，加快排序查询时间；在经常使用在WHERE子句中的列上面创建索引，加快条件的判断速度。不在哪些列建索引？对于那些在查询中很少使用或者参考的列不应该创建索引。这是因为，既然这些列很少使用到，因此有索引或者无索引，并不能提高查询速度。相反，由于增加了索引，反而降低了系统的维护速度和增大了空间需求。对于那些只有很少数据值的列也不应该增加索引。这是因为，由于这些列的取值很少，例如人事表的性别列，在查询的结果中，结果集的数据行占了表中数据行的很大比例，即需要在表中搜索的数据行的比例很大。增加索引，并不能明显加快检索速度。对于那些定义为text, image和bit数据类型的列不应该增加索引。这是因为，这些列的数据量要么相当大，要么取值很少。当修改性能远远大于检索性能时，不应该创建索引。这是因为，修改性能和检索性能是互相矛盾的。当增加索引时，会提高检索性能，但是会降低修改性能。当减少索引时，会提高修改性能，降低检索性能。因此，当修改性能远远大于检索性能时，不应该创建索引。索引的数据结构常见的索引的数据结构有：B+Tree、Hash索引、FullText索引、R-Tree索引。Hash 索引1. 概述：MySQL 中，只有Memory存储引擎支持Hash索引，是Memory表的默认索引类型。hash 索引把数据的索引以 hash 值形式组织起来，因此检索效率非常高，可以一次定位，不像B-/+Tree索引需要进行从根节点到叶节点的多次 IO 操作。2. Hash 索引的缺点：① Hash 索引仅仅能满足等值的查询，不能满足范围查询。因为数据在经过 Hash 算法后，其大小关系就可能发生变化。② Hash 索引不能被排序。同样是因为数据经过 Hash 算法后，大小关系就可能发生变化，排序是没有意义的。③ Hash 索引不能避免表数据的扫描。因为发生 Hash 碰撞时，仅仅比较 Hash 值是不够的，需要比较实际的值以判定是否符合要求。④ Hash 索引在发生大量 Hash 值相同的情况时性能不一定比 B-Tree 索引高。因为碰撞情况会导致多次的表数据的扫描，造成整体性能的低下，可以通过采用合适的 Hash 算法一定程度解决这个问题。⑤ Hash 索引不能使用部分索引键查询。因为当使用组合索引情况时，是把多个数据库列数据合并后再计算 Hash 值，所以对单独列数据计算 Hash 值是没有意义的。FullText 索引1. 概述：全文索引，目前 MySQL 中只有MyISAM存储引擎支持，并且只有char、varchar、text 类型支持。它用于替代效率较低的like 模糊匹配操作，而且可以通过多字段组合的全文索引一次性全模糊匹配多个字段。2. 存储结构：同样使用B-Tree存放索引数据，但使用的是特定的算法，将字段数据分割后再进行索引（一般每 4 个字节一次分割），索引文件存储的是分割前的索引字符串集合，与分割后的索引信息，对应 Btree 结构的节点存储的是分割后的词信息以及它在分割前的索引字符串集合中的位置。B-/+Tree 索引B+Tree 是 mysql 使用最频繁的一个索引数据结构，是 Innodb 和 Myisam 存储引擎模式的索引类型。相对 Hash 索引，B+树在查找单条记录的速度比不上 Hash 索引，但是更适合排序等操作。1. B+Tree 索引的优点：带顺序访问指针的 B+Tree：B+Tree 所有索引数据都在叶子结点上，并且增加了顺序访问指针,每个叶子节点都有指向相邻叶子节点的指针。这样做是为了提高区间查询效率，例如查询 key 为从 18 到 49 的所有数据记录，当找到 18 后，只需顺着节点和指针顺序遍历就可以一次性访问到所有数据节点，极大提到了区间查询效率。大大减少磁盘 I/O 读取次数。B-/+Tree 索引：文件系统及数据库系统普遍采用 B-/+Tree 作为索引结构：一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储在磁盘上。这样的话，索引查找过程中就要产生磁盘 I/O 消耗，相对于内存存取，I/O 存取的消耗要高几个数量级，所以评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘 I/O 操作次数的渐进复杂度。换句话说，索引的结构组织要尽量减少查找过程中磁盘 I/O 的存取次数。局部性处理与磁盘预读由于存储介质的特性，磁盘本身存取就比主存慢很多，再加上机械运动耗费，磁盘的存取速度往往是主存的几百分分之一，因此为了提高效率，要尽量减少磁盘 I/O。为了达到这个目的，磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。由于磁盘顺序读取的效率很高（不需要寻道时间，只需很少的旋转时间），因此对于具有局部性的程序来说，预读可以提高 I/O 效率。预读的长度一般为页（page）的整倍数。页是计算机管理存储器的逻辑块，硬件及操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（在许多操作系统中，页得大小通常为 4k），主存和磁盘以页为单位交换数据。当程序要读取的数据不在主存中时，会触发一个缺页异常，此时系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后异常返回，程序继续运行。B-/+Tree 索引的性能分析上文说过一般使用磁盘 I/O 次数评价索引结构的优劣。先从 B-Tree 分析，根据 B-Tree 的定义，可知检索一次最多需要访问 h 个节点。数据库系统的设计者巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次 I/O 就可以完全载入。为了达到这个目的，在实际实现 B-Tree 还需要使用如下技巧：每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一个节点只需一次 I/O。B-Tree 中一次检索最多需要h-1次 I/O（根节点常驻内存），渐进复杂度为O(h)=O(logdN)。一般实际应用中，出度 d 是非常大的数字，通常超过 100，因此 h 非常小（通常不超过 3）。综上所述，用 B-Tree 作为索引结构效率是非常高的。而红黑树这种结构，h 明显要深的多。由于逻辑上很近的节点（父子）物理上可能很远，无法利用局部性，所以红黑树的 I/O 渐进复杂度也为 O(h)，效率明显比 B-Tree 差很多。另外，B+Tree 更适合外存索引，原因和内节点出度 d 有关。从上面分析可以看到，d 越大索引的性能越好，而出度的上限取决于节点内 key 和 data 的大小，由于 B+Tree 内节点去掉了 data 域，因此可以拥有更大的出度，拥有更好的性能。（详细见本部分第 3 点）B-Tree 与 B+Tree 的对比根据 B-Tree 和 B+Tree 的结构，我们可以发现 B+树相比于 B 树，在文件系统或者数据库系统当中，更有优势，原因如下：1. B+树的磁盘读写代价更低B+树的内部结点并没有指向关键字具体信息的指针。因此其内部结点相对 B 树更小。如果把所有同一内部结点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多。一次性读入内存中的需要查找的关键字也就越多。相对来说 I/O 读写次数也就降低了。2. B+树的查询效率更加稳定由于内部结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。3. B+树更有利于对数据库的扫描B 树在提高了磁盘 IO 性能的同时并没有解决元素遍历的效率低下的问题，而 B+树只需要遍历叶子节点就可以解决对全部关键字信息的扫描，所以对于数据库中频繁使用的 range query，B+树有着更高的性能。MySQL 索引的实现在 MySQL 中，索引属于存储引擎级别的概念，不同存储引擎对索引的实现方式是不同的，本部分主要讨论 MyISAM 和 InnoDB 两个存储引擎的索引实现方式。MyISAM 索引的实现1. 主键索引MyISAM 引擎使用 B+Tree 作为索引结构，叶节点的 data 域存放的是数据记录的地址。下图是 MyISAM 索引的原理图：img这里设表一共有三列，假设我们以 Col1 为主键，则上图是一个 MyISAM 表的主索引（Primary key）示意。可以看出 MyISAM 的索引文件仅仅保存数据记录的地址。2. 辅助索引在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求 key 是唯一的，而辅助索引的 key 可以重复。如果我们在 Col2 上建立一个辅助索引，则此索引的结构如下图所示：img同样也是一颗 B+Tree，data 域保存数据记录的地址。因此，MyISAM 中索引检索的算法为首先按照 B+Tree 搜索算法搜索索引，如果指定的 Key 存在，则取出其 data 域的值，然后以 data 域的值为地址，读取相应数据记录。MyISAM 的索引方式也叫做“非聚集”的，之所以这么称呼是为了与 InnoDB 的聚集索引区分。InnoDB 索引的实现虽然 InnoDB 也使用 B+Tree 作为索引结构，但具体实现方式却不相同。1. 主键索引与 MyISAM 第一个重大区别是 InnoDB 的数据文件本身就是索引文件。从上文知道，MyISAM 索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在 InnoDB 中，表数据文件本身就是按 B+Tree 组织的一个索引结构，这棵树的叶节点 data 域保存了完整的数据记录。这个索引的 key 是数据表的主键，因此 InnoDB 表数据文件本身就是主索引。img上图是 InnoDB 主索引（同时也是数据文件）的示意图，可以看到叶节点包含了完整的数据记录。这种索引叫做聚集索引。因为 InnoDB 的数据文件本身要按主键聚集，所以 InnoDB 要求表必须有主键（MyISAM 可以没有），如果没有显式指定，则 MySQL 系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则 MySQL 自动为 InnoDB 表生成一个隐含字段作为主键，这个字段长度为 6 个字节，类型为长整形。2. 辅助索引第二个与 MyISAM 索引的不同是 InnoDB 的辅助索引 data 域存储相应记录主键的值而不是地址。换句话说，InnoDB 的所有辅助索引都引用主键作为 data 域。例如，下图为定义在 Col3 上的一个辅助索引：img这里以英文字符的 ASCII 码作为比较准则。聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。InnoDB 表是基于聚簇索引建立的。因此 InnoDB 的索引能提供一种非常快速的主键查找性能。不过，它的辅助索引也会包含主键列，所以，如果主键使用过长的字段，将会导致其他辅助索变得更大。如果想在表上定义 、很多索引，则争取尽量把主键定义得小一些。InnoDB 不会压缩索引。更多内容请关注微信公众号【码猿技术专栏】本文使用 mdnice 排版]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[explain执行计划]]></title>
      <url>%2F2020%2F04%2F20%2Fexplain%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92%2F</url>
      <content type="text"><![CDATA[前言如何写出效率高的SQL语句，提到这必然离不开Explain执行计划的分析，至于什么是执行计划，如何写出高效率的SQL，本篇文章将会一一介绍。执行计划执行计划是数据库根据 SQL 语句和相关表的统计信息作出的一个查询方案，这个方案是由查询优化器自动分析产生的。使用explain关键字可以模拟优化器执行 SQL 查询语句，从而知道 MySQL 是如何处理你的 SQL 语句的，分析你的 select 语句或是表结构的性能瓶颈，让我们知道 select 效率低下的原因，从而改进我们的查询。explain 的结果如下：下面是有关各列的详细介绍，重要的有id、type、key、rows、extra。idid 列的编号就是 select 的序列号，也可以理解为 SQL 执行顺序的标识，有几个 select 就有几个 id。id 值不同：如果是只查询，id 的序号会递增，id 值越大优先级越高，越先被执行；id 值相同：从上往下依次执行；id 列为 null：表示这是一个结果集，不需要使用它来进行查询。select_type查询的类型，主要用于区分普通查询、联合查询、子查询等复杂的查询；simple：表示查询中不包括 union 操作或者子查询，位于最外层的查询的 select_type 即为 simple，且只有一个； explain select from t3 where id=3952602;primary：需要 union 操作或者含有子查询的 select，位于最外层的查询的 select_type 即为 primary，且只有一个；explain select from (select from t3 where id=3952602) a ;derived：from 列表中出现的子查询，也叫做衍生表；mysql 或者递归执行这些子查询，把结果放在临时表里。 explain select from (select from t3 where id=3952602) a ;subquery：除了 from 子句中包含的子查询外，其他地方出现的子查询都可能是 subquery。explain select from t3 where id = (select id from t3 whereid=3952602 ) ;union：若第二个 select 出现在 union 之后，则被标记为 union；若 union 包含在 from 子句的子查询中，外层 select 将被标记为 derived。explain select from t3 where id=3952602 union all select from t3;union result：从 union 表获取结果的 select ，因为它不需要参与查询，所以 id 字段为 null。 explain select from t3 where id=3952602 union all select from t3;dependent union：与 union 一样，出现在 union 或 union all 语句中，但是这个查询要受到外部查询的影响；dependent subquery：与 dependent union 类似，子查询中的第一个 SELECT，这个 subquery 的查询要受到外部表查询的影响。table表示 explain 的一行正在访问哪个表。如果查询使用了别名，那么这里显示的是别名;如果不涉及对数据表的操作，那么这显示为 null;如果显示为尖括号括起来的就表示这个是临时表，后边的 N 就是执行计划中的 id，表示结果来自于这个查询产生;如果是尖括号括起来的&lt;union M,N&gt;，与类似，也是一个临时表，表示这个结果来自于 union 查询的 id 为 M,N 的结果集。type访问类型，即 MySQL 决定如何查找表中的行。依次从好到差：system &gt; const &gt; eq_ref &gt; ref &gt; fulltext &gt; ref_or_null &gt; index_merge &gt; unique_subquery &gt; index_subquery &gt; range &gt; index &gt; ALL，除了 all 之外，其他的 type 都可以使用到索引，除了 index_merge 之外，其他的 type 只可以用到一个索引。一般来说，得保证查询至少达到 range 级别，最好能达到 ref。system：表中只有一行数据（等于系统表），这是 const 类型的特例，平时不会出现，可以忽略不计。const：使用唯一索引或者主键，表示通过索引一次就找到了，const 用于比较 primary key 或者 unique 索引。因为只需匹配一行数据，所有很快。如果将主键置于 where 列表中，mysql 就能将该查询转换为一个 const。eq_ref：唯一性索引扫描，对于每个索引键，表中只有一行数据与之匹配。常见于主键或唯一索引扫描。ref：非唯一性索引扫描，返回匹配某个单独值的所有行。本质也是一种索引。fulltext：全文索引检索，全文索引的优先级很高，若全文索引和普通索引同时存在时，mysql 不管代价，优先选择使用全文索引。ref_or_null：与 ref 方法类似，只是增加了 null 值的比较。index_merge：表示查询使用了两个以上的索引，索引合并的优化方法，最后取交集或者并集，常见 and ，or 的条件使用了不同的索引。unique_subquery：用于 where 中的 in 形式子查询，子查询返回不重复值唯一值；index_subquery：用于 in 形式子查询使用到了辅助索引或者 in 常数列表，子查询可能返回重复值，可以使用索引将子查询去重。range：索引范围扫描，常见于使用&gt;,&lt;,between ,in ,like等运算符的查询中。index：索引全表扫描，把索引树从头到尾扫一遍；all：遍历全表以找到匹配的行（Index 与 ALL 虽然都是读全表，但 index 是从索引中读取，而 ALL 是从硬盘读取）NULL: MySQL 在优化过程中分解语句，执行时甚至不用访问表或索引。possible_keys显示查询可能使用到的索引。key显示查询实际使用哪个索引来优化对该表的访问；select_type 为 index_merge 时，这里可能出现两个以上的索引，其他的 select_type 这里只会出现一个。key_len用于处理查询的索引长度，表示索引中使用的字节数。通过这个值，可以得出一个多列索引里实际使用了哪一部分。注：key_len 显示的值为索引字段的最大可能长度，并非实际使用长度，即 key_len 是根据表定义计算而得，不是通过表内检索出的。另外，key_len 只计算 where 条件用到的索引长度，而排序和分组就算用到了索引，也不会计算到 key_len 中。ref显示哪个字段或者常数与 key 一起被使用。如果是使用的常数等值查询，这里会显示 const。如果是连接查询，被驱动表的执行计划这里会显示驱动表的关联字段。如果是条件使用了表达式或者函数，或者条件列发生了内部隐式转换，这里可能显示为 func。rows表示 MySQL 根据表统计信息及索引选用情况，大致估算的找到所需的目标记录所需要读取的行数，不是精确值。extra不适合在其他列中显示但十分重要的额外信息。这个列可以显示的信息非常多，有几十种，常用的有：类型说明Using filesortMySQL 有两种方式可以生成有序的结果，通过排序操作或者使用索引，当 Extra 中出现了 Using filesort 说明 MySQL 使用了后者，但注意虽然叫 filesort 但并不是说明就是用了文件来进行排序，只要可能排序都是在内存里完成的。大部分情况下利用索引排序更快，所以一般这时也要考虑优化查询了。使用文件完成排序操作，这是可能是 ordery by，group by 语句的结果，这可能是一个 CPU 密集型的过程，可以通过选择合适的索引来改进性能，用索引来为查询结果排序。Using temporary用临时表保存中间结果，常用于 GROUP BY 和 ORDER BY 操作中，一般看到它说明查询需要优化了，就算避免不了临时表的使用也要尽量避免硬盘临时表的使用。Not existsMYSQL 优化了 LEFT JOIN，一旦它找到了匹配 LEFT JOIN 标准的行， 就不再搜索了。Using index说明查询是覆盖了索引的，不需要读取数据文件，从索引树（索引文件）中即可获得信息。如果同时出现 using where，表明索引被用来执行索引键值的查找，没有 using where，表明索引用来读取数据而非执行查找动作。这是 MySQL 服务层完成的，但无需再回表查询记录。Using index condition这是 MySQL 5.6 出来的新特性，叫做“索引条件推送”。简单说一点就是 MySQL 原来在索引上是不能执行如 like 这样的操作的，但是现在可以了，这样减少了不必要的 IO 操作，但是只能用在二级索引上。Using where使用了 WHERE 从句来限制哪些行将与下一张表匹配或者是返回给用户。注意：Extra 列出现 Using where 表示 MySQL 服务器将存储引擎返回服务层以后再应用 WHERE 条件过滤。Using join buffer使用了连接缓存：Block Nested Loop，连接算法是块嵌套循环连接;Batched Key Access，连接算法是批量索引连接impossible wherewhere 子句的值总是 false，不能用来获取任何元组select tables optimized away在没有 GROUP BY 子句的情况下，基于索引优化 MIN/MAX 操作，或者对于 MyISAM 存储引擎优化 COUNT(*)操作，不必等到执行阶段再进行计算，查询执行计划生成的阶段即完成优化。distinct优化 distinct 操作，在找到第一匹配的元组后即停止找同样值的动作filtered使用 explain extended 时会出现这个列，5.7 之后的版本默认就有这个字段，不需要使用 explain extended 了。这个字段表示存储引擎返回的数据在 server 层过滤后，剩下多少满足查询的记录数量的比例，注意是百分比，不是具体记录数。关于 MySQL 执行计划的局限性EXPLAIN 不会告诉你关于触发器、存储过程的信息或用户自定义函数对查询的影响情况；EXPLAIN 不考虑各种 Cache；EXPLAIN 不能显示 MySQL 在执行查询时所作的优化工作；部分统计信息是估算的，并非精确值；EXPALIN 只能解释 SELECT 操作，其他操作要重写为 SELECT 后查看。查询计划案例分析执行顺序（id = 4）：【select id, name from t2】：select_type 为 union，说明 id=4 的 select 是 union 里面的第二个 select。（id = 3）：【select id, name from t1 where address = ‘11’】：因为是在 from 语句中包含的子查询所以被标记为 DERIVED（衍生），where address = ‘11’ 通过复合索引 idx_name_email_address 就能检索到，所以 type 为 index。（id = 2）：【select id from t3】：因为是在 select 中包含的子查询所以被标记为 SUBQUERY。（id = 1）：【select d1.name, … d2 from … d1】：select_type 为 PRIMARY 表示该查询为最外层查询，table 列被标记为 “derived3”表示查询结果来自于一个衍生表（id = 3 的 select 结果）。（id = NULL）：【 … union … 】：代表从 union 的临时表中读取行的阶段，table 列的 “union 1, 4”表示用 id=1 和 id=4 的 select 结果进行 union 操作。本文使用 mdnice 排版]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Mysql最全面试题]]></title>
      <url>%2F2020%2F04%2F20%2FMysql%E6%9C%80%E5%85%A8%E9%9D%A2%E8%AF%95%E9%A2%98%2F</url>
      <content type="text"><![CDATA[前言前几天有读者找到我，说想要一套全面的Mysql面试题，今天陈某特地为她写了一篇。由于篇幅较长，陈某已经将此文章转换为PDF，公众号回复关键词Mysql面试题即可获取。Mysql什么是SQL？结构化查询语言(Structured Query Language)简称SQL，是一种数据库查询语言。作用：用于存取数据、查询、更新和管理关系数据库系统。什么是MySQL?MySQL是一个关系型数据库管理系统，由瑞典MySQL AB 公司开发，属于 Oracle 旗下产品。MySQL 是最流行的关系型数据库管理系统之一，在 WEB 应用方面，MySQL是最好的 RDBMS (Relational Database Management System，关系数据库管理系统) 应用软件之一。在Java企业级开发中非常常用，因为 MySQL 是开源免费的，并且方便扩展。数据库三大范式是什么？第一范式：每个列都不可以再拆分。第二范式：在第一范式的基础上，非主键列完全依赖于主键，而不能是依赖于主键的一部分。第三范式：在第二范式的基础上，非主键列只依赖于主键，不依赖于其他非主键。在设计数据库结构的时候，要尽量遵守三范式，如果不遵守，必须有足够的理由。比如性能。事实上我们经常会为了性能而妥协数据库的设计。mysql有关权限的表都有哪几个？MySQL服务器通过权限表来控制用户对数据库的访问，权限表存放在mysql数据库里，由mysql_install_db脚本初始化。这些权限表分别user，db，table_priv，columns_priv和host。下面分别介绍一下这些表的结构和内容：user权限表：记录允许连接到服务器的用户帐号信息，里面的权限是全局级的。db权限表：记录各个帐号在各个数据库上的操作权限。table_priv权限表：记录数据表级的操作权限。columns_priv权限表：记录数据列级的操作权限。host权限表：配合db权限表对给定主机上数据库级操作权限作更细致的控制。这个权限表不受GRANT和REVOKE语句的影响。MySQL的binlog有有几种录入格式？分别有什么区别？有三种格式，statement，row和mixed。statement模式下，每一条会修改数据的sql都会记录在binlog中。不需要记录每一行的变化，减少了binlog日志量，节约了IO，提高性能。由于sql的执行是有上下文的，因此在保存的时候需要保存相关的信息，同时还有一些使用了函数之类的语句无法被记录复制。row级别下，不记录sql语句上下文相关信息，仅保存哪条记录被修改。记录单元为每一行的改动，基本是可以全部记下来但是由于很多操作，会导致大量行的改动(比如alter table)，因此这种模式的文件保存的信息太多，日志量太大。mixed，一种折中的方案，普通操作使用statement记录，当无法使用statement的时候使用row。此外，新版的MySQL中对row级别也做了一些优化，当表结构发生变化的时候，会记录语句而不是逐行记录。mysql有哪些数据类型？1、整数类型，包括TINYINT、SMALLINT、MEDIUMINT、INT、BIGINT，分别表示1字节、2字节、3字节、4字节、8字节整数。任何整数类型都可以加上UNSIGNED属性，表示数据是无符号的，即非负整数。长度：整数类型可以被指定长度，例如：INT(11)表示长度为11的INT类型。长度在大多数场景是没有意义的，它不会限制值的合法范围，只会影响显示字符的个数，而且需要和UNSIGNED ZEROFILL属性配合使用才有意义。例子：假定类型设定为INT(5)，属性为UNSIGNED ZEROFILL，如果用户插入的数据为12的话，那么数据库实际存储数据为00012。2、实数类型，包括FLOAT、DOUBLE、DECIMAL。DECIMAL可以用于存储比BIGINT还大的整型，能存储精确的小数。而FLOAT和DOUBLE是有取值范围的，并支持使用标准的浮点进行近似计算。计算时FLOAT和DOUBLE相比DECIMAL效率更高一些，DECIMAL你可以理解成是用字符串进行处理。3、字符串类型，包括VARCHAR、CHAR、TEXT、BLOBVARCHAR用于存储可变长字符串，它比定长类型更节省空间。VARCHAR使用额外1或2个字节存储字符串长度。列长度小于255字节时，使用1字节表示，否则使用2字节表示。VARCHAR存储的内容超出设置的长度时，内容会被截断。CHAR是定长的，根据定义的字符串长度分配足够的空间。CHAR会根据需要使用空格进行填充方便比较。CHAR适合存储很短的字符串，或者所有值都接近同一个长度。CHAR存储的内容超出设置的长度时，内容同样会被截断。4、枚举类型（ENUM），把不重复的数据存储为一个预定义的集合。有时可以使用ENUM代替常用的字符串类型。ENUM存储非常紧凑，会把列表值压缩到一个或两个字节。ENUM在内部存储时，其实存的是整数。尽量避免使用数字作为ENUM枚举的常量，因为容易混乱。排序是按照内部存储的整数5、日期和时间类型，尽量使用timestamp，空间效率高于datetime，用整数保存时间戳通常不方便处理。如果需要存储微妙，可以使用bigint存储。看到这里，这道真题是不是就比较容易回答了。MyISAM索引与InnoDB索引的区别？InnoDB索引是聚簇索引，MyISAM索引是非聚簇索引。InnoDB的主键索引的叶子节点存储着行数据，因此主键索引非常高效。MyISAM索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据。InnoDB非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会非常高效。InnoDB引擎的4大特性插入缓冲（insert buffer)二次写(double write)自适应哈希索引(ahi)预读(read ahead)什么是索引？索引是一种特殊的文件(InnoDB数据表上的索引是表空间的一个组成部分)，它们包含着对数据表里所有记录的引用指针。索引是一种数据结构。数据库索引，是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据。索引的实现通常使用B树及其变种B+树。更通俗的说，索引就相当于目录。为了方便查找书中的内容，通过对内容建立索引形成目录。索引是一个文件，它是要占据物理空间的。索引有哪些优缺点？索引的优点：可以大大加快数据的检索速度，这也是创建索引的最主要的原因。通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。索引的缺点：时间方面：创建索引和维护索引要耗费时间，具体地，当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，会降低增/改/删的执行效率；空间方面：索引需要占物理空间。索引有哪几种类型？主键索引: 数据列不允许重复，不允许为NULL，一个表只能有一个主键。唯一索引: 数据列不允许重复，允许为NULL值，一个表允许多个列创建唯一索引。可以通过 ALTER TABLE table_name ADD UNIQUE (column); 创建唯一索引可以通过 ALTER TABLE table_name ADD UNIQUE (column1,column2); 创建唯一组合索引普通索引: 基本的索引类型，没有唯一性的限制，允许为NULL值。可以通过ALTER TABLE table_name ADD INDEX index_name (column);创建普通索引可以通过ALTER TABLE table_name ADD INDEX index_name(column1, column2, column3);创建组合索引。全文索引： 是目前搜索引擎使用的一种关键技术。可以通过ALTER TABLE table_name ADD FULLTEXT (column);创建全文索引索引的数据结构（b树，hash）索引的数据结构和具体存储引擎的实现有关，在MySQL中使用较多的索引有Hash索引，B+树索引等，而我们经常使用的InnoDB存储引擎的默认索引实现为：B+树索引。对于哈希索引来说，底层的数据结构就是哈希表，因此在绝大多数需求为单条记录查询的时候，可以选择哈希索引，查询性能最快；其余大部分场景，建议选择BTree索引。1. B树索引mysql通过存储引擎取数据，基本上90%的人用的就是InnoDB了，按照实现方式分，InnoDB的索引类型目前只有两种：BTREE（B树）索引和HASH索引。B树索引是Mysql数据库中使用最频繁的索引类型，基本所有存储引擎都支持BTree索引。通常我们说的索引不出意外指的就是（B树）索引（实际是用B+树实现的，因为在查看表索引时，mysql一律打印BTREE，所以简称为B树索引）2. B+tree性质n棵子tree的节点包含n个关键字，不用来保存数据而是保存数据的索引。所有的叶子结点中包含了全部关键字的信息，及指向含这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。所有的非终端结点可以看成是索引部分，结点中仅含其子树中的最大（或最小）关键字。B+ 树中，数据对象的插入和删除仅在叶节点上进行。B+树有2个头指针，一个是树的根节点，一个是最小关键码的叶节点。3. 哈希索引简要说下，类似于数据结构中简单实现的HASH表（散列表）一样，当我们在mysql中用哈希索引时，主要就是通过Hash算法（常见的Hash算法有直接定址法、平方取中法、折叠法、除数取余法、随机数法），将数据库字段数据转换成定长的Hash值，与这条数据的行指针一并存入Hash表的对应位置；如果发生Hash碰撞（两个不同关键字的Hash值相同），则在对应Hash键下以链表形式存储。当然这只是简略模拟图。索引的基本原理索引用来快速地寻找那些具有特定值的记录。如果没有索引，一般来说执行查询时遍历整张表。索引的原理很简单，就是把无序的数据变成有序的查询把创建了索引的列的内容进行排序对排序结果生成倒排表在倒排表内容上拼上数据地址链在查询的时候，先拿到倒排表内容，再取出数据地址链，从而拿到具体数据索引算法有哪些？索引算法有 BTree算法和Hash算法1. BTree算法BTree是最常用的mysql数据库索引算法，也是mysql默认的算法。因为它不仅可以被用在=,&gt;,&gt;=,&lt;,&lt;=和between这些比较操作符上，而且还可以用于like操作符，只要它的查询条件是一个不以通配符开头的常量。2. Hash算法Hash Hash索引只能用于对等比较，例如=,&lt;=&gt;（相当于=）操作符。由于是一次定位数据，不像BTree索引需要从根节点到枝节点，最后才能访问到页节点这样多次IO访问，所以检索效率远高于BTree索引。索引设计的原则？适合索引的列是出现在where子句中的列，或者连接子句中指定的列。基数较小的类，索引效果较差，没有必要在此列建立索引使用短索引，如果对长字符串列进行索引，应该指定一个前缀长度，这样能够节省大量索引空间不要过度索引。索引需要额外的磁盘空间，并降低写操作的性能。在修改表内容的时候，索引会进行更新甚至重构，索引列越多，这个时间就会越长。所以只保持需要的索引有利于查询即可。创建索引的原则索引虽好，但也不是无限制的使用，最好符合一下几个原则最左前缀匹配原则，组合索引非常重要的原则，mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。较频繁作为查询条件的字段才去创建索引更新频繁字段不适合创建索引若是不能有效区分数据的列不适合做索引列(如性别，男女未知，最多也就三种，区分度实在太低)尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。定义有外键的数据列一定要建立索引。对于那些查询中很少涉及的列，重复值比较多的列不要建立索引。对于定义为text、image和bit的数据类型的列不要建立索引。创建索引时需要注意什么？非空字段：应该指定列为NOT NULL，除非你想存储NULL。在mysql中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用0、一个特殊的值或者一个空串代替空值；取值离散大的字段：（变量各个取值之间的差异程度）的列放到联合索引的前面，可以通过count()函数查看字段的差异值，返回值越大说明字段的唯一值越多字段的离散程度高；索引字段越小越好：数据库的数据存储以页为单位一页存储的数据越多一次IO操作获取的数据越大效率越高。使用索引查询一定能提高查询的性能吗？通常，通过索引查询数据比全表扫描要快。但是我们也必须注意到它的代价。索引需要空间来存储，也需要定期维护， 每当有记录在表中增减或索引列被修改时，索引本身也会被修改。 这意味着每条记录的INSERT，DELETE，UPDATE将为此多付出4，5 次的磁盘I/O。 因为索引需要额外的存储空间和处理，那些不必要的索引反而会使查询反应时间变慢。使用索引查询不一定能提高查询性能，索引范围查询(INDEX RANGE SCAN)适用于两种情况:基于一个范围的检索，一般查询返回结果集小于表中记录数的30%基于非唯一性索引的检索百万级别或以上的数据如何删除？关于索引：由于索引需要额外的维护成本，因为索引文件是单独存在的文件,所以当我们对数据的增加,修改,删除,都会产生额外的对索引文件的操作,这些操作需要消耗额外的IO,会降低增/改/删的执行效率。所以，在我们删除数据库百万级别数据的时候，查询MySQL官方手册得知删除数据的速度和创建的索引数量是成正比的。所以我们想要删除百万数据的时候可以先删除索引（此时大概耗时三分多钟）然后删除其中无用数据（此过程需要不到两分钟）删除完成后重新创建索引(此时数据较少了)创建索引也非常快，约十分钟左右。与之前的直接删除绝对是要快速很多，更别说万一删除中断,一切删除会回滚。那更是坑了。什么是最左前缀原则？什么是最左匹配原则？顾名思义，就是最左优先，在创建多列索引时，要根据业务需求，where子句中使用最频繁的一列放在最左边。最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。=和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式B树和B+树的区别在B树中，你可以将键和值存放在内部节点和叶子节点；但在B+树中，内部节点都是键，没有值，叶子节点同时存放键和值。B+树的叶子节点有一条链相连，而B树的叶子节点各自独立。使用B树的好处B树可以在内部节点同时存储键和值，因此，把频繁访问的数据放在靠近根节点的地方将会大大提高热点数据的查询效率。这种特性使得B树在特定数据重复多次查询的场景中更加高效。使用B+树的好处由于B+树的内部节点只存放键，不存放值，因此，一次读取，可以在内存页中获取更多的键，有利于更快地缩小查找范围。 B+树的叶节点由一条链相连，因此，当需要进行一次全数据遍历的时候，B+树只需要使用O(logN)时间找到最小的一个节点，然后通过链进行O(N)的顺序遍历即可。而B树则需要对树的每一层进行遍历，这会需要更多的内存置换次数，因此也就需要花费更多的时间什么是聚簇索引？何时使用聚簇索引与非聚簇索引？聚簇索引：将数据存储与索引放到了一块，找到索引也就找到了数据非聚簇索引：将数据存储于索引分开结构，索引结构的叶子节点指向了数据的对应行，myisam通过key_buffer把索引先缓存到内存中，当需要访问数据时（通过索引访问数据），在内存中直接搜索索引，然后通过索引找到磁盘相应数据，这也就是为什么索引不在key buffer命中时，速度慢的原因。非聚簇索引一定会回表查询吗？不一定，这涉及到查询语句所要求的字段是否全部命中了索引，如果全部命中了索引，那么就不必再进行回表查询。举个简单的例子，假设我们在员工表的年龄上建立了索引，那么当进行select age from employee where age &lt; 20的查询时，在索引的叶子节点上，已经包含了age信息，不会再次进行回表查询。联合索引是什么？为什么需要注意联合索引中的顺序？MySQL可以使用多个字段同时建立一个索引，叫做联合索引。在联合索引中，如果想要命中索引，需要按照建立索引时的字段顺序挨个使用，否则无法命中索引。MySQL使用索引时需要索引有序，假设现在建立了”name，age，school”的联合索引，那么索引的排序为: 先按照name排序，如果name相同，则按照age排序，如果age的值也相等，则按照school进行排序。当进行查询时，此时索引仅仅按照name严格有序，因此必须首先使用name字段进行等值查询，之后对于匹配到的列而言，其按照age字段严格有序，此时可以使用age字段用做索引查找，以此类推。因此在建立联合索引的时候应该注意索引列的顺序，一般情况下，将查询需求频繁或者字段选择性高的列放在前面。此外可以根据特例的查询或者表结构进行单独的调整。什么是数据库事务？事务是一个不可分割的数据库操作序列，也是数据库并发控制的基本单位，其执行的结果必须使数据库从一种一致性状态变到另一种一致性状态。事务是逻辑上的一组操作，要么都执行，要么都不执行。事物的四大特性(ACID)介绍一下?原子性： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；一致性： 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的；隔离性： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；持久性： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。什么是脏读？幻读？不可重复读？脏读(Drity Read)：某个事务已更新一份数据，另一个事务在此时读取了同一份数据，由于某些原因，前一个RollBack了操作，则后一个事务所读取的数据就会是不正确的。不可重复读(Non-repeatable read):在一个事务的两次查询之中数据不一致，这可能是两次查询过程中间插入了一个事务更新的原有的数据。幻读(Phantom Read):在一个事务的两次查询中数据笔数不一致，例如有一个事务查询了几列(Row)数据，而另一个事务却在此时插入了新的几列数据，先前的事务在接下来的查询中，就会发现有几列数据是它先前所没有的。什么是事务的隔离级别？MySQL的默认隔离级别是什么？为了达到事务的四大特性，数据库定义了4种不同的事务隔离级别，由低到高依次为Read uncommitted、Read committed、Repeatable read、Serializable，这四个级别可以逐个解决脏读、不可重复读、幻读这几类问题。SQL 标准定义了四个隔离级别：READ-UNCOMMITTED(读取未提交)： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。READ-COMMITTED(读取已提交)： 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。REPEATABLE-READ(可重复读)： 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。SERIALIZABLE(可串行化)： 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。Mysql 默认采用的 REPEATABLE_READ隔离级别 Oracle 默认采用的 READ_COMMITTED隔离级别隔离级别与锁的关系在Read Uncommitted级别下，读取数据不需要加共享锁，这样就不会跟被修改的数据上的排他锁冲突在Read Committed级别下，读操作需要加共享锁，但是在语句执行完以后释放共享锁；在Repeatable Read级别下，读操作需要加共享锁，但是在事务提交之前并不释放共享锁，也就是必须等待事务执行完毕以后才释放共享锁。SERIALIZABLE 是限制性最强的隔离级别，因为该级别锁定整个范围的键，并一直持有锁，直到事务完成。按照锁的粒度分数据库锁有哪些？行级锁:行级锁是Mysql中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。行级锁分为共享锁 和 排他锁。特点：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。表级锁: 表级锁是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。最常使用的MYISAM与INNODB都支持表级锁定。表级锁定分为表共享读锁（共享锁）与表独占写锁（排他锁）。特点：开销小，加锁快；不会出现死锁；锁定粒度大，发出锁冲突的概率最高，并发度最低。页级锁:页级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。从锁的类别上分MySQL都有哪些锁呢？从锁的类别上来讲，有共享锁和排他锁。共享锁: 又叫做读锁。 当用户要进行数据的读取时，对数据加上共享锁。共享锁可以同时加上多个。排他锁: 又叫做写锁。 当用户要进行数据的写入时，对数据加上排他锁。排他锁只可以加一个，他和其他的排他锁，共享锁都相斥。InnoDB存储引擎的锁的算法有哪三种？Record lock：单个行记录上的锁Gap lock：间隙锁，锁定一个范围，不包括记录本身Next-key lock：record+gap 锁定一个范围，包含记录本身什么是死锁？怎么解决？死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而导致恶性循环的现象。常见的解决死锁的方法如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会。在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率；对于非常容易产生死锁的业务部分，可以尝试使用升级锁定颗粒度，通过表级锁定来减少死锁产生的概率；如果业务处理不好可以用分布式事务锁或者使用乐观锁数据库的乐观锁和悲观锁是什么？怎么实现的？数据库管理系统（DBMS）中的并发控制的任务是确保在多个事务同时存取数据库中同一数据时不破坏事务的隔离性和统一性以及数据库的统一性。乐观并发控制（乐观锁）和悲观并发控制（悲观锁）是并发控制主要采用的技术手段。悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。在查询完数据的时候就把事务锁起来，直到提交事务。实现方式：使用数据库中的锁机制乐观锁：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。在修改数据的时候把事务锁起来，通过version的方式来进行锁定。实现方式：乐一般会使用版本号机制或CAS算法实现。大表数据查询，怎么优化？优化shema、sql语句+索引；第二加缓存，memcached, redis；主从复制，读写分离；垂直拆分，根据你模块的耦合度，将一个大的系统分为多个小的系统，也就是分布式系统水平切分，针对数据量大的表，这一步最麻烦，最能考验技术水平，要选择一个合理的sharding key, 为了有好的查询效率，表结构也要改动，做一定的冗余，应用也要改，sql中尽量带sharding key，将数据定位到限定的表上去查，而不是扫描全部的表超大分页怎么处理？超大的分页一般从两个方向上来解决:数据库层面,这也是我们主要集中关注的(虽然收效没那么大),类似于select from table where age &gt; 20 limit 1000000,10这种查询其实也是有可以优化的余地的. 这条语句需要load1000000数据然后基本上全部丢弃,只取10条当然比较慢. 当时我们可以修改为select from table where id in (select id from table where age &gt; 20 limit 1000000,10).这样虽然也load了一百万的数据,但是由于索引覆盖,要查询的所有字段都在索引中,所以速度会很快. 同时如果ID连续的好,我们还可以select * from table where id &gt; 1000000 limit 10,效率也是不错的,优化的可能性有许多种,但是核心思想都一样,就是减少load的数据从需求的角度减少这种请求…主要是不做类似的需求(直接跳转到几百万页之后的具体某一页.只允许逐页查看或者按照给定的路线走,这样可预测,可缓存)以及防止ID泄漏且连续被人恶意攻击为什么要尽量设定一个主键？主键是数据库确保数据行在整张表唯一性的保障，即使业务上本张表没有主键，也建议添加一个自增长的ID列作为主键。设定了主键之后，在后续的删改查的时候可能更加快速以及确保操作数据范围安全。主键使用自增ID还是UUID？推荐使用自增ID，不要使用UUID。因为在InnoDB存储引擎中，主键索引是作为聚簇索引存在的，也就是说，主键索引的B+树叶子节点上存储了主键索引以及全部的数据(按照顺序)，如果主键索引是自增ID，那么只需要不断向后排列即可，如果是UUID，由于到来的ID与原来的大小不确定，会造成非常多的数据插入，数据移动，然后导致产生很多的内存碎片，进而造成插入性能的下降。总之，在数据量大一些的情况下，用自增主键性能会好一些。关于主键是聚簇索引，如果没有主键，InnoDB会选择一个唯一键来作为聚簇索引，如果没有唯一键，会生成一个隐式的主键。字段为什么要求定义为not null？null值会占用更多的字节，且会在程序中造成很多与预期不符的情况。如果要存储用户的密码散列，应该使用什么字段进行存储？密码散列，盐，用户身份证号等固定长度的字符串应该使用char而不是varchar来存储，这样可以节省空间且提高检索效率。数据库结构优化？一个好的数据库设计方案对于数据库的性能往往会起到事半功倍的效果。需要考虑数据冗余、查询和更新的速度、字段的数据类型是否合理等多方面的内容。将字段很多的表分解成多个表：对于字段较多的表，如果有些字段的使用频率很低，可以将这些字段分离出来形成新表。因为当一个表的数据量很大时，会由于使用频率低的字段的存在而变慢。增加中间表：对于需要经常联合查询的表，可以建立中间表以提高查询效率。通过建立中间表，将需要通过联合查询的数据插入到中间表中，然后将原来的联合查询改为对中间表的查询。增加冗余字段：设计数据表时应尽量遵循范式理论的规约，尽可能的减少冗余字段，让数据库设计看起来精致、优雅。但是，合理的加入冗余字段可以提高查询速度。表的规范化程度越高，表和表之间的关系越多，需要连接查询的情况也就越多，性能也就越差。MySQL数据库cpu飙升到500%的话他怎么处理？当 cpu 飙升到 500%时，先用操作系统命令 top 命令观察是不是 mysqld 占用导致的，如果不是，找出占用高的进程，并进行相关处理。如果是 mysqld 造成的， show processlist，看看里面跑的 session 情况，是不是有消耗资源的 sql 在运行。找出消耗高的 sql，看看执行计划是否准确， index 是否缺失，或者实在是数据量太大造成。一般来说，肯定要 kill 掉这些线程(同时观察 cpu 使用率是否下降)，等进行相应的调整(比如说加索引、改 sql、改内存参数)之后，再重新跑这些 SQL。也有可能是每个 sql 消耗资源并不多，但是突然之间，有大量的 session 连进来导致 cpu 飙升，这种情况就需要跟应用一起来分析为何连接数会激增，再做出相应的调整，比如说限制连接数等。主从复制的作用？主数据库出现问题，可以切换到从数据库。可以进行数据库层面的读写分离。可以在从数据库上进行日常备份。MySQL主从复制解决的问题？数据分布：随意开始或停止复制，并在不同地理位置分布数据备份负载均衡：降低单个服务器的压力高可用和故障切换：帮助应用程序避免单点失败升级测试：可以用更高版本的MySQL作为从库MySQL主从复制工作原理？在主库上把数据更高记录到二进制日志从库将主库的日志复制到自己的中继日志从库读取中继日志的事件，将其重放到从库数据中。小福利由于文章篇幅较长，陈某将其转换为PDF文档，老规矩，回复关键词Mysql面试题即可获取。巨人的肩膀https://www.cnblogs.com/hsmwlyl/p/10719152.htmlhttps://www.cnblogs.com/caomusheng/p/12586895.htmlhttps://article.itxueyuan.com/eoJEMjhttps://blog.csdn.net/thinkwon/article/details/104778621#comments本文使用 mdnice 排版]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[order by 如何工作]]></title>
      <url>%2F2020%2F04%2F20%2Forder%20by%20%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%2F</url>
      <content type="text"><![CDATA[前言在实际的开发中一定会碰到根据某个字段进行排序后来显示结果的需求，但是你真的理解order by在 Mysql 底层是如何执行的吗？假设你要查询城市是苏州的所有人名字，并且按照姓名进行排序返回前 1000 个人的姓名、年龄，这条 sql 语句应该如何写？首先创建一张用户表，sql 语句如下：CREATE TABLE user ( id int(11) NOT NULL, city varchar(16) NOT NULL, name varchar(16) NOT NULL, age int(11) NOT NULL, PRIMARY KEY (id), KEY city (city)) ENGINE=InnoDB;则上述需求的 sql 查询语句如下：select city,name,age from user where city=‘苏州’ order by name limit 1000;这条 sql 查询语句相信大家都能写出来，但是你了解它在 Mysql 底层的执行流程吗？今天陈某来大家聊一聊这条 sql 语句是如何执行的以及有什么参数会影响执行的流程。本篇文章分为如下几个部分进行详细的阐述：全字段排序rowid 排序全字段排序 VS rowid 排序如何避免排序全字段排序前面聊过索引能够避免全表扫描，因此我们给city这个字段上添加了索引，当然城市的字段很小，不用考虑字符串的索引问题，之前有写过一篇关于如何给字符串的加索引的文章，有不了解朋友看一下这篇文章:Mysql 性能优化：如何给字符串加索引？此时用Explain来分析一下的这条查询语句的执行情况，结果如下图：Extra这个字段中的Using filesort表示的就是需要排序，MySQL 会给每个线程分配一块内存用于排序，称为sort_buffer。既然使用了索引进行查询，我们来简单的画一下city这棵索引树的结构，如下图：从上图可以看出，满足city=’苏州’是从ID3到IDX这些记录。通常情况下，此条 sql 语句执行流程如下：初始化 sort_buffer，确定放入 name、city、age 这三个字段。从索引 city 找到第一个满足city=’苏州’条件的主键id，也就是图中的ID3。到主键id索引取出整行，取name、city、age三个字段的值，存入sort_buffer中。从索引city取下一个记录的主键 id。重复步骤 3、4 直到 city 的值不满足查询条件为止，对应的主键 id 也就是图中的IDX。对sort_buffer中的数据按照字段name做快速排序。按照排序结果取前 1000 行返回给客户端。我们称这个排序过程为全字段排序，执行的流程图如下：图中按name排序这个动作，可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数sort_buffer_size。sort_buffer_size：就是 MySQL 为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。rowid 排序在上面这个算法过程里面，只对原表的数据读了一遍，剩下的操作都是在sort_buffer和临时文件中执行的。但这个算法有一个问题，就是如果查询要返回的字段很多的话，那么sort_buffer里面要放的字段数太多，这样内存里能够同时放下的行数很少，要分成很多个临时文件，排序的性能会很差。所以如果单行很大，这个方法效率不够好。我们可以修改一个max_length_for_sort_data这个参数使其使用另外一种算法。max_length_for_sort_data，是 MySQL 中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL 就认为单行太大，要换一个算法。city、name、age 这三个字段的定义总长度是36，我把max_length_for_sort_data设置为 16，我们再来看看计算过程有什么改变。设置的 sql 语句如下：SET max_length_for_sort_data = 16;新的算法放入 sort_buffer 的字段，只有要排序的列（即 name 字段）和主键 id。但这时，排序的结果就因为少了 city 和 age 字段的值，不能直接返回了，整个执行流程就变成如下所示的样子：初始化sort_buffer，确定放入两个字段，即name和id。从索引 city 找到第一个满足city=’苏州’条件的主键id，也就是图中的ID3。到主键id索引取出整行，取 name、id 这两个字段，存入 sort_buffer 中。从索引city取下一个记录的主键 id。重复步骤 3、4 直到 city 的值不满足查询条件为止，对应的主键 id 也就是图中的IDX。对sort_buffer中的数据按照字段name做快速排序。遍历排序结果，取前 1000 行，并按照 id 的值回到原表中取出 city、name 和 age 三个字段返回给客户端。这个执行流程的示意图如下，我把它称为rowid排序。对比全字段排序，rowid排序多了一次回表查询，即是多了第7步的查询主键索引树。全字段排序 VS rowid 排序如果 MySQL 实在是担心排序内存太小，会影响排序效率，才会采用 rowid 排序算法，这样排序过程中一次可以排序更多行，但是需要再回到原表去取数据。如果 MySQL 认为内存足够大，会优先选择全字段排序，把需要的字段都放到 sort_buffer 中，这样排序后就会直接从内存里面返回查询结果了，不用再回到原表去取数据。这也就体现了 MySQL 的一个设计思想：如果内存够，就要多利用内存，尽量减少磁盘访问。对于 InnoDB 表来说，rowid 排序会要求回表多造成磁盘读，因此不会被优先选择。如何避免排序其实，并不是所有的order by语句，都需要排序操作的。从上面分析的执行过程，我们可以看到，MySQL 之所以需要生成临时表，并且在临时表上做排序操作，其原因是原来的数据都是无序的。如果能够保证从city这个索引上取出来的行，天然就是按照 name 递增排序的话，是不是就可以不用再排序了呢？因此想到了联合索引，创建(city,name)联合索引，sql 语句如下：alter table user add index city_user(city, name);此时的索引树如下：在这个索引里面，我们依然可以用树搜索的方式定位到第一个满足city=’苏州’的记录，并且额外确保了，接下来按顺序取“下一条记录”的遍历过程中，只要 city 的值是苏州，name 的值就一定是有序的。按照上图，整个查询的流程如下：从索引(city,name)找到第一个满足 city=’苏州’条件的主键 id。到主键 id 索引取出整行，取 name、city、age 三个字段的值，作为结果集的一部分直接返回。从索引(city,name)取下一个记录主键 id。重复步骤 2、3，直到查到第 1000 条记录，或者是不满足 city=’苏州’条件时循环结束。对应的流程图如下：可以看到，这个查询过程不需要临时表，也不需要排序。接下来，我们用 explain 的结果来印证一下。从图中可以看到，Extra字段中没有Using filesort了，也就是不需要排序了。而且由于(city,name)这个联合索引本身有序，所以这个查询也不用把 4000 行全都读一遍，只要找到满足条件的前 1000 条记录就可以退出了。也就是说，在我们这个例子里，只需要扫描 1000 次。难道仅仅这样就能满足了？此条查询语句是否能再优化呢？朋友们还记得覆盖索引吗？覆盖索引的好处就是能够避免再次回表查询，不了解的朋友们可以看一下陈某之前写的文章：Mysql 性能优化：如何使用覆盖索引？。我们创建(city,name,age)联合索引，这样在执行上面的查询语句就能使用覆盖索引了，避免了回表查询了，sql 语句如下：alter table user add index city_user_age(city, name, age);此时执行流程图如下：当然，覆盖索引能够提升效率，但是维护索引也是需要代价的，因此还需要权衡使用。总结今天这篇文章，我和你介绍了 MySQL 里面order by语句的几种算法流程。在开发系统的时候，你总是不可避免地会使用到 order by 语句。心里要清楚每个语句的排序逻辑是怎么实现的，还要能够分析出在最坏情况下，每个语句的执行对系统资源的消耗，这样才能做到下笔如有神，不犯低级错误。本文使用 mdnice 排版]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[一文搞懂Redis持久化]]></title>
      <url>%2F2020%2F04%2F20%2F%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82Redis%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
      <content type="text"><![CDATA[前言 Redis目前已经成为主流的内存数据库了，但是大部分人仅仅是停留在会用的阶段，你真的了解Redis内部的工作原理吗？ 今天这篇文章将为大家介绍Redis持久化的两种方案，文章将会从以下五个方面介绍： 什么是RDB，RDB如何实现持久化？ 什么是AOF，AOF如何实现持久化？ AOF和RDB的区别。 如何重启恢复数据？ 持久化性能问题和解决方案RDB RDB持久化是把当前进程数据生成快照保存到硬盘的过程， 触发RDB持久化过程分为手动触发和自动触发。 RDB完成后会自动生成一个文件，保存在dir配置的指定目录下，文件名是dbfileName指定。 Redis默认会采用LZF算法对生成的RDB文件做压缩处理，压缩后的文件远远小于内存大小，默认开启。 手动触发 手动触发的命令有save和bgsave。 save：该命令会阻塞Redis服务器，直到RDB的过程完成，已经被废弃，因此线上不建议使用。 bgsave：每次进行RDB过程都会fork一个子进程，由子进程完成RDB的操作，因此阻塞只会发生在fork阶段，一般时间很短。 自动触发 除了手动触发RDB，Redis服务器内部还有如下几个场景能够自动触发RDB： 根据我们的 save m n 配置规则自动触发。 如果从节点执行全量复制操作， 主节点自动执行bgsave生成RDB文件并发送给从节点。 执行debug reload命令重新加载Redis时， 也会自动触发save操作。 默认情况下执行shutdown命令时， 如果没有开启AOF持久化功能则自动执行bgsave。 RDB执行流程 RDB的主流方式就是bgsave，通过下图我们来看看RDB的执行流程： 通过上图可以很清楚RDB的执行流程，如下： 执行bgsave命令后，会先判断是否存在AOF或者RDB的子进程，如果存在，直接返回。 父进程fork操作创建一个子进程，fork操作中父进程会被阻塞。 fork完成后，子进程开始根据父进程的内存生成临时快照文件，完成后对原有的RDB文件进行替换。执行lastsave命令可以查看最近一次的RDB时间。 子进程完成后发送信号给父进程，父进程更新统计信息。 RDB的优点 RDB是一个紧凑压缩的二进制文件， 代表Redis在某个时间点上的数据快照。 非常适用于备份， 全量复制等场景。 比如每6小时执行bgsave备份，并把RDB文件拷贝到远程机器或者文件系统中，用于灾难恢复。 Redis加载RDB恢复数据远远快于AOF的方式。 RDB的缺点 RDB方式数据没办法做到实时持久化/秒级持久化。 因为bgsave每次运行都要执行fork操作创建子进程，属于重量级操作，频繁执行成本过高。 RDB文件使用特定二进制格式保存， Redis版本演进过程中有多个格式的RDB版本， 存在老版本Redis服务无法兼容新版RDB格式的问题。 AOF AOF（append only file） 持久化： 以独立日志的方式记录每次写命令，重启时再重新执行AOF文件中的命令达到恢复数据的目的。 AOF的主要作用是解决了数据持久化的实时性， 目前已经是Redis持久化的主流方式。 如何开启AOF 开启AOF功能需要设置配置：appendonly yes， 默认不开启。 AOF文件名通过appendfilename配置设置， 默认文件名是appendonly.aof。 保存路径同RDB持久化方式一致，通过dir配置指定。 AOF整体的执行流程 AOF执行的流程大致分为命令写入、文件同步、文件重写、重启加载四个步骤，如下图： 从上图大致了解了AOF的执行流程，下面一一分析上述的四个步骤。 命令写入 AOF命令写入的内容直接是文本协议格式。 例如set hello world这条命令， 在AOF缓冲区会追加如下文本： 1*3\r\n$3\r\nset\r\n$5\r\nhello\r\n$5\r\nworld\r\n 命令写入是直接写入到AOF的缓冲区中，至于为什么？原因很简单，Redis使用单线程响应命令，如果每次写AOF文件命令都直接追加到硬盘， 那么性能完全取决于当前硬盘负载。先写入缓冲区aof_buf中， 还有另一个好处， Redis可以提供多种缓冲区同步硬盘的策略，在性能和安全性方面做出平衡。 文件同步 Redis提供了多种AOF缓冲区同步文件策略， 由参数appendfsync控制，如下： 配置为always时， 每次写入都要同步AOF文件， 在一般的SATA硬盘上，Redis只能支持大约几百TPS写入， 显然跟Redis高性能特性背道而驰，不建议配置。 配置为no，由于操作系统每次同步AOF文件的周期不可控，而且会加大每次同步硬盘的数据量，虽然提升了性能，但数据安全性无法保证。 配置为everysec（默认的配置），是建议的同步策略， 也是默认配置，做到兼顾性能和数据安全性。理论上只有在系统突然宕机的情况下丢失1秒的数据（当然，这是不太准确的）。 文件重写机制 随着命令不断写入AOF， 文件会越来越大， 为了解决这个问题， Redis引入AOF重写机制压缩文件体积。 AOF文件重写是把Redis进程内的数据转化为写命令同步到新AOF文件的过程。 为什么要文件重写呢？ 因为文件重写能够使得AOF文件的体积变得更小，从而使得可以更快的被Redis加载。 重写过程分为手动触发和自动触发。 手动触发直接使用bgrewriteaof命令。 根据auto-aof-rewrite-min-size和auto-aof-rewrite-percentage参数确定自动触发时机。 auto-aof-rewrite-min-size：表示运行AOF重写时文件最小体积， 默认为64MB。 auto-aof-rewrite-percentage：代表当前AOF文件空间（aof_current_size） 和上一次重写后AOF文件空间（aof_base_size） 的比值。 自动触发时机相当于aof_current_size&gt;auto-aof-rewrite-minsize&amp;&amp;（aof_current_size-aof_base_size） /aof_base_size&gt;=auto-aof-rewritepercentage。其中aof_current_size和aof_base_size可以在info Persistence统计信息中查看。 那么文件重写后的AOF文件为什么会变小呢？ 有如下几个原因： 进程内已经超时的数据将不会再次写入AOF文件中。 旧的AOF文件含有无效命令，如del key1、 hdel key2等。重写使用进程内数据直接生成，这样新的AOF文件只保留最终数据的写入命令。 多条写命令可以合并为一个， 如：lpush list a、 lpush list b、lpush listc可以转化为：lpush list a b c。为了防止单条命令过大造成客户端缓冲区溢出，对于list、 set、 hash、 zset等类型操作，以64个元素为界拆分为多条。 介绍了文件重写的系列知识，下面来看看Redis内部是如何进行文件重写的，如下图： 看完上图，大致了解了文件重写的流程，对于重写的流程，补充如下： 重写期间，主线程并没有阻塞，而是在执行其他的操作命令，依然会向旧的AOF文件写入数据，这样能够保证备份的最终完整性，如果数据重写失败，也能保证数据不会丢失。 为了把重写期间响应的写入信息也写入到新的文件中，因此也会为子进程保留一个缓冲区，防止新写的文件丢失数据。 重写是直接把当前内存的数据生成对应命令，并不需要读取老的AOF文件进行分析、命令合并。 AOF文件直接采用的文本协议，主要是兼容性好、追加方便、可读性高可认为修改修复。 无论是RDB还是AOF都是先写入一个临时文件，然后通过重命名完成文件的替换。 AOF的优点 使用 AOF 持久化会让 Redis 变得非常耐久：你可以设置不同的 fsync 策略，比如无 fsync ，每秒钟一次 fsync ，或者每次执行写入命令时 fsync 。 AOF 的默认策略为每秒钟 fsync 一次，在这种配置下，Redis 仍然可以保持良好的性能，并且就算发生故障停机，也最多只会丢失一秒钟的数据（ fsync 会在后台线程执行，所以主线程可以继续努力地处理命令请求）。 AOF的缺点 对于相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积。根据所使用的 fsync 策略，AOF 的速度可能会慢于 RDB。 在一般情况下， 每秒 fsync 的性能依然非常高， 而关闭 fsync 可以让 AOF 的速度和 RDB 一样快， 即使在高负荷之下也是如此。不过在处理巨大的写入载入时，RDB 可以提供更有保证的最大延迟时间。 数据恢复速度相对于RDB比较慢。 AOF和RDB的区别 RDB持久化是指在指定的时间间隔内将内存中的数据集快照写入磁盘，实际操作过程是fork一个子进程，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储。 AOF持久化以日志的形式记录服务器所处理的每一个写、删除操作，查询操作不会记录，以文本的方式记录，可以打开文件看到详细的操作记录。 重启加载 无论是RDB还是AOF都可用于服务器重启时的数据恢复，执行流程如下图： 上图很清晰的分析了Redis启动恢复数据的流程，先检查AOF文件是否开启，文件是否存在，再检查RDB是否开启，文件是否存在。 性能问题与解决方案 通过上面的分析，我们都知道RDB的快照、AOF的重写都需要fork，这是一个重量级操作，会对Redis造成阻塞。因此为了不影响Redis主进程响应，我们需要尽可能降低阻塞。 那么如何减少fork操作的阻塞呢？ 优先使用物理机或者高效支持fork操作的虚拟化技术。 控制Redis实例最大可用内存， fork耗时跟内存量成正比， 线上建议每个Redis实例内存控制在10GB以内。 合理配置Linux内存分配策略，避免物理内存不足导致fork失败。 降低fork操作的频率，如适度放宽AOF自动触发时机，避免不必要的全量复制等。 总结 本文介绍了Redis持久化的两种不同的策略，大部分内容是运维人员需要掌握的，当然作为后端人员也是需要了解一下，毕竟小公司都是一人搞全栈，哈哈。 如果觉得陈某写的不错，有所收获的话，关注分享一波，你的关注将是陈某写作的最大动力，谢谢支持！！！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Mysql最全面试指南]]></title>
      <url>%2F2020%2F04%2F20%2FMysql%E6%9C%80%E5%85%A8%E9%9D%A2%E8%AF%95%E6%8C%87%E5%8D%97%2F</url>
      <content type="text"><![CDATA[前言 前几天有读者找到我，说想要一套全面的Mysql面试题，今天陈某特地为她写了一篇。 由于篇幅较长，陈某已经将此文章转换为PDF，公众号回复关键词Mysql面试题即可获取。 Mysql什么是SQL？ 结构化查询语言(Structured Query Language)简称SQL，是一种数据库查询语言。 作用：用于存取数据、查询、更新和管理关系数据库系统。 什么是MySQL? MySQL是一个关系型数据库管理系统，由瑞典MySQL AB 公司开发，属于 Oracle 旗下产品。MySQL 是最流行的关系型数据库管理系统之一，在 WEB 应用方面，MySQL是最好的 RDBMS (Relational Database Management System，关系数据库管理系统) 应用软件之一。在Java企业级开发中非常常用，因为 MySQL 是开源免费的，并且方便扩展。 数据库三大范式是什么？ 第一范式：每个列都不可以再拆分。 第二范式：在第一范式的基础上，非主键列完全依赖于主键，而不能是依赖于主键的一部分。 第三范式：在第二范式的基础上，非主键列只依赖于主键，不依赖于其他非主键。 在设计数据库结构的时候，要尽量遵守三范式，如果不遵守，必须有足够的理由。比如性能。事实上我们经常会为了性能而妥协数据库的设计。 mysql有关权限的表都有哪几个？ MySQL服务器通过权限表来控制用户对数据库的访问，权限表存放在mysql数据库里，由mysql_install_db脚本初始化。这些权限表分别user，db，table_priv，columns_priv和host。下面分别介绍一下这些表的结构和内容： user权限表：记录允许连接到服务器的用户帐号信息，里面的权限是全局级的。 db权限表：记录各个帐号在各个数据库上的操作权限。 table_priv权限表：记录数据表级的操作权限。 columns_priv权限表：记录数据列级的操作权限。 host权限表：配合db权限表对给定主机上数据库级操作权限作更细致的控制。这个权限表不受GRANT和REVOKE语句的影响。 MySQL的binlog有有几种录入格式？分别有什么区别？ 有三种格式，statement，row和mixed。 statement模式下，每一条会修改数据的sql都会记录在binlog中。不需要记录每一行的变化，减少了binlog日志量，节约了IO，提高性能。由于sql的执行是有上下文的，因此在保存的时候需要保存相关的信息，同时还有一些使用了函数之类的语句无法被记录复制。 row级别下，不记录sql语句上下文相关信息，仅保存哪条记录被修改。记录单元为每一行的改动，基本是可以全部记下来但是由于很多操作，会导致大量行的改动(比如alter table)，因此这种模式的文件保存的信息太多，日志量太大。 mixed，一种折中的方案，普通操作使用statement记录，当无法使用statement的时候使用row。 此外，新版的MySQL中对row级别也做了一些优化，当表结构发生变化的时候，会记录语句而不是逐行记录。 mysql有哪些数据类型？ 1、整数类型，包括TINYINT、SMALLINT、MEDIUMINT、INT、BIGINT，分别表示1字节、2字节、3字节、4字节、8字节整数。任何整数类型都可以加上UNSIGNED属性，表示数据是无符号的，即非负整数。 长度：整数类型可以被指定长度，例如：INT(11)表示长度为11的INT类型。长度在大多数场景是没有意义的，它不会限制值的合法范围，只会影响显示字符的个数，而且需要和UNSIGNED ZEROFILL属性配合使用才有意义。 例子：假定类型设定为INT(5)，属性为UNSIGNED ZEROFILL，如果用户插入的数据为12的话，那么数据库实际存储数据为00012。 2、实数类型，包括FLOAT、DOUBLE、DECIMAL。DECIMAL可以用于存储比BIGINT还大的整型，能存储精确的小数。而FLOAT和DOUBLE是有取值范围的，并支持使用标准的浮点进行近似计算。计算时FLOAT和DOUBLE相比DECIMAL效率更高一些，DECIMAL你可以理解成是用字符串进行处理。 3、字符串类型，包括VARCHAR、CHAR、TEXT、BLOB VARCHAR用于存储可变长字符串，它比定长类型更节省空间。 VARCHAR使用额外1或2个字节存储字符串长度。列长度小于255字节时，使用1字节表示，否则使用2字节表示。 VARCHAR存储的内容超出设置的长度时，内容会被截断。 CHAR是定长的，根据定义的字符串长度分配足够的空间。 CHAR会根据需要使用空格进行填充方便比较。 CHAR适合存储很短的字符串，或者所有值都接近同一个长度。 CHAR存储的内容超出设置的长度时，内容同样会被截断。 4、枚举类型（ENUM），把不重复的数据存储为一个预定义的集合。 有时可以使用ENUM代替常用的字符串类型。 ENUM存储非常紧凑，会把列表值压缩到一个或两个字节。 ENUM在内部存储时，其实存的是整数。 尽量避免使用数字作为ENUM枚举的常量，因为容易混乱。 排序是按照内部存储的整数 5、日期和时间类型，尽量使用timestamp，空间效率高于datetime， 用整数保存时间戳通常不方便处理。 如果需要存储微妙，可以使用bigint存储。 看到这里，这道真题是不是就比较容易回答了。 MyISAM索引与InnoDB索引的区别？ InnoDB索引是聚簇索引，MyISAM索引是非聚簇索引。 InnoDB的主键索引的叶子节点存储着行数据，因此主键索引非常高效。 MyISAM索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据。 InnoDB非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会非常高效。 InnoDB引擎的4大特性 插入缓冲（insert buffer) 二次写(double write) 自适应哈希索引(ahi) 预读(read ahead) 什么是索引？ 索引是一种特殊的文件(InnoDB数据表上的索引是表空间的一个组成部分)，它们包含着对数据表里所有记录的引用指针。 索引是一种数据结构。数据库索引，是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据。索引的实现通常使用B树及其变种B+树。 更通俗的说，索引就相当于目录。为了方便查找书中的内容，通过对内容建立索引形成目录。索引是一个文件，它是要占据物理空间的。 索引有哪些优缺点？ 索引的优点： 可以大大加快数据的检索速度，这也是创建索引的最主要的原因。 通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。 索引的缺点： 时间方面：创建索引和维护索引要耗费时间，具体地，当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，会降低增/改/删的执行效率； 空间方面：索引需要占物理空间。 索引有哪几种类型？ 主键索引: 数据列不允许重复，不允许为NULL，一个表只能有一个主键。 唯一索引: 数据列不允许重复，允许为NULL值，一个表允许多个列创建唯一索引。 可以通过 ALTER TABLE table_name ADD UNIQUE (column); 创建唯一索引 可以通过 ALTER TABLE table_name ADD UNIQUE (column1,column2); 创建唯一组合索引 普通索引: 基本的索引类型，没有唯一性的限制，允许为NULL值。 可以通过ALTER TABLE table_name ADD INDEX index_name (column);创建普通索引 可以通过ALTER TABLE table_name ADD INDEX index_name(column1, column2, column3);创建组合索引。 全文索引： 是目前搜索引擎使用的一种关键技术。 可以通过ALTER TABLE table_name ADD FULLTEXT (column);创建全文索引 索引的数据结构（b树，hash） 索引的数据结构和具体存储引擎的实现有关，在MySQL中使用较多的索引有Hash索引，B+树索引等，而我们经常使用的InnoDB存储引擎的默认索引实现为：B+树索引。对于哈希索引来说，底层的数据结构就是哈希表，因此在绝大多数需求为单条记录查询的时候，可以选择哈希索引，查询性能最快；其余大部分场景，建议选择BTree索引。 1. B树索引 mysql通过存储引擎取数据，基本上90%的人用的就是InnoDB了，按照实现方式分，InnoDB的索引类型目前只有两种：BTREE（B树）索引和HASH索引。B树索引是Mysql数据库中使用最频繁的索引类型，基本所有存储引擎都支持BTree索引。通常我们说的索引不出意外指的就是（B树）索引（实际是用B+树实现的，因为在查看表索引时，mysql一律打印BTREE，所以简称为B树索引） 2. B+tree性质 n棵子tree的节点包含n个关键字，不用来保存数据而是保存数据的索引。 所有的叶子结点中包含了全部关键字的信息，及指向含这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。 所有的非终端结点可以看成是索引部分，结点中仅含其子树中的最大（或最小）关键字。 B+ 树中，数据对象的插入和删除仅在叶节点上进行。 B+树有2个头指针，一个是树的根节点，一个是最小关键码的叶节点。 3. 哈希索引 简要说下，类似于数据结构中简单实现的HASH表（散列表）一样，当我们在mysql中用哈希索引时，主要就是通过Hash算法（常见的Hash算法有直接定址法、平方取中法、折叠法、除数取余法、随机数法），将数据库字段数据转换成定长的Hash值，与这条数据的行指针一并存入Hash表的对应位置；如果发生Hash碰撞（两个不同关键字的Hash值相同），则在对应Hash键下以链表形式存储。当然这只是简略模拟图。 索引的基本原理 索引用来快速地寻找那些具有特定值的记录。如果没有索引，一般来说执行查询时遍历整张表。 索引的原理很简单，就是把无序的数据变成有序的查询 把创建了索引的列的内容进行排序 对排序结果生成倒排表 在倒排表内容上拼上数据地址链 在查询的时候，先拿到倒排表内容，再取出数据地址链，从而拿到具体数据 索引算法有哪些？ 索引算法有 BTree算法和Hash算法 1. BTree算法 BTree是最常用的mysql数据库索引算法，也是mysql默认的算法。因为它不仅可以被用在=,&gt;,&gt;=,&lt;,&lt;=和between这些比较操作符上，而且还可以用于like操作符，只要它的查询条件是一个不以通配符开头的常量。 2. Hash算法 Hash Hash索引只能用于对等比较，例如=,&lt;=&gt;（相当于=）操作符。由于是一次定位数据，不像BTree索引需要从根节点到枝节点，最后才能访问到页节点这样多次IO访问，所以检索效率远高于BTree索引。 索引设计的原则？ 适合索引的列是出现在where子句中的列，或者连接子句中指定的列。 基数较小的类，索引效果较差，没有必要在此列建立索引 使用短索引，如果对长字符串列进行索引，应该指定一个前缀长度，这样能够节省大量索引空间 不要过度索引。索引需要额外的磁盘空间，并降低写操作的性能。在修改表内容的时候，索引会进行更新甚至重构，索引列越多，这个时间就会越长。所以只保持需要的索引有利于查询即可。 创建索引的原则 索引虽好，但也不是无限制的使用，最好符合一下几个原则 最左前缀匹配原则，组合索引非常重要的原则，mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。 较频繁作为查询条件的字段才去创建索引 更新频繁字段不适合创建索引 若是不能有效区分数据的列不适合做索引列(如性别，男女未知，最多也就三种，区分度实在太低) 尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。 定义有外键的数据列一定要建立索引。 对于那些查询中很少涉及的列，重复值比较多的列不要建立索引。 对于定义为text、image和bit的数据类型的列不要建立索引。 创建索引时需要注意什么？ 非空字段：应该指定列为NOT NULL，除非你想存储NULL。在mysql中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用0、一个特殊的值或者一个空串代替空值； 取值离散大的字段：（变量各个取值之间的差异程度）的列放到联合索引的前面，可以通过count()函数查看字段的差异值，返回值越大说明字段的唯一值越多字段的离散程度高； 索引字段越小越好：数据库的数据存储以页为单位一页存储的数据越多一次IO操作获取的数据越大效率越高。 使用索引查询一定能提高查询的性能吗？ 通常，通过索引查询数据比全表扫描要快。但是我们也必须注意到它的代价。 索引需要空间来存储，也需要定期维护， 每当有记录在表中增减或索引列被修改时，索引本身也会被修改。 这意味着每条记录的INSERT，DELETE，UPDATE将为此多付出4，5 次的磁盘I/O。 因为索引需要额外的存储空间和处理，那些不必要的索引反而会使查询反应时间变慢。使用索引查询不一定能提高查询性能，索引范围查询(INDEX RANGE SCAN)适用于两种情况: 基于一个范围的检索，一般查询返回结果集小于表中记录数的30% 基于非唯一性索引的检索 百万级别或以上的数据如何删除？ 关于索引：由于索引需要额外的维护成本，因为索引文件是单独存在的文件,所以当我们对数据的增加,修改,删除,都会产生额外的对索引文件的操作,这些操作需要消耗额外的IO,会降低增/改/删的执行效率。所以，在我们删除数据库百万级别数据的时候，查询MySQL官方手册得知删除数据的速度和创建的索引数量是成正比的。 所以我们想要删除百万数据的时候可以先删除索引（此时大概耗时三分多钟） 然后删除其中无用数据（此过程需要不到两分钟） 删除完成后重新创建索引(此时数据较少了)创建索引也非常快，约十分钟左右。 与之前的直接删除绝对是要快速很多，更别说万一删除中断,一切删除会回滚。那更是坑了。 什么是最左前缀原则？什么是最左匹配原则？ 顾名思义，就是最左优先，在创建多列索引时，要根据业务需求，where子句中使用最频繁的一列放在最左边。 最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。 =和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式 B树和B+树的区别 在B树中，你可以将键和值存放在内部节点和叶子节点；但在B+树中，内部节点都是键，没有值，叶子节点同时存放键和值。 B+树的叶子节点有一条链相连，而B树的叶子节点各自独立。 使用B树的好处 B树可以在内部节点同时存储键和值，因此，把频繁访问的数据放在靠近根节点的地方将会大大提高热点数据的查询效率。这种特性使得B树在特定数据重复多次查询的场景中更加高效。 使用B+树的好处 由于B+树的内部节点只存放键，不存放值，因此，一次读取，可以在内存页中获取更多的键，有利于更快地缩小查找范围。 B+树的叶节点由一条链相连，因此，当需要进行一次全数据遍历的时候，B+树只需要使用O(logN)时间找到最小的一个节点，然后通过链进行O(N)的顺序遍历即可。而B树则需要对树的每一层进行遍历，这会需要更多的内存置换次数，因此也就需要花费更多的时间 什么是聚簇索引？何时使用聚簇索引与非聚簇索引？ 聚簇索引：将数据存储与索引放到了一块，找到索引也就找到了数据 非聚簇索引：将数据存储于索引分开结构，索引结构的叶子节点指向了数据的对应行，myisam通过key_buffer把索引先缓存到内存中，当需要访问数据时（通过索引访问数据），在内存中直接搜索索引，然后通过索引找到磁盘相应数据，这也就是为什么索引不在key buffer命中时，速度慢的原因。 非聚簇索引一定会回表查询吗？ 不一定，这涉及到查询语句所要求的字段是否全部命中了索引，如果全部命中了索引，那么就不必再进行回表查询。 举个简单的例子，假设我们在员工表的年龄上建立了索引，那么当进行select age from employee where age &lt; 20的查询时，在索引的叶子节点上，已经包含了age信息，不会再次进行回表查询。 联合索引是什么？为什么需要注意联合索引中的顺序？ MySQL可以使用多个字段同时建立一个索引，叫做联合索引。在联合索引中，如果想要命中索引，需要按照建立索引时的字段顺序挨个使用，否则无法命中索引。 MySQL使用索引时需要索引有序，假设现在建立了”name，age，school”的联合索引，那么索引的排序为: 先按照name排序，如果name相同，则按照age排序，如果age的值也相等，则按照school进行排序。 当进行查询时，此时索引仅仅按照name严格有序，因此必须首先使用name字段进行等值查询，之后对于匹配到的列而言，其按照age字段严格有序，此时可以使用age字段用做索引查找，以此类推。因此在建立联合索引的时候应该注意索引列的顺序，一般情况下，将查询需求频繁或者字段选择性高的列放在前面。此外可以根据特例的查询或者表结构进行单独的调整。 什么是数据库事务？ 事务是一个不可分割的数据库操作序列，也是数据库并发控制的基本单位，其执行的结果必须使数据库从一种一致性状态变到另一种一致性状态。事务是逻辑上的一组操作，要么都执行，要么都不执行。 事物的四大特性(ACID)介绍一下? 原子性： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用； 一致性： 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的； 隔离性： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的； 持久性： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。 什么是脏读？幻读？不可重复读？ 脏读(Drity Read)：某个事务已更新一份数据，另一个事务在此时读取了同一份数据，由于某些原因，前一个RollBack了操作，则后一个事务所读取的数据就会是不正确的。 不可重复读(Non-repeatable read):在一个事务的两次查询之中数据不一致，这可能是两次查询过程中间插入了一个事务更新的原有的数据。 幻读(Phantom Read):在一个事务的两次查询中数据笔数不一致，例如有一个事务查询了几列(Row)数据，而另一个事务却在此时插入了新的几列数据，先前的事务在接下来的查询中，就会发现有几列数据是它先前所没有的。 什么是事务的隔离级别？MySQL的默认隔离级别是什么？ 为了达到事务的四大特性，数据库定义了4种不同的事务隔离级别，由低到高依次为Read uncommitted、Read committed、Repeatable read、Serializable，这四个级别可以逐个解决脏读、不可重复读、幻读这几类问题。 SQL 标准定义了四个隔离级别： READ-UNCOMMITTED(读取未提交)： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。 READ-COMMITTED(读取已提交)： 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。 REPEATABLE-READ(可重复读)： 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。 SERIALIZABLE(可串行化)： 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。 Mysql 默认采用的 REPEATABLE_READ隔离级别 Oracle 默认采用的 READ_COMMITTED隔离级别 隔离级别与锁的关系 在Read Uncommitted级别下，读取数据不需要加共享锁，这样就不会跟被修改的数据上的排他锁冲突 在Read Committed级别下，读操作需要加共享锁，但是在语句执行完以后释放共享锁； 在Repeatable Read级别下，读操作需要加共享锁，但是在事务提交之前并不释放共享锁，也就是必须等待事务执行完毕以后才释放共享锁。 SERIALIZABLE 是限制性最强的隔离级别，因为该级别锁定整个范围的键，并一直持有锁，直到事务完成。 按照锁的粒度分数据库锁有哪些？ 行级锁:行级锁是Mysql中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。行级锁分为共享锁 和 排他锁。特点：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。 表级锁: 表级锁是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。最常使用的MYISAM与INNODB都支持表级锁定。表级锁定分为表共享读锁（共享锁）与表独占写锁（排他锁）。特点：开销小，加锁快；不会出现死锁；锁定粒度大，发出锁冲突的概率最高，并发度最低。 页级锁:页级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。 从锁的类别上分MySQL都有哪些锁呢？ 从锁的类别上来讲，有共享锁和排他锁。 共享锁: 又叫做读锁。 当用户要进行数据的读取时，对数据加上共享锁。共享锁可以同时加上多个。 排他锁: 又叫做写锁。 当用户要进行数据的写入时，对数据加上排他锁。排他锁只可以加一个，他和其他的排他锁，共享锁都相斥。 InnoDB存储引擎的锁的算法有哪三种？ Record lock：单个行记录上的锁 Gap lock：间隙锁，锁定一个范围，不包括记录本身 Next-key lock：record+gap 锁定一个范围，包含记录本身 什么是死锁？怎么解决？ 死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而导致恶性循环的现象。 常见的解决死锁的方法 如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会。 在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率； 对于非常容易产生死锁的业务部分，可以尝试使用升级锁定颗粒度，通过表级锁定来减少死锁产生的概率； 如果业务处理不好可以用分布式事务锁或者使用乐观锁 数据库的乐观锁和悲观锁是什么？怎么实现的？ 数据库管理系统（DBMS）中的并发控制的任务是确保在多个事务同时存取数据库中同一数据时不破坏事务的隔离性和统一性以及数据库的统一性。乐观并发控制（乐观锁）和悲观并发控制（悲观锁）是并发控制主要采用的技术手段。 悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。在查询完数据的时候就把事务锁起来，直到提交事务。实现方式：使用数据库中的锁机制 乐观锁：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。在修改数据的时候把事务锁起来，通过version的方式来进行锁定。实现方式：乐一般会使用版本号机制或CAS算法实现。 大表数据查询，怎么优化？ 优化shema、sql语句+索引； 第二加缓存，memcached, redis； 主从复制，读写分离； 垂直拆分，根据你模块的耦合度，将一个大的系统分为多个小的系统，也就是分布式系统 水平切分，针对数据量大的表，这一步最麻烦，最能考验技术水平，要选择一个合理的sharding key, 为了有好的查询效率，表结构也要改动，做一定的冗余，应用也要改，sql中尽量带sharding key，将数据定位到限定的表上去查，而不是扫描全部的表 超大分页怎么处理？ 超大的分页一般从两个方向上来解决: 数据库层面,这也是我们主要集中关注的(虽然收效没那么大),类似于select from table where age &gt; 20 limit 1000000,10这种查询其实也是有可以优化的余地的. 这条语句需要load1000000数据然后基本上全部丢弃,只取10条当然比较慢. 当时我们可以修改为select from table where id in (select id from table where age &gt; 20 limit 1000000,10).这样虽然也load了一百万的数据,但是由于索引覆盖,要查询的所有字段都在索引中,所以速度会很快. 同时如果ID连续的好,我们还可以select * from table where id &gt; 1000000 limit 10,效率也是不错的,优化的可能性有许多种,但是核心思想都一样,就是减少load的数据 从需求的角度减少这种请求…主要是不做类似的需求(直接跳转到几百万页之后的具体某一页.只允许逐页查看或者按照给定的路线走,这样可预测,可缓存)以及防止ID泄漏且连续被人恶意攻击 为什么要尽量设定一个主键？ 主键是数据库确保数据行在整张表唯一性的保障，即使业务上本张表没有主键，也建议添加一个自增长的ID列作为主键。设定了主键之后，在后续的删改查的时候可能更加快速以及确保操作数据范围安全。 主键使用自增ID还是UUID？ 推荐使用自增ID，不要使用UUID。 因为在InnoDB存储引擎中，主键索引是作为聚簇索引存在的，也就是说，主键索引的B+树叶子节点上存储了主键索引以及全部的数据(按照顺序)，如果主键索引是自增ID，那么只需要不断向后排列即可，如果是UUID，由于到来的ID与原来的大小不确定，会造成非常多的数据插入，数据移动，然后导致产生很多的内存碎片，进而造成插入性能的下降。 总之，在数据量大一些的情况下，用自增主键性能会好一些。 关于主键是聚簇索引，如果没有主键，InnoDB会选择一个唯一键来作为聚簇索引，如果没有唯一键，会生成一个隐式的主键。 字段为什么要求定义为not null？ null值会占用更多的字节，且会在程序中造成很多与预期不符的情况。 如果要存储用户的密码散列，应该使用什么字段进行存储？ 密码散列，盐，用户身份证号等固定长度的字符串应该使用char而不是varchar来存储，这样可以节省空间且提高检索效率。 数据库结构优化？ 一个好的数据库设计方案对于数据库的性能往往会起到事半功倍的效果。 需要考虑数据冗余、查询和更新的速度、字段的数据类型是否合理等多方面的内容。 将字段很多的表分解成多个表：对于字段较多的表，如果有些字段的使用频率很低，可以将这些字段分离出来形成新表。因为当一个表的数据量很大时，会由于使用频率低的字段的存在而变慢。 增加中间表：对于需要经常联合查询的表，可以建立中间表以提高查询效率。通过建立中间表，将需要通过联合查询的数据插入到中间表中，然后将原来的联合查询改为对中间表的查询。 增加冗余字段：设计数据表时应尽量遵循范式理论的规约，尽可能的减少冗余字段，让数据库设计看起来精致、优雅。但是，合理的加入冗余字段可以提高查询速度。表的规范化程度越高，表和表之间的关系越多，需要连接查询的情况也就越多，性能也就越差。 MySQL数据库cpu飙升到500%的话他怎么处理？ 当 cpu 飙升到 500%时，先用操作系统命令 top 命令观察是不是 mysqld 占用导致的，如果不是，找出占用高的进程，并进行相关处理。 如果是 mysqld 造成的， show processlist，看看里面跑的 session 情况，是不是有消耗资源的 sql 在运行。找出消耗高的 sql，看看执行计划是否准确， index 是否缺失，或者实在是数据量太大造成。 一般来说，肯定要 kill 掉这些线程(同时观察 cpu 使用率是否下降)，等进行相应的调整(比如说加索引、改 sql、改内存参数)之后，再重新跑这些 SQL。 也有可能是每个 sql 消耗资源并不多，但是突然之间，有大量的 session 连进来导致 cpu 飙升，这种情况就需要跟应用一起来分析为何连接数会激增，再做出相应的调整，比如说限制连接数等。 主从复制的作用？ 主数据库出现问题，可以切换到从数据库。 可以进行数据库层面的读写分离。 可以在从数据库上进行日常备份。 MySQL主从复制解决的问题？ 数据分布：随意开始或停止复制，并在不同地理位置分布数据备份 负载均衡：降低单个服务器的压力 高可用和故障切换：帮助应用程序避免单点失败 升级测试：可以用更高版本的MySQL作为从库 MySQL主从复制工作原理？ 在主库上把数据更高记录到二进制日志 从库将主库的日志复制到自己的中继日志 从库读取中继日志的事件，将其重放到从库数据中。 小福利 由于文章篇幅较长，陈某将其转换为PDF文档，老规矩，回复关键词Mysql面试题即可获取。 巨人的肩膀 https://www.cnblogs.com/hsmwlyl/p/10719152.html https://www.cnblogs.com/caomusheng/p/12586895.html https://article.itxueyuan.com/eoJEMj https://blog.csdn.net/thinkwon/article/details/104778621#comments]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Zookeeper实现分布式锁]]></title>
      <url>%2F2020%2F04%2F19%2FZookeeper%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%2F</url>
      <content type="text"><![CDATA[导读 真是有人(锁)的地方就有江湖(事务)，今天不谈江湖，来撩撩人。 分布式锁的概念、为什么使用分布式锁，想必大家已经很清楚了。前段时间作者写过Redis是如何实现分布式锁，今天这篇文章来谈谈Zookeeper是如何实现分布式锁的。 陈某今天分别从如下几个方面来详细讲讲ZK如何实现分布式锁： ZK的四种节点 排它锁的实现 读写锁的实现 Curator实现分步式锁 ZK的四种节点 持久性节点：节点创建后将会一直存在 临时节点：临时节点的生命周期和当前会话绑定，一旦当前会话断开临时节点也会删除，当然可以主动删除。 持久有序节点：节点创建一直存在，并且zk会自动为节点加上一个自增的后缀作为新的节点名称。 临时有序节点：保留临时节点的特性，并且zk会自动为节点加上一个自增的后缀作为新的节点名称。 排它锁的实现 排他锁的实现相对简单一点，利用了zk的创建节点不能重名的特性。如下图： 根据上图分析大致分为如下步骤： 尝试获取锁：创建临时节点，zk会保证只有一个客户端创建成功。 创建临时节点成功，获取锁成功，执行业务逻辑，业务执行完成后删除锁。 创建临时节点失败，阻塞等待。 监听删除事件，一旦临时节点删除了，表示互斥操作完成了，可以再次尝试获取锁。 递归：获取锁的过程是一个递归的操作，获取锁-&gt;监听-&gt;获取锁。 如何避免死锁：创建的是临时节点，当服务宕机会话关闭后临时节点将会被删除，锁自动释放。 代码实现 作者参照JDK锁的实现方式加上模板方法模式的封装，封装接口如下： 12345678910111213141516/** * @Description ZK分布式锁的接口 * @Author 陈某 * @Date 2020/4/7 22:52 */public interface ZKLock &#123; /** * 获取锁 */ void lock() throws Exception; /** * 解锁 */ void unlock() throws Exception;&#125; 模板抽象类如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/** * @Description 排他锁，模板类 * @Author 陈某 * @Date 2020/4/7 22:55 */public abstract class AbstractZKLockMutex implements ZKLock &#123; /** * 节点路径 */ protected String lockPath; /** * zk客户端 */ protected CuratorFramework zkClient; private AbstractZKLockMutex()&#123;&#125; public AbstractZKLockMutex(String lockPath,CuratorFramework client)&#123; this.lockPath=lockPath; this.zkClient=client; &#125; /** * 模板方法，搭建的获取锁的框架，具体逻辑交于子类实现 * @throws Exception */ @Override public final void lock() throws Exception &#123; //获取锁成功 if (tryLock())&#123; System.out.println(Thread.currentThread().getName()+"获取锁成功"); &#125;else&#123; //获取锁失败 //阻塞一直等待 waitLock(); //递归，再次获取锁 lock(); &#125; &#125; /** * 尝试获取锁，子类实现 */ protected abstract boolean tryLock() ; /** * 等待获取锁，子类实现 */ protected abstract void waitLock() throws Exception; /** * 解锁：删除节点或者直接断开连接 */ @Override public abstract void unlock() throws Exception;&#125; 排他锁的具体实现类如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283/** * @Description 排他锁的实现类，继承模板类 AbstractZKLockMutex * @Author 陈某 * @Date 2020/4/7 23:23 */@Datapublic class ZKLockMutex extends AbstractZKLockMutex &#123; /** * 用于实现线程阻塞 */ private CountDownLatch countDownLatch; public ZKLockMutex(String lockPath,CuratorFramework zkClient)&#123; super(lockPath,zkClient); &#125; /** * 尝试获取锁：直接创建一个临时节点，如果这个节点存在创建失败抛出异常，表示已经互斥了， * 反之创建成功 * @throws Exception */ @Override protected boolean tryLock() &#123; try &#123; zkClient.create() //临时节点 .withMode(CreateMode.EPHEMERAL) //权限列表 world:anyone:crdwa .withACL(ZooDefs.Ids.OPEN_ACL_UNSAFE) .forPath(lockPath,"lock".getBytes()); return true; &#125;catch (Exception ex)&#123; return false; &#125; &#125; /** * 等待锁，一直阻塞监听 * @return 成功获取锁返回true，反之返回false */ @Override protected void waitLock() throws Exception &#123; //监听节点的新增、更新、删除 final NodeCache nodeCache = new NodeCache(zkClient, lockPath); //启动监听 nodeCache.start(); ListenerContainer&lt;NodeCacheListener&gt; listenable = nodeCache.getListenable(); //监听器 NodeCacheListener listener=()-&gt; &#123; //节点被删除，此时获取锁 if (nodeCache.getCurrentData() == null) &#123; //countDownLatch不为null，表示节点存在，此时监听到节点删除了，因此-1 if (countDownLatch != null) countDownLatch.countDown(); &#125; &#125;; //添加监听器 listenable.addListener(listener); //判断节点是否存在 Stat stat = zkClient.checkExists().forPath(lockPath); //节点存在 if (stat!=null)&#123; countDownLatch=new CountDownLatch(1); //阻塞主线程，监听 countDownLatch.await(); &#125; //移除监听器 listenable.removeListener(listener); &#125; /** * 解锁，直接删除节点 * @throws Exception */ @Override public void unlock() throws Exception &#123; zkClient.delete().forPath(lockPath); &#125;&#125; 可重入性排他锁如何设计 可重入的逻辑很简单，在本地保存一个ConcurrentMap，key是当前线程，value是定义的数据，结构如下： 1private final ConcurrentMap&lt;Thread, LockData&gt; threadData = Maps.newConcurrentMap(); 重入的伪代码如下： 123456public boolean tryLock()&#123; //判断当前线程是否在threadData保存过 //存在，直接return true //不存在执行获取锁的逻辑 //获取成功保存在threadData中&#125; 读写锁的实现 读写锁分为读锁和写锁，区别如下： 读锁允许多个线程同时读数据，但是在读的同时不允许写线程修改。 写锁在获取后，不允许多个线程同时写或者读。 如何实现读写锁？ZK中有一类节点叫临时有序节点，上文有介绍。下面我们来利用临时有序节点来实现读写锁的功能。 读锁的设计 读锁允许多个线程同时进行读，并且在读的同时不允许线程进行写操作，实现原理如下图： 根据上图，获取一个读锁分为以下步骤： 创建临时有序节点（当前线程拥有的读锁或称作读节点）。 获取路径下所有的子节点，并进行从小到大排序 获取当前节点前的临近写节点(写锁)。 如果不存在的临近写节点，则成功获取读锁。 如果存在临近写节点，对其监听删除事件。 一旦监听到删除事件，重复2,3,4,5的步骤(递归)。 写锁的设计 线程一旦获取了写锁，不允许其他线程读和写。实现原理如下： 从上图可以看出唯一和写锁不同的就是监听的节点，这里是监听临近节点(读节点或者写节点)，读锁只需要监听写节点，步骤如下： 创建临时有序节点（当前线程拥有的写锁或称作写节点）。 获取路径下的所有子节点，并进行从小到大排序。 获取当前节点的临近节点(读节点和写节点)。 如果不存在临近节点，则成功获取锁。 如果存在临近节点，对其进行监听删除事件。 一旦监听到删除事件，重复2,3,4,5的步骤(递归)。 如何监听 无论是写锁还是读锁都需要监听前面的节点，不同的是读锁只监听临近的写节点，写锁是监听临近的所有节点，抽象出来看其实是一种链式的监听，如下图： 每一个节点都在监听前面的临近节点，一旦前面一个节点删除了，再从新排序后监听前面的节点，这样递归下去。 代码实现 作者简单的写了读写锁的实现，先造出来再优化，不建议用在生产环境。代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140public class ZKLockRW &#123; /** * 节点路径 */ protected String lockPath; /** * zk客户端 */ protected CuratorFramework zkClient; /** * 用于阻塞线程 */ private CountDownLatch countDownLatch=new CountDownLatch(1); private final static String WRITE_NAME="_W_LOCK"; private final static String READ_NAME="_R_LOCK"; public ZKLockRW(String lockPath, CuratorFramework client) &#123; this.lockPath=lockPath; this.zkClient=client; &#125; /** * 获取锁，如果获取失败一直阻塞 * @throws Exception */ public void lock() throws Exception &#123; //创建节点 String node = createNode(); //阻塞等待获取锁 tryLock(node); countDownLatch.await(); &#125; /** * 创建临时有序节点 * @return * @throws Exception */ private String createNode() throws Exception &#123; //创建临时有序节点 return zkClient.create() .withMode(CreateMode.EPHEMERAL_SEQUENTIAL) .withACL(ZooDefs.Ids.OPEN_ACL_UNSAFE) .forPath(lockPath); &#125; /** * 获取写锁 * @return */ public ZKLockRW writeLock()&#123; return new ZKLockRW(lockPath+WRITE_NAME,zkClient); &#125; /** * 获取读锁 * @return */ public ZKLockRW readLock()&#123; return new ZKLockRW(lockPath+READ_NAME,zkClient); &#125; private void tryLock(String nodePath) throws Exception &#123; //获取所有的子节点 List&lt;String&gt; childPaths = zkClient.getChildren() .forPath("/") .stream().sorted().map(o-&gt;"/"+o).collect(Collectors.toList()); //第一个节点就是当前的锁，直接获取锁。递归结束的条件 if (nodePath.equals(childPaths.get(0)))&#123; countDownLatch.countDown(); return; &#125; //1. 读锁：监听最前面的写锁，写锁释放了，自然能够读了 if (nodePath.contains(READ_NAME))&#123; //查找临近的写锁 String preNode = getNearWriteNode(childPaths, childPaths.indexOf(nodePath)); if (preNode==null)&#123; countDownLatch.countDown(); return; &#125; NodeCache nodeCache=new NodeCache(zkClient,preNode); nodeCache.start(); ListenerContainer&lt;NodeCacheListener&gt; listenable = nodeCache.getListenable(); listenable.addListener(() -&gt; &#123; //节点删除事件 if (nodeCache.getCurrentData()==null)&#123; //继续监听前一个节点 String nearWriteNode = getNearWriteNode(childPaths, childPaths.indexOf(preNode)); if (nearWriteNode==null)&#123; countDownLatch.countDown(); return; &#125; tryLock(nearWriteNode); &#125; &#125;); &#125; //如果是写锁，前面无论是什么锁都不能读，直接循环监听上一个节点即可，直到前面无锁 if (nodePath.contains(WRITE_NAME))&#123; String preNode = childPaths.get(childPaths.indexOf(nodePath) - 1); NodeCache nodeCache=new NodeCache(zkClient,preNode); nodeCache.start(); ListenerContainer&lt;NodeCacheListener&gt; listenable = nodeCache.getListenable(); listenable.addListener(() -&gt; &#123; //节点删除事件 if (nodeCache.getCurrentData()==null)&#123; //继续监听前一个节点 tryLock(childPaths.get(childPaths.indexOf(preNode) - 1&lt;0?0:childPaths.indexOf(preNode) - 1)); &#125; &#125;); &#125; &#125; /** * 查找临近的写节点 * @param childPath 全部的子节点 * @param index 右边界 * @return */ private String getNearWriteNode(List&lt;String&gt; childPath,Integer index)&#123; for (int i = 0; i &lt; index; i++) &#123; String node = childPath.get(i); if (node.contains(WRITE_NAME)) return node; &#125; return null; &#125;&#125; Curator实现分步式锁 Curator是Netflix公司开源的一个Zookeeper客户端，与Zookeeper提供的原生客户端相比，Curator的抽象层次更高，简化了Zookeeper客户端的开发量。 Curator在分布式锁方面已经为我们封装好了，大致实现的思路就是按照作者上述的思路实现的。中小型互联网公司还是建议直接使用框架封装好的，毕竟稳定，有些大型的互联公司都是手写的，牛逼啊。 创建一个排他锁很简单，如下： 123456//arg1：CuratorFramework连接对象，arg2：节点路径lock=new InterProcessMutex(client,path);//获取锁lock.acquire();//释放锁lock.release(); 更多的API请参照官方文档，不是此篇文章重点。 至此ZK实现分布式锁就介绍完了，如有想要源码的朋友，老规矩，回复关键词分布式锁获取。 一点小福利 对于Zookeeper不太熟悉的朋友，陈某特地花费两天时间总结了ZK的常用知识点，包括ZK常用shell命令、ZK权限控制、Curator的基本操作API。目录如下： 需要上面PDF文件的朋友，老规矩，回复关键词ZK总结。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Zookeeper入门]]></title>
      <url>%2F2020%2F04%2F19%2FZookeeper%E5%85%A5%E9%97%A8%2F</url>
      <content type="text"><![CDATA[导读 Zookeeper 相信大家都听说过，最典型的使用就是作为服务注册中心。今天陈某带大家从零基础入门 Zookeeper，看了本文，你将会对 Zookeeper 有了初步的了解和认识。 注意：本文基于 Zookeeper 的版本是 3.4.14，最新版本的在使用上会有一些出入，但是企业现在使用的大部分都是 3.4x 版本的。 Zookeeper 概述 Zookeeper 是一个分布式协调服务的开源框架。主要用来解决分布式集群中应用系统的一致性问题，例如怎样避免同时操作同一数据造成脏读的问题。 ZooKeeper 本质上是一个分布式的小文件存储系统。提供基于类似于文件系 统的目录树方式的数据存储，并且可以对树中的节点进行有效管理。从而用来维护和监控你存储的数据的状态变化。通过监控这些数据状态的变化，从而可以达 到基于数据的集群管理。诸如：统一命名服务、分布式配置管理、分布式消息队列、分布式锁、分布式协调等功能。 Zookeeper 特性 全局数据一致：每个 server 保存一份相同的数据副本，client 无论连 接到哪个 server，展示的数据都是一致的，这是最重要的特征； 可靠性：如果消息被其中一台服务器接受，那么将被所有的服务器接受。 顺序性：包括全局有序和偏序两种：全局有序是指如果在一台服务器上 消息 a 在消息 b 前发布，则在所有 Server 上消息 a 都将在消息 b 前被 发布；偏序是指如果一个消息 b 在消息 a 后被同一个发送者发布，a 必将排在 b 前面。 数据更新原子性：一次数据更新要么成功（半数以上节点成功），要么失 败，不存在中间状态； 实时性：Zookeeper 保证客户端将在一个时间间隔范围内获得服务器的更新信息，或者服务器失效的信息。 Zookeeper 节点类型 Znode 有两种，分别为临时节点和永久节点。 临时节点：该节点的生命周期依赖于创建它们的会话。一旦会话结束，临时节点将被自动删除，当然可以也可以手动删除。临时节点不允许拥有子节点。 永久节点：该节点的生命周期不依赖于会话，并且只有在客户端显示执行删除操作的时候，他们才能被删除。 节点的类型在创建时即被确定，并且不能改变。 Znode 还有一个序列化的特性，如果创建的时候指定的话，该 Znode 的名字后面会自动追加一个不断增加的序列号。序列号对于此节点的父节点来说是唯一的，这样便会记录每个子节点创建的先后顺序。它的格式为&quot;%10d&quot;(10 位数字,没有数值的数位用 0 补充，例如“0000000001”)。 这样便会存在四种类型的 Znode 节点，分类如下： PERSISTENT：永久节点 EPHEMERAL：临时节点 PERSISTENT_SEQUENTIAL：永久节点、序列化 EPHEMERAL_SEQUENTIAL：临时节点、序列化 ZooKeeper Watcher ZooKeeper 提供了分布式数据发布/订阅功能，一个典型的发布/订阅模型系统定义了一种一对多的订阅关系，能让多个订阅者同时监听某一个主题对象，当这个主题对象自身状态变化时，会通知所有订阅者，使他们能够做出相应的处理。 触发事件种类很多，如：节点创建，节点删除，节点改变，子节点改变等。 总的来说可以概括 Watcher 为以下三个过程：客户端向服务端注册 Watcher、服务端事件发生触发 Watcher、客户端回调 Watcher 得到触发事件情况。 Watcher 机制特点 一次性触发 ：事件发生触发监听，一个 watcher event 就会被发送到设置监听的客户端，这种效果是一次性的，后续再次发生同样的事件，不会再次触发。 事件封装 ：ZooKeeper 使用 WatchedEvent 对象来封装服务端事件并传递。WatchedEvent 包含了每一个事件的三个基本属性： 通知状态（keeperState），事件类型（EventType）和节点路径（path）。 event 异步发送 ：watcher 的通知事件从服务端发送到客户端是异步的。 先注册再触发 ：Zookeeper 中的 watch 机制，必须客户端先去服务端注册监听，这样事件发送才会触发监听，通知给客户端。 常用 Shell 命令新增节点1create [-s] [-e] path data -s：表示创建有序节点 -e：表示创建临时节点 创建持久化节点： 1234create /test 1234## 子节点create /test/node1 node1 创建持久化有序节点： 1234567## 完整的节点名称是a0000000001create /a aCreated /a0000000001## 完整的节点名称是b0000000002create /b bCreated /b0000000002 创建临时节点： 1create -e /a a 创建临时有序节点： 123## 完整的节点名称是a0000000001create -e -s /a aCreated /a0000000001 更新节点1set [path] [data] [version] path：节点路径 data：数据 version：版本号 修改节点数据： 1234set /test aaa## 修改子节点set /test/node1 bbb 基于数据版本号修改，如果修改的节点的版本号(dataVersion)不正确，拒绝修改 1set /test aaa 1 删除节点1delete [path] [version] path：节点路径 version：版本号，版本号不正确拒绝删除 删除节点 1234delete /test## 版本号删除delete /test 2 递归删除，删除某个节点及后代 1rmr /test 查看节点数据和状态 命令格式如下： 1get path 获取节点详情： 12345678910111213141516## 获取节点详情get /node1## 节点内容aaacZxid = 0x6ctime = Sun Apr 05 14:50:10 CST 2020mZxid = 0x6mtime = Sun Apr 05 14:50:10 CST 2020pZxid = 0x7cversion = 1dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 3numChildren = 1 节点各个属性对应的含义如下： cZxid：数据节点创建时的事务 ID。 ctime：数据节点创建时间。 mZxid：数据节点最后一次更新时的事务 ID。 mtime：数据节点最后一次更新的时间。 pZxid：数据节点的子节点最后一次被修改时的事务 ID。 cversion：子节点的更改次数。 dataVersion：节点数据的更改次数。 aclVersion ：节点 ACL 的更改次数。 ephemeralOwner：如果节点是临时节点，则表示创建该节点的会话的 SessionID。如果节点是持久化节点，值为 0。 dataLength ：节点数据内容的长度。 numChildren：数据节点当前的子节点的个数。 查看节点状态1stat path stat命令和get命令相似，不过这个命令不会返回节点的数据，只返回节点的状态属性。 1234567891011121314stat /node1## 节点状态信息，没有节点数据cZxid = 0x6ctime = Sun Apr 05 14:50:10 CST 2020mZxid = 0x6mtime = Sun Apr 05 14:50:10 CST 2020pZxid = 0x7cversion = 1dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 3numChildren = 1 查看节点列表 查看节点列表有ls path和ls2 path两个命令。后者是前者的增强，不仅会返回节点列表还会返回当前节点的状态信息。 ls path： 1234ls /## 仅仅返回节点列表[zookeeper, node1] ls2 path： 123456789101112131415ls2 /## 返回节点列表和当前节点的状态信息[zookeeper, node1]cZxid = 0x0ctime = Thu Jan 01 08:00:00 CST 1970mZxid = 0x0mtime = Thu Jan 01 08:00:00 CST 1970pZxid = 0x6cversion = 2dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 0numChildren = 2 监听器 get path watch 使用get path watch注册的监听器在节点内容发生改变时，向客户端发送通知，注意 Zookeeper 的触发器是一次性的，触发一次后会立即生效。 12345678get /node1 watch## 改变节点数据set /node1 bbb## 监听到节点内容改变了WATCHER::WatchedEvent state:SyncConnected type:NodeDataChanged path:/node1 监听器 stat path watch stat path watch注册的监听器能够在节点状态发生改变时向客户端发出通知。比如节点数据改变、节点被删除等。 12345678stat /node2 watch## 删除节点node2delete /node2## 监听器监听到了节点删除WATCHER::WatchedEvent state:SyncConnected type:NodeDeleted path:/node2 监听器 ls/ls2 path watch 使用ls path watch或者ls2 path watch注册的监听器，能够监听到该节点下的子节点的增加和删除操作。 12345678ls /node1 watch## 创建子节点create /node1/b b## 监听到了子节点的新增WATCHER::WatchedEvent state:SyncConnected type:NodeChildrenChanged path:/node1 Zookeeper 的 ACL 权限控制 zookeeper 类似文件控制系统，client 可以创建，删除，修改，查看节点，那么如何做到权限控制的呢？zookeeper 的access control list 访问控制列表可以做到这一点。 ACL 权限控制，使用scheme:id:permission来标识。 权限模式(scheme)：授权的策略 授权对象(id)：授权的对象 权限(permission)：授予的权限 权限控制是基于每个节点的，需要对每个节点设置权限。 每个节点支持设置多种权限控制方案和多个权限。 子节点不会继承父节点的权限，客户端无权访问某节点，但可能可以访问它的子节点。 例如：根据 IP 地址进行授权，命令如下： 1setACl /node1 ip:192.168.10.1:crdwa 权限模式 权限模式即是采用何种方式授权。 world：只有一个用户，anyone，表示登录 zookeeper 所有人（默认的模式）。 ip：对客户端使用 IP 地址认证。 auth：使用已添加认证的用户认证。 digest：使用用户名:密码方式认证。 授权对象 给谁授权，授权对象的 ID 指的是权限赋予的实体，例如 IP 地址或用户。 授予的权限 授予的权限包括create、delete、read、writer、admin。也就是增、删、改、查、管理的权限，简写cdrwa。 注意：以上 5 种权限中，delete是指对子节点的删除权限，其他 4 种权限是对自身节点的操作权限。 create：简写c，可以创建子节点。 delete：简写d，可以删除子节点（仅下一级节点）。 read：简写r，可以读取节点数据以及显示子节点列表。 write：简写w，可以更改节点数据。 admin：简写a，可以设置节点访问控制列表权限。 授权相关命令 getAcl [path]：读取指定节点的 ACL 权限。 setAcl [path] [acl]：设置 ACL addauth &lt;scheme&gt; &lt;auth&gt;：添加认证用户，和 auth，digest 授权模式相关。 world 授权模式案例 zookeeper 中默认的授权模式，针对登录 zookeeper 的任何用户授予指定的权限。命令如下： 1setAcl [path] world:anyone:[permission] path：节点 permission：授予的权限，比如cdrwa 去掉不能读取节点数据的权限： 12345678910111213141516171819## 获取权限列表（默认的）getAcl /node2'world,'anyone: cdrwa## 去掉读取节点数据的的权限，去掉rsetAcl /node2 world:anyone:cdwa## 再次获取权限列表getAcl /node2'world,'anyone: cdwa## 获取节点数据，没有权限，失败get /node2Authentication is not valid : /node2 IP 授权模式案例 针对登录用户的 ip 进行限制权限。命令如下： 1setAcl [path] ip:[ip]:[acl] 远程登录 zookeeper 的命令如下： 1./zkCli.sh -server ip 设置192.168.10.1这个 ip 的增删改查管理的权限。 1setAcl /node2 ip:192.168.10.1:crdwa Auth 授权模式案例 auth 授权模式需要有一个认证用户，添加命令如下： 1addauth digest [username]:[password] 设置 auth 授权模式命令如下： 1setAcl [path] auth:[user]:[acl] 为chenmou这个账户添加 cdrwa 权限： 12345## 添加一个认证账户addauth digest chenmou:123456## 添加权限setAcl /node2 auth:chenmou:crdwa 多种模式授权 zookeeper 中同一个节点可以使用多种授权模式，多种授权模式用,分隔。 12345678## 创建节点create /node3## 添加认证用户addauth chenmou:123456## 添加多种授权模式setAcl /node3 ip:192.178.10.1:crdwa,auth:chenmou:crdwa ACL 超级管理员 zookeeper 的权限管理模式有一种叫做super，该模式提供一个超管可以方便的访问任何权限的节点。 假设这个超管是super:admin，需要先为超管生成密码的密文： 1234echo -n super:admin | openssl dgst -binary -sha1 |openssl base64## 执行完生成了秘钥xQJmxLMiHGwaqBvst5y6rkB6HQs= 打开zookeeper目录下/bin/zkServer.sh，找到如下一行： 1nohup JAVA&amp;quot;−Dzookeeper.log.dir=JAVA"−Dzookeeper.log.dir=&#123;ZOO_LOG_DIR&#125;" "-Dzookeeper.root.logger=$&#123;ZOO_LOG4J_PROP&#125;" 在后面添加一行脚本，如下： 1"-Dzookeeper.DigestAuthenticationProvider.superDigest=super:xQJmxLMiHGwaqBvst5y6rkB6HQs=" 此时完整的脚本如下： 12nohup "$JAVA" "-Dzookeeper.log.dir=$&#123;ZOO_LOG_DIR&#125;" "-Dzookeeper.root.logger=$&#123;ZOO_LOG4J_PROP&#125;" "-Dzookeeper.DigestAuthenticationProvider.superDigest=super:xQJmxLMiHGwaqBvst5y6rkB6HQs=" \ -cp "$CLASSPATH" $JVMFLAGS $ZOOMAIN "$ZOOCFG" &gt; "$_ZOO_DAEMON_OUT" 2&gt;&amp;1 &lt; /dev/null &amp; 重启 zookeeper 重启完成之后此时超管即配置完成，如果需要使用，则使用如下命令： 1addauth digest super:admin Curator 客户端 Curator 是 Netflix 公司开源的一个 Zookeeper 客户端，与 Zookeeper 提供的原生客户端相比，Curator 的抽象层次更高，简化了 Zookeeper 客户端的开发量。 添加依赖1234567891011121314151617&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;version&gt;4.0.0&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.10&lt;/version&gt; &lt;/dependency&gt; 建立连接 客户端建立与 Zookeeper 的连接，这里仅仅演示单机版本的连接，如下： 12345678910111213//创建CuratorFramework，用来操作apiCuratorFramework client = CuratorFrameworkFactory.builder() //ip地址+端口号，如果是集群，逗号分隔 .connectString("120.26.101.207:2181") //会话超时时间 .sessionTimeoutMs(5000) //超时重试策略,RetryOneTime：超时重连仅仅一次 .retryPolicy(new RetryOneTime(3000)) //命名空间，父节点，如果不指定是在根节点下 .namespace("node4") .build();//启动client.start(); 重连策略 会话连接策略，即是当客户端与 Zookeeper 断开连接之后，客户端重新连接 Zookeeper 时使用的策略，比如重新连接一次。 RetryOneTime：N 秒后重连一次，仅仅一次，演示如下： 1.retryPolicy(new RetryOneTime(3000)) RetryNTimes：每 n 秒重连一次，重连 m 次。演示如下： 12//每三秒重连一次，重连3次。arg1：多长时间后重连，单位毫秒，arg2：总共重连几次.retryPolicy(new RetryNTimes(3000,3)) RetryUntilElapsed：设置了最大等待时间，如果超过这个最大等待时间将会不再连接。 12//每三秒重连一次，等待时间超过10秒不再重连。arg1：总等待时间，arg2：多长时间重连，单位毫秒.retryPolicy(new RetryUntilElapsed(10000,3000)) 新增节点 新增节点 1234567client.create() //指定节点的类型。PERSISTENT：持久化节点，PERSISTENT_SEQUENTIAL：持久化有序节点，EPHEMERAL：临时节点，EPHEMERAL_SEQUENTIAL临时有序节点 .withMode(CreateMode.PERSISTENT) //指定权限列表，OPEN_ACL_UNSAFE：world:anyone:crdwa .withACL(ZooDefs.Ids.OPEN_ACL_UNSAFE) //写入节点数据，arg1:节点名称 arg2:节点数据 .forPath("/a", "a".getBytes()); 自定义权限列表：withACL(acls)方法中可以设置自定义的权限列表，代码如下： 1234567891011//自定义权限列表List&lt;ACL&gt; acls=new ArrayList&lt;&gt;();//指定授权模式和授权对象 arg1:授权模式，arg2授权对象Id id=new Id("ip","127.0.0.1");//指定授予的权限，ZooDefs.Perms.ALL:crdwaacls.add(new ACL(ZooDefs.Perms.ALL,id));client.create() .withMode(CreateMode.PERSISTENT) //指定自定义权限列表 .withACL(acls) .forPath("/b", "b".getBytes()); 递归创建节点：creatingParentsIfNeeded()方法对于创建多层节点，如果其中一个节点不存在的话会自动创建 12345678//递归创建节点client.create() //递归方法，如果节点不存在，那么创建该节点 .creatingParentsIfNeeded() .withMode(CreateMode.PERSISTENT) .withACL(ZooDefs.Ids.OPEN_ACL_UNSAFE) //test节点和b节点不存在，递归创建出来 .forPath("/test/a", "a".getBytes()); 异步创建节点：inBackground()方法可以异步回调创建节点，创建完成后会自动回调实现的方法 1234567891011121314151617 //异步创建节点client.create() .withMode(CreateMode.PERSISTENT) .withACL(ZooDefs.Ids.OPEN_ACL_UNSAFE) //异步创建 .inBackground(new BackgroundCallback() &#123; /** * @param curatorFramework 客户端对象 * @param curatorEvent 事件对象 */ @Override public void processResult(CuratorFramework curatorFramework, CuratorEvent curatorEvent) throws Exception &#123; //打印事件类型 System.out.println(curatorEvent.getType()); &#125; &#125;) .forPath("/test1", "a".getBytes()); 更新节点数据 更新节点，当节点不存在会报错，代码如下： 12client.setData() .forPath("/a","a".getBytes()); 携带版本号更新节点，当版本错误拒绝更新 1234client.setData() //指定版本号更新，如果版本号错误则拒绝更新 .withVersion(1) .forPath("/a","a".getBytes()); 异步更新节点数据： 123456789client.setData() //异步更新 .inBackground(new BackgroundCallback() &#123; //回调方法 @Override public void processResult(CuratorFramework curatorFramework, CuratorEvent curatorEvent) throws Exception &#123; &#125; &#125;) .forPath("/a","a".getBytes()); 删除节点 删除当前节点，如果有子节点则拒绝删除 123client.delete() //删除节点，如果是该节点包含子节点，那么不能删除 .forPath("/a"); 指定版本号删除，如果版本错误则拒绝删除 12345client.delete() //指定版本号删除 .withVersion(1) //删除节点，如果是该节点包含子节点，那么不能删除 .forPath("/a"); 如果当前节点包含子节点则一并删除，使用deletingChildrenIfNeeded()方法 12345client.delete() //如果删除的节点包含子节点则一起删除 .deletingChildrenIfNeeded() //删除节点，如果是该节点包含子节点，那么不能删除 .forPath("/a"); 异步删除节点，使用inBackground() 1234567891011client.delete() .deletingChildrenIfNeeded() //异步删除节点 .inBackground(new BackgroundCallback() &#123; @Override public void processResult(CuratorFramework curatorFramework, CuratorEvent curatorEvent) throws Exception &#123; //回调监听 &#125; &#125;) //删除节点，如果是该节点包含子节点，那么不能删除 .forPath("/a"); 获取节点数据 同步获取节点数据 12byte[] bytes = client.getData().forPath("/node1");System.out.println(new String(bytes)); 获取节点状态和数据 123456789//保存节点状态Stat stat=new Stat();byte[] bytes = client.getData() //获取节点状态存储在stat对象中 .storingStatIn(stat) .forPath("/node1");System.out.println(new String(bytes));//获取节点数据的长度System.out.println(stat.getDataLength()); 异步获取节点数据 1234567client.getData() //异步获取节点数据，回调监听 .inBackground((curatorFramework, curatorEvent) -&gt; &#123; //节点数据 System.out.println(new String(curatorEvent.getData())); &#125;) .forPath("/node1"); 获取子节点 同步获取全部子节点 1234List&lt;String&gt; strs = client.getChildren().forPath("/"); for (String str:strs) &#123; System.out.println(str); &#125; 异步获取全部子节点 123456789client.getChildren()//异步获取.inBackground((curatorFramework, curatorEvent) -&gt; &#123; List&lt;String&gt; strs = curatorEvent.getChildren(); for (String str:strs) &#123; System.out.println(str); &#125; &#125;).forPath("/"); 查看节点是否存在 同步查看 12//如果节点不存在，stat为nullStat stat = client.checkExists().forPath("/node"); 异步查看 1234567//如果节点不存在，stat为nullclient.checkExists() .inBackground((curatorFramework, curatorEvent) -&gt; &#123; //如果为null则不存在 System.out.println(curatorEvent.getStat()); &#125;) .forPath("/node"); Watcher API curator 提供了两种 watcher 来监听节点的变化 NodeCache：监听一个特定的节点，监听新增和修改 PathChildrenCache：监听一个节点的子节点，当一个子节点增加、删除、更新时，path Cache 会改变他的状态，会包含最新的子节点的数据和状态。 NodeCache 演示： 123456789101112131415//arg1:连接对象 arg2:监听的节点路径,/namespace/pathfinal NodeCache nodeCache = new NodeCache(client, "/w1");//启动监听nodeCache.start();//添加监听器nodeCache.getListenable().addListener(() -&gt; &#123; //节点路径 System.out.println(nodeCache.getCurrentData().getPath()); //节点数据 System.out.println(new String(nodeCache.getCurrentData().getData()));&#125;);//睡眠100秒Thread.sleep(1000000);//关闭监听nodeCache.close(); PathChildrenCache演示： 123456789101112//arg1：连接对象 arg2：节点路径 arg3:是否能够获取节点数据PathChildrenCache cache=new PathChildrenCache(client,"/w1", true);cache.start();cache.getListenable().addListener((curatorFramework, pathChildrenCacheEvent) -&gt; &#123; //节点路径 System.out.println(pathChildrenCacheEvent.getData().getPath()); //节点状态 System.out.println(pathChildrenCacheEvent.getData().getStat()); //节点数据 System.out.println(new String(pathChildrenCacheEvent.getData().getData()));&#125;);cache.close(); 小福利 是不是觉得文章太长看得头晕脑胀，为此陈某特地将本篇文章制作成 PDF 文本，需要回去仔细研究的朋友，老规矩，回复关键词ZK入门指南。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Mysql中orderby底层执行流程]]></title>
      <url>%2F2020%2F04%2F19%2FMysql%E4%B8%ADorderby%E5%BA%95%E5%B1%82%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B%2F</url>
      <content type="text"><![CDATA[前言 在实际的开发中一定会碰到根据某个字段进行排序后来显示结果的需求，但是你真的理解order by在 Mysql 底层是如何执行的吗？ 假设你要查询城市是苏州的所有人名字，并且按照姓名进行排序返回前 1000 个人的姓名、年龄，这条 sql 语句应该如何写？ 首先创建一张用户表，sql 语句如下： 12345678CREATE TABLE user ( id int(11) NOT NULL, city varchar(16) NOT NULL, name varchar(16) NOT NULL, age int(11) NOT NULL, PRIMARY KEY (id), KEY city (city)) ENGINE=InnoDB; 则上述需求的 sql 查询语句如下： 1select city,name,age from user where city='苏州' order by name limit 1000; 这条 sql 查询语句相信大家都能写出来，但是你了解它在 Mysql 底层的执行流程吗？今天陈某来大家聊一聊这条 sql 语句是如何执行的以及有什么参数会影响执行的流程。 本篇文章分为如下几个部分进行详细的阐述： 全字段排序 rowid 排序 全字段排序 VS rowid 排序 如何避免排序 全字段排序 前面聊过索引能够避免全表扫描，因此我们给city这个字段上添加了索引，当然城市的字段很小，不用考虑字符串的索引问题，之前有写过一篇关于如何给字符串的加索引的文章，有不了解朋友看一下这篇文章:Mysql 性能优化：如何给字符串加索引？ 此时用Explain来分析一下的这条查询语句的执行情况，结果如下图： Extra这个字段中的Using filesort表示的就是需要排序，MySQL 会给每个线程分配一块内存用于排序，称为sort_buffer。 既然使用了索引进行查询，我们来简单的画一下city这棵索引树的结构，如下图： 从上图可以看出，满足city=&#39;苏州&#39;是从ID3到IDX这些记录。 通常情况下，此条 sql 语句执行流程如下： 初始化 sort_buffer，确定放入 name、city、age 这三个字段。 从索引 city 找到第一个满足city=&#39;苏州&#39;条件的主键id，也就是图中的ID3。 到主键id索引取出整行，取name、city、age三个字段的值，存入sort_buffer中。 从索引city取下一个记录的主键 id。 重复步骤 3、4 直到 city 的值不满足查询条件为止，对应的主键 id 也就是图中的IDX。 对sort_buffer中的数据按照字段name做快速排序。 按照排序结果取前 1000 行返回给客户端。 我们称这个排序过程为全字段排序，执行的流程图如下： 图中按name排序这个动作，可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数sort_buffer_size。 sort_buffer_size：就是 MySQL 为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。 rowid 排序 在上面这个算法过程里面，只对原表的数据读了一遍，剩下的操作都是在sort_buffer和临时文件中执行的。但这个算法有一个问题，就是如果查询要返回的字段很多的话，那么sort_buffer里面要放的字段数太多，这样内存里能够同时放下的行数很少，要分成很多个临时文件，排序的性能会很差。 所以如果单行很大，这个方法效率不够好。 我们可以修改一个max_length_for_sort_data这个参数使其使用另外一种算法。max_length_for_sort_data，是 MySQL 中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL 就认为单行太大，要换一个算法。 city、name、age 这三个字段的定义总长度是36，我把max_length_for_sort_data设置为 16，我们再来看看计算过程有什么改变。设置的 sql 语句如下： 1SET max_length_for_sort_data = 16; 新的算法放入 sort_buffer 的字段，只有要排序的列（即 name 字段）和主键 id。 但这时，排序的结果就因为少了 city 和 age 字段的值，不能直接返回了，整个执行流程就变成如下所示的样子： 初始化sort_buffer，确定放入两个字段，即name和id。 从索引 city 找到第一个满足city=&#39;苏州&#39;条件的主键id，也就是图中的ID3。 到主键id索引取出整行，取 name、id 这两个字段，存入 sort_buffer 中。 从索引city取下一个记录的主键 id。 重复步骤 3、4 直到 city 的值不满足查询条件为止，对应的主键 id 也就是图中的IDX。 对sort_buffer中的数据按照字段name做快速排序。 遍历排序结果，取前 1000 行，并按照 id 的值回到原表中取出 city、name 和 age 三个字段返回给客户端。 这个执行流程的示意图如下，我把它称为rowid排序。 对比全字段排序，rowid排序多了一次回表查询，即是多了第7步的查询主键索引树。 全字段排序 VS rowid 排序 如果 MySQL 实在是担心排序内存太小，会影响排序效率，才会采用 rowid 排序算法，这样排序过程中一次可以排序更多行，但是需要再回到原表去取数据。 如果 MySQL 认为内存足够大，会优先选择全字段排序，把需要的字段都放到 sort_buffer 中，这样排序后就会直接从内存里面返回查询结果了，不用再回到原表去取数据。 这也就体现了 MySQL 的一个设计思想：如果内存够，就要多利用内存，尽量减少磁盘访问。 对于 InnoDB 表来说，rowid 排序会要求回表多造成磁盘读，因此不会被优先选择。 如何避免排序 其实，并不是所有的order by语句，都需要排序操作的。从上面分析的执行过程，我们可以看到，MySQL 之所以需要生成临时表，并且在临时表上做排序操作，其原因是原来的数据都是无序的。 如果能够保证从city这个索引上取出来的行，天然就是按照 name 递增排序的话，是不是就可以不用再排序了呢？ 因此想到了联合索引，创建(city,name)联合索引，sql 语句如下： 1alter table user add index city_user(city, name); 此时的索引树如下： 在这个索引里面，我们依然可以用树搜索的方式定位到第一个满足city=&#39;苏州&#39;的记录，并且额外确保了，接下来按顺序取“下一条记录”的遍历过程中，只要 city 的值是苏州，name 的值就一定是有序的。 按照上图，整个查询的流程如下： 从索引(city,name)找到第一个满足 city=’苏州’条件的主键 id。 到主键 id 索引取出整行，取 name、city、age 三个字段的值，作为结果集的一部分直接返回。 从索引(city,name)取下一个记录主键 id。 重复步骤 2、3，直到查到第 1000 条记录，或者是不满足 city=’苏州’条件时循环结束。 对应的流程图如下： 可以看到，这个查询过程不需要临时表，也不需要排序。接下来，我们用 explain 的结果来印证一下。 从图中可以看到，Extra字段中没有Using filesort了，也就是不需要排序了。而且由于(city,name)这个联合索引本身有序，所以这个查询也不用把 4000 行全都读一遍，只要找到满足条件的前 1000 条记录就可以退出了。也就是说，在我们这个例子里，只需要扫描 1000 次。 难道仅仅这样就能满足了？此条查询语句是否能再优化呢？ 朋友们还记得覆盖索引吗？覆盖索引的好处就是能够避免再次回表查询，不了解的朋友们可以看一下陈某之前写的文章：Mysql 性能优化：如何使用覆盖索引？。 我们创建(city,name,age)联合索引，这样在执行上面的查询语句就能使用覆盖索引了，避免了回表查询了，sql 语句如下： 1alter table user add index city_user_age(city, name, age); 此时执行流程图如下： 当然，覆盖索引能够提升效率，但是维护索引也是需要代价的，因此还需要权衡使用。 总结 今天这篇文章，我和你介绍了 MySQL 里面order by语句的几种算法流程。 在开发系统的时候，你总是不可避免地会使用到 order by 语句。心里要清楚每个语句的排序逻辑是怎么实现的，还要能够分析出在最坏情况下，每个语句的执行对系统资源的消耗，这样才能做到下笔如有神，不犯低级错误。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[面试官：你知道哪些事务失效的场景？]]></title>
      <url>%2F2020%2F04%2F19%2F%E9%9D%A2%E8%AF%95%E5%AE%98%EF%BC%9A%E4%BD%A0%E7%9F%A5%E9%81%93%E5%93%AA%E4%BA%9B%E4%BA%8B%E5%8A%A1%E5%A4%B1%E6%95%88%E7%9A%84%E5%9C%BA%E6%99%AF%EF%BC%9F%2F</url>
      <content type="text"><![CDATA[前言 声明式事务是Spring功能中最爽之一，可是有些时候，我们在使用声明式事务并未生效，这是为什么呢？ 今天陈某带大家来聊一聊声明事务的几种失效场景。本文将会从以下两个方面来说一下事务为什么会失效？ @Transactional介绍 @Transactional失效场景 @Transactional介绍 @Transactional是声明式事务的注解，可以被标记在类上、接口、方法上。 该注解中有很多值得深入了解的几种属性，我们来看一下。 transactionManager 指定事务管理器，值为bean的名称，这个主要用于多事务管理器情况下指定。比如多数据源配置的情况下。 isolation 事务的隔离级别，默认是Isolation.DEFAULT。 几种值的含义如下： Isolation.DEFAULT：事务默认的隔离级别，使用数据库默认的隔离级别。 Isolation.READ_UNCOMMITTED：这是事务最低的隔离级别，它充许别外一个事务可以看到这个事务未提交的数据。这种隔离级别会产生脏读，不可重复读和幻读。 Isolation.READ_COMMITTED：保证一个事务修改的数据提交后才能被另外一个事务读取。另外一个事务不能读取该事务未提交的数据。这种事务隔离级别可以避免脏读出现，但是可能会出现不可重复读和幻读。 Isolation.REPEATABLE_READ：这种事务隔离级别可以防止脏读，不可重复读。但是可能出现幻读。 Isolation.SERIALIZABLE：这是花费最高代价但是最可靠的事务隔离级别。事务被处理为顺序执行。除了防止脏读，不可重复读外，还避免了幻读。 propagation 代表事务的传播行为，默认值为Propagation.REQUIRED。 Propagation.REQUIRED：如果存在一个事务，则支持当前事务。如果没有事务则开启一个新的事务。比如A方法内部调用了B方法，此时B方法将会使用A方法的事务。 Propagation.MANDATORY：支持当前事务，如果当前没有事务，就抛出异常。 Propagation.NEVER：以非事务方式执行，如果当前存在事务，则抛出异常。 Propagation.NOT_SUPPORTED：以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。 Propagation.REQUIRES_NEW：新建事务，如果当前存在事务，把当前事务挂起。比如A方法使用默认的事务传播属性，B方法使用REQUIRES_NEW，此时A方法在内部调用B方法，一旦A方法出现异常，A方法中的事务回滚了，但是B方法并没有回滚，因为A和B方法使用的不是同一个事务，B方法新建了一个事务。 Propagation.NESTED：支持当前事务，新增Savepoint点，也就是在进入子事务之前，父事务建立一个回滚点，与当前事务同步提交或回滚。 子事务是父事务的一部分，在父事务还未提交时，子事务一定没有提交。嵌套事务一个非常重要的概念就是内层事务依赖于外层事务。外层事务失败时，会回滚内层事务所做的动作。而内层事务操作失败并不会引起外层事务的回滚。 timeout 事务的超时时间，单位为秒。 readOnly 该属性用于设置当前事务是否为只读事务，设置为true表示只读，false则表示可读写，默认值为false。如果一个事务只涉及到只读，可以设置为true。 rollbackFor 属性 用于指定能够触发事务回滚的异常类型，可以指定多个异常类型。 默认是在RuntimeException和Error上回滚。 noRollbackFor 抛出指定的异常类型，不回滚事务，也可以指定多个异常类型。 @Transactional失效场景 声明式事务失效的场景有很多，陈某这里只是罗列一下几种常见的场景。 底层数据库引擎不支持事务 如果数据库引擎不支持事务，则Spring自然无法支持事务。 在非public修饰的方法使用 @Transactional注解使用的是AOP，在使用动态代理的时候只能针对public方法进行代理，源码依据在AbstractFallbackTransactionAttributeSource类中的computeTransactionAttribute方法中，如下： 123456protected TransactionAttribute computeTransactionAttribute(Method method, Class&lt;?&gt; targetClass) &#123; // Don't allow no-public methods as required. if (allowPublicMethodsOnly() &amp;&amp; !Modifier.isPublic(method.getModifiers())) &#123; return null;&#125; 此处如果不是标注在public修饰的方法上并不会抛出异常，但是会导致事务失效。 异常被 “ 踹死了 “ 这种情况小白是最容易犯错的，在整个事务的方法中使用try-catch，导致异常无法抛出，自然会导致事务失效。伪代码如下：123456789@Transactionalpublic void method()&#123; try&#123; //插入一条数据 //更改一条数据 &#125;catch(Exception ex)&#123; return; &#125;&#125; 方法中调用同类的方法 简单的说就是一个类中的A方法（未标注声明式事务）在内部调用了B方法(标注了声明式事务)，这样会导致B方法中的事务失效。 代码如下： 123456789101112public class Test&#123; public void A()&#123; //插入一条数据 //调用B方法 B(); &#125; @Transactional public void B()&#123; //插入数据 &#125;&#125; 为什么会失效呢？：其实原因很简单，Spring在扫描Bean的时候会自动为标注了@Transactional注解的类生成一个代理类（proxy）,当有注解的方法被调用的时候，实际上是代理类调用的，代理类在调用之前会开启事务，执行事务的操作，但是同类中的方法互相调用，相当于this.B()，此时的B方法并非是代理类调用，而是直接通过原有的Bean直接调用，所以注解会失效。 如何解决呢？：这就涉及到注解失效的原因了，后续文章会介绍到，这里不过多介绍了。 rollbackFor属性设置错误 很容易理解，指定异常触发回滚，一旦设置错误，导致一些异常不能触发回滚，此时的声明式事务不就失效了吗。 noRollbackFor属性设置错误 这个和rollbackFor属性设置错误类似，一旦设置错误，也会导致异常不能触发回滚，此时的声明式事务会失效。 propagation属性设置错误 事务的传播属性在上面已经介绍了，默认的事务传播属性是Propagation.REQUIRED，但是一旦配置了错误的传播属性，也是会导致事务失效，如下三种配置将会导致事务失效： Propagation.SUPPORTS Propagation.NOT_SUPPORTED Propagation.NEVER 原始SSM项目，重复扫描导致事务失效 在原始的SSM项目中都配置了context:component-scan并且同时扫描了service层，此时事务将会失效。 按照Spring配置文件的加载顺序来说，会先加载Springmvc的配置文件，如果在加载Springmvc配置文件的时候把service也加载了，但是此时事务还没加载，将会导致事务无法成功生效。 解决方法很简单，把扫描service层的配置设置在Spring配置文件或者其他配置文件中即可。 总结 事务失效的原因很多，但是千万不要做到一知半解，只有深入理解了，才能在面试过程中对答如流。 今天的文章就到此结束了，如果觉得陈某写得不错，有所收获的，关注在看来一波，你们的鼓励，将会是我写作的动力，谢谢支持！！！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[设计模式：工厂方法模式]]></title>
      <url>%2F2020%2F04%2F05%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F%2F</url>
      <content type="text"><![CDATA[导读 工厂方法模式是所有设计模式中比较常用的一种模式，但是真正能搞懂用好的少之又少，Spring底层大量的使用该设计模式来进行封装，以致开发者阅读源代码的时候晕头转向。 今天陈某分别从以下五个方面详细讲述一下工厂方法模式： 从什么是工厂方法模式 通用框架实现 工厂方法模式的优点 工厂方法模式的升级 Spring底层如何使用工厂方法模式 什么是工厂方法模式？ 定义：定义一个用于创建对象的 接口，让子类决定实例化哪一个类。工厂方法使一个类的实例化延迟到其子类。 工厂方法模式通用类图如下： 在工厂方法模式中，抽象产品Product负责定义产品的特性，实现对事物的抽象定义。 AbstractFactory是抽象工厂类，定义了一个抽象工厂方法。具体的如何创建产品由工厂实现类ConcreteFactory完成。 通用框架实现 工厂方法模式的变种有很多，陈某给出一个比较实用的通用框架。 抽象产品类： 1234567891011public abstract class Product &#123; /** * 公共逻辑方法 */ public void method1()&#123;&#125; /** * 抽象方法：由子类实现，根据业务逻辑定义多个 */ public abstract void method2();&#125; 具体产品类1，继承抽象产品类，如下： 123456789public class Product1 extends Product &#123; /** * 实现抽象产品类的抽象方法 */ @Override public void method2() &#123; &#125;&#125; 具体产品类2，继承抽象产品类，如下： 12345678910public class Product2 extends Product &#123; /** * 实现抽象产品类的抽象方法 */ @Override public void method2() &#123; &#125;&#125; 抽象工厂类，必须定义一个工厂方法来自己实现具体的创建逻辑，如下： 123456789public abstract class AbstractFactory &#123; /** * 工厂方法，需要子类实现 * @param cls * @param &lt;T&gt; * @return */ public abstract &lt;T extends Product&gt; T create(Class&lt;T&gt; cls);&#125; 具体工厂类，使用了反射对具体产品的实例化，如下： 123456789101112public class ConcreteFactory extends AbstractFactory &#123; @Override public &lt;T extends Product&gt; T create(Class&lt;T&gt; cls) &#123; Product product=null; try&#123; product= (Product) Class.forName(cls.getName()).newInstance(); &#125;catch (Exception ex)&#123; ex.printStackTrace(); &#125; return (T) product; &#125;&#125; 测试如下： 1234567public static void main(String[] args) &#123; //创建具体工厂类 ConcreteFactory factory = new ConcreteFactory(); //调用工厂方法获取产品类1的实例 Product1 product1 = factory.create(Product1.class); System.out.println(product1); &#125; 以上是简单的一个通用框架，读者可以根据自己的业务在其上拓展。 工厂方法模式的优点 良好的封装性，代码结构清晰，调用者不用关系具体的实现过程，只需要提供对应的产品类名称即可。 易扩展性，在增加产品类的情况下，只需要适当的修改工厂类逻辑或者重新拓展一个工厂类即可。 屏蔽了产品类，产品类的变化调用者不用关心。比如在使用JDBC连接数据库时，只需要改动一个驱动的名称，数据库就会从Mysql切换到Oracle，极其灵活。 工厂方法模式的升级 在复杂的系统中，一个产品的初始化过程是及其复杂的，仅仅一个具体工厂实现可能有些吃力，此时最好的做法就是为每个产品实现一个工厂，达到一个工厂类只负责生产一个产品。 此时工厂方法模式的类图如下： 如上图，每个产品类都对应了一个工厂，一个工厂只负责生产一个产品，非常符合单一职责原则。 针对上述的升级过程，那么工厂方法中不需要传入抽象产品类了，因为一个工厂只负责一个产品的生产，此时的抽象工厂类如下：123456public abstract class AbstractFactory &#123; /** * 工厂方法，需要子类实现 */ public abstract &lt;T extends Product&gt; T create();&#125; Spring底层如何使用工厂方法模式？ 工厂方法模式在Spring底层被广泛的使用，陈某今天举个最常用的例子就是AbstractFactoryBean。 这个抽象工厂很熟悉了，这里不再讨论具体的作用。其实现了FactoryBean接口，这个接口中getObject()方法返回真正的Bean实例。 AbstractFactoryBean中的getObject()方法如下： 12345678910111213public final T getObject() throws Exception &#123; //单例，从缓存中取，或者暴露一个早期实例解决循环引用 if (isSingleton()) &#123; return (this.initialized ? this.singletonInstance : getEarlySingletonInstance()); &#125; //多实例 else &#123; //调用createInstance return createInstance(); &#125; &#125; //创建对象 protected abstract T createInstance() throws Exception; 从以上代码可以看出，创建对象的职责交给了createInstance这个抽象方法，由其子类去定制自己的创建逻辑。 下图显示了继承了AbstractFactoryBean的具体工厂类，如下： 其实与其说AbstractFactoryBean是抽象工厂类，不如说FactoryBean是真正的抽象工厂类，前者只是对后者的一种增强，完成大部分的可复用的逻辑。比如常用的sqlSessionFactoryBean只是简单的实现了FactoryBean，并未继承AbstractFactoryBean，至于结论如何，具体看你从哪方面看了。 总结 工厂方法模式是一种常见的设计模式，但是真正能够用的高级，用的透彻还是有些难度的，开发者所能做的就是在此模式基础上思考如何优化自己的代码，达到易扩展、封装性强的效果了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[设计模式：模板模式]]></title>
      <url>%2F2020%2F04%2F05%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E6%A8%A1%E6%9D%BF%E6%A8%A1%E5%BC%8F%2F</url>
      <content type="text"><![CDATA[导读 模板模式在是Spring底层被广泛的应用，比如事务管理器的实现，JDBC模板的实现。 今天就来谈谈什么是模板模式、模板模式的优缺点、模板模式的简单演示、模板模式在Spring底层的实现。 什么是模板模式 模板模式首先要有一个抽象类，这个抽象类公开定义了执行它的方法的方式/模板。它的子类可以按需要重写方法实现，但调用将以抽象类中定义的方式进行。这种类型的设计模式属于行为型模式。 定义：定义一个操作中的算法骨架，而将算法的一些步骤延迟到子类中，使得子类可以不改变该算法结构的情况下重定义该算法的某些特定步骤。 比如在造房子一样，地基，铺线，房子户型都是一样的，由开发商决定，但是在交房之后，室内的装修风格和场景布置却是由业主决定，在这个场景中，开发商其实就是一个抽象类，地基，铺线，房子户型都是可以复用的，但是装修却是不可复用的，必须由业主决定，此时的每一个业主的房子就是一个实现的子类。 模板方法的实现条件注意： 必须是一个抽象类。 抽象类有一个模板方法，其中定义了算法骨架。 为了防止恶意操作，模板方法必须加上final关键词。 模板方法中除了复用的代码，其他的关键代码必须是抽象的，子类可以继承实现。 优点 它封装了不变部分，扩展可变部分。它把认为是不变部分的算法封装到父类中实现，而把可变部分算法由子类继承实现，便于子类继续扩展。 它在父类中提取了公共的部分代码，便于代码复用。 部分方法是由子类实现的，因此子类可以通过扩展方式增加相应的功能，符合开闭原则。 缺点 对每个不同的实现都需要定义一个子类，这会导致类的个数增加，系统更加庞大，设计也更加抽象。 父类中的抽象方法由子类实现，子类执行的结果会影响父类的结果，这导致一种反向的控制结构，它提高了代码阅读的难度。 简单演示 比如游戏的运行需要如下几个步骤： 初始化游戏 开始游戏 结束游戏 上述的三个步骤可以是模板类的抽象方法，由具体的子类实现，比如足球游戏。 定义模板类，必须是一个抽象类，模板方法必须是final修饰。 12345678910111213141516171819public abstract class Game &#123; //抽象方法 abstract void initialize(); abstract void startPlay(); abstract void endPlay(); //模板方法 public final void play()&#123; //初始化游戏 initialize(); //开始游戏 startPlay(); //结束游戏 endPlay(); &#125;&#125; 定义实现类，足球游戏，继承模板类，实现其中的三个抽象方法 1234567891011121314151617public class Football extends Game &#123; @Override void endPlay() &#123; System.out.println("足球游戏结束......"); &#125; @Override void initialize() &#123; System.out.println("足球游戏初始化中......"); &#125; @Override void startPlay() &#123; System.out.println("足球游侠开始了......"); &#125;&#125; 此时写一个测试方法，运行足球游戏，如下： 12345678public class TemplatePatternDemo &#123; public static void main(String[] args) &#123; //创建足球游戏实例 Game game = new Football(); //开始游戏 game.play(); &#125;&#125; 输出结果如下： 123足球游戏初始化中......足球游侠开始了......足球游戏结束...... Spring中的模板模式 Spring底层对于模板模式的使用有很多处，今天陈某带大家康康事务管理器是如何使用模板模式的。 模板抽象类 AbstractPlatformTransactionManager是Spring中的模板抽象类，来看看它的继承关系图： 实现了PlatformTransactionManager接口，重载了接口中的方法。 模板方法 事务管理器中抽象类中的模板方法不止一个，比如以下两个方法 12345//提交事务public final void commit()//获取TransactionStatuspublic final TransactionStatus getTransaction() 这两个方法都对于自己要实现的逻辑搭建了一个骨架，主要的功能是由抽象方法完成，由子类来完成。 抽象方法 事务管理器抽象类中的抽象方法定义了多个，分别用于处理不同的业务逻辑，由子类实现其中具体的逻辑，如下： 1234567891011//提交事务protected abstract void doCommit(DefaultTransactionStatus status);//回滚事务protected abstract void doRollback(DefaultTransactionStatus status);//开始事务protected abstract void doBegin(Object transaction, TransactionDefinition definition)//获取当前的事务对象protected abstract Object doGetTransaction() 抽象方法的定义便于子类去扩展，在保证算法逻辑不变的情况下，子类能够定制自己的实现。 具体子类 事务管理器的模板类有很多的具体子类，如下图： 其中我们熟悉的有DataSourceTransactionManager、JtaTransactionManager、RabbitTransactionManager。具体承担什么样的角色和责任不是本节的重点，不再细说。 总结 模板模式是一个很重要，易扩展的模式，提高了代码复用性，在Spring中有着广泛的应用，比如JDBCTemplate,AbstractPlatformTransactionManager，这些实现都用到了模板模式。 如果觉得陈某的文章能够对你有所帮助，有所启发，关注分享一波，点个在看，谢谢支持！！！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Mysql性能优化：为什么count(*)这么慢？]]></title>
      <url>%2F2020%2F04%2F05%2FMysql%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%EF%BC%9A%E4%B8%BA%E4%BB%80%E4%B9%88count%E8%BF%99%E4%B9%88%E6%85%A2%2F</url>
      <content type="text"><![CDATA[导读 在开发中一定会用到统计一张表的行数，比如一个交易系统，老板会让你每天生成一个报表，这些统计信息少不了sql中的count函数。 但是随着记录越来越多，查询的速度会越来越慢，为什么会这样呢？Mysql内部到底是怎么处理的？ 今天这篇文章将从Mysql内部对于count函数是怎样处理的？ count的实现方式 在Mysql中的不同的存储引擎对count函数有不同的实现方式。 MyISAM引擎把一个表的总行数存在了磁盘上，因此执行count(*)的时候会直接返回这个数，效率很高（没有where查询条件）。 InnoDB引擎并没有直接将总数存在磁盘上，在执行count(*)函数的时候需要一行一行的将数据读出来，然后累计总数。 为什么InnoDB不将总数存起来？ 说道InnoDB相信读者总会想到其支持事务的特性，事务具有隔离性，如果将总数存起来，怎么保证各个事务之间的总数的一致性呢？不明白的看下图： 事务A和事务B中的count(*)的执行结果是不同的，因此InnoDB引擎在每个事务中返回多少行是不确定的，只能一行一行的读出来用来判断总数。 如何提升count效率 在InnoDB对于如何提升count(*)的查询效率，网上有多种解决办法，这里主要介绍三种，并分析可行性。 show table status show table status这个命令能够很快的查询出数据库中每个表的行数，但是真的能够替代count(*)吗？ 答案是不能。原因很简单，这个命令统计出来的值是一个估值，因此是不准确的，官方文档说误差大概在40%-50%。 因此这种方法直接pass，不准确还用它干嘛。 缓存系统存储总数 这种方法也是最容易想到的，增加一行就+1，删除一行就-1，并且缓存系统读取也是很快，既简单又方便的为什么不用？ 缓存系统和Mysql是两个系统，比如redis和Mysql这两个是典型的比较。两个系统最难的就是在高并发下无法保证数据的一致性。通过以下两图我们来理解一下： 通过上面两张图，无论是redis计数+1还是insert into user先执行，最终都会导致数据在逻辑上的不一致。第一张图会出现redis计数少了，第二张图虽然计数正确了但是并没有查询出插入的那一行数据。 在并发系统里面，我们是无法精确控制不同线程的执行时刻的，因为存在图中的这种操作序列，所以，我们说即使Redis正常工作，这个计数值还是逻辑上不精确的。 在数据库保存计数 通过缓存系统保存的分析得知了使用缓存无法保证数据在逻辑上的一致性，因此我们想到了直接使用数据库来保存，有了事务的支持，也就保证了数据的一致性了。 如何使用呢？很简单，直接将计数保存在一张表中（table_name,total）。 至于执行的逻辑只需要将缓存系统中redis计数+1改成total字段+1即可，如下图： 由于在同一个事务中，保证了数据在逻辑上的一致性。 不同count的用法 count()是一个聚合函数，对于返回的结果集，一行行地判断，如果count函数的参数不是NULL，累计值就加1，否则不加。最后返回累计值。 count的用法有多种，分别是count(*)、count(字段)、count(1)、count(主键id)。那么多种用法，到底有什么差别呢？当然，前提是没有where条件语句。 count(id)：InnoDB引擎会遍历整张表，把每一行的id值都取出来，返回给server层。server层拿到id后，判断是不可能为空的，就按行累加。 count(1)：InnoDB引擎遍历整张表，但不取值。server层对于返回的每一行，放一个数字1进去，判断是不可能为空的，按行累加。 count(字段)： 如果这个“字段”是定义为not null的话，一行行地从记录里面读出这个字段，判断不能为null，按行累加； 如果这个字段定义允许为null，那么执行的时候，判断到有可能是null，还要把值取出来再判断一下，不是null才累加。 count(*)：不会把全部字段取出来，而是专门做了优化，不取值。count(*)肯定不是null，按行累加。 所以结论很简单：按照效率排序的话，count(字段)&lt;count(主键id)&lt;count(1)≈count(*)，所以建议读者，尽量使用count(*)。 注意：这里肯定有人会问，count(id)不是走的索引吗，为什么查询效率和其他的差不多呢？陈某在这里解释一下，虽然走的索引，但是还是要一行一行的扫描才能统计出来总数。 总结 MyISAM表虽然count(*)很快，但是不支持事务； show table status命令虽然返回很快，但是不准确； InnoDB直接count(*)会遍历全表(没有where条件)，虽然结果准确，但会导致性能问题。 缓存系统的存储计数虽然简单效率高，但是无法保证数据的一致性。 数据库保存计数很简单，也能保证数据的一致性，建议使用。 思考题，读者留言区讨论：在系统高并发的情况下，使用数据库保存计数，是先更新计数+1,还是先插入数据。即是先update total+=1还是先insert into。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[接口幂等性如何设计？]]></title>
      <url>%2F2020%2F04%2F01%2F%E6%8E%A5%E5%8F%A3%E5%B9%82%E7%AD%89%E6%80%A7%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%EF%BC%9F%2F</url>
      <content type="text"><![CDATA[导读 现在这个时代大家可能最关心的就是钱了，那么有没有想过你银行转账给你没有一次是转多的，要么失败，要么成功，为什么不能失误一下多转一笔呢？醒醒吧年轻人，别做梦了，做银行的能那么傻x吗？ 今天我们就来谈一谈为什么银行转账不能多给我转一笔？关乎到钱的问题，小伙伴们打起精神！！！ 要想要理解上述的疑惑，不得不提的一个概念就是幂等性，至于什么是幂等性，如何通过代码实现幂等性，下面将会详细讲述。 什么是幂等性 所谓幂等性通俗的将就是一次请求和多次请求同一个资源产生相同的副作用。用数学语言表达就是f(x)=f(f(x))。 维基百科的幂等性定义如下： 12幂等（idempotent、idempotence）是一个数学与计算机学概念，常见于抽象代数中。在编程中一个幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。幂等函数，或幂等方法，是指可以使用相同参数重复执行，并能获得相同结果的函数。这些函数不会影响系统状态，也不用担心重复执行会对系统造成改变。例如，“setTrue()”函数就是一个幂等函数,无论多次执行，其结果都是一样的，更复杂的操作幂等保证是利用唯一交易号(流水号)实现. 为什么需要幂等性 在系统高并发的环境下，很有可能因为网络，阻塞等等问题导致客户端或者调用方并不能及时的收到服务端的反馈甚至是调用超时的问题。总之，就是请求方调用了你的服务，但是没有收到任何的信息，完全懵逼的状态。比如订单的问题，可能会遇到如下的几个问题： 创建订单时，第一次调用服务超时，再次调用是否产生两笔订单？ 订单创建成功去减库存时，第一次减库存超时，是否会多扣一次？ 订单支付时，服务端扣钱成功，但是接口反馈超时，此时再次调用支付，是否会多扣一笔呢？ 作为消费者，前两种能接受，第三种情况就MMP了，哈哈哈！！！这种情况一般有如下两种解决方式 服务方提供一个查询操作是否成功的api，第一次超时之后，调用方调用查询接口，如果查到了就走成功的流程，失败了就走失败的流程。 另一种就是服务方需要使用幂等的方式保证一次和多次的请求结果一致。 HTTP的幂等性 GET：只是获取资源，对资源本身没有任何副作用，天然的幂等性。 HEAD：本质上和GET一样，获取头信息，主要是探活的作用，具有幂等性。 OPTIONS：获取当前URL所支持的方法，因此也是具有幂等性的。 DELETE：用于删除资源，有副作用，但是它应该满足幂等性，比如根据id删除某一个资源，调用方可以调用N次而不用担心引起的错误（根据业务需求而变）。 PUT：用于更新资源，有副作用，但是它应该满足幂等性，比如根据id更新数据，调用多次和N次的作用是相同的（根据业务需求而变）。 POST：用于添加资源，多次提交很可能产生副作用，比如订单提交，多次提交很可能产生多笔订单。 幂等性的实现方式 对于客户端交互的接口，可以在前端拦截一部分，例如防止表单重复提交，按钮置灰，隐藏，不可点击等方式。但是前端进行拦截器显然是针对普通用户，懂点技术的都可以模拟请求调用接口，所以后端幂等性很重要。 后端的幂等性如何实现？将会从以下几个方面介绍。 数据库去重表 在往数据库中插入数据的时候，利用数据库唯一索引特性，保证数据唯一。比如订单的流水号，也可以是多个字段的组合。 实现比较简单，读者可以自己实现看看，这里不再提供demo了。 状态机 很多业务中多有多个状态，比如订单的状态有提交、待支付、已支付、取消、退款等等状态。后端可以根据不同的状态去保证幂等性，比如在退款的时候，一定要保证这笔订单是已支付的状态。 业务中常常出现，读者可以自己实现看看，不再提供demo。 TOKEN机制 针对客户端连续点击或者调用方的超时重试等情况，例如提交订单，此种操作就可以用Token的机制实现防止重复提交。 TOKEN机制如何实现？简单的说就是调用方在调用接口的时候先向后端请求一个全局ID（TOKEN），请求的时候携带这个全局ID一起请求，后端需要对这个全局ID校验来保证幂等操作，流程如下图： 主要的流程步骤如下： 客户端先发送获取token的请求，服务端会生成一个全局唯一的ID保存在redis中，同时把这个ID返回给客户端。 客户端调用业务请求的时候必须携带这个token，一般放在请求头上。 服务端会校验这个Token，如果校验成功，则执行业务。 如果校验失败，则表示重复操作，直接返回指定的结果给客户端。 通过以上的流程分析，唯一的重点就是这个全局唯一ID如何生成，在分布式服务中往往都会有一个生成全局ID的服务来保证ID的唯一性，但是工程量和实现难度比较大，UUID的数据量相对有些大，此处陈某选择的是雪花算法生成全局唯一ID，不了解雪花算法的读者下一篇文章会着重介绍。 代码实现 陈某选择的环境是SpringBoot+Redis单机环境+注解+拦截器的方式实现，只是演示一下思想，具体的代码可以参照实现。 redis如何实现，获取Token接口将全局唯一Id存入Redis（一定要设置失效时间，根据业务需求），业务请求的时候直接从redis中删除，根据delete的返回值判断，返回true表示第一次请求，返回false表示重复请求。代码如下： 12345678910111213141516171819202122@Servicepublic class TokenServiceImpl implements TokenService &#123; @Autowired private StringRedisTemplate stringRedisTemplate; @Override public String getToken() &#123; //获取全局唯一id long nextId = SnowflakeUtil.nextId(); //存入redis，设置10分钟失效 stringRedisTemplate.opsForValue().set(String.valueOf(nextId), UUID.randomUUID().toString(),10, TimeUnit.MINUTES); return String.valueOf(nextId); &#125; /** * 删除记录，true表示第一次提交，false重复提交 */ @Override public Boolean checkToken(String token) &#123; return stringRedisTemplate.delete(token); &#125;&#125; 注解的实现如下，标注在controller类上表示当前类上全部接口都做幂等，标注单个方法上，表示单个接口做幂等操作。 12345678910/** * @Description 幂等操作的注解 * @Author CJB * @Date 2020/3/25 10:19 */@Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface RepeatLimiter &#123;&#125; 请求头的拦截器，用于提取请求头和校验请求头，如下： 1234567891011121314151617181920212223242526272829303132/** * @Description 获取请求头的信息，具体校验逻辑读者自己实现 * @Author CJB * @Date 2020/3/25 11:09 */@Componentpublic class HeaderIntercept implements HandlerInterceptor &#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; //获取token String token = request.getHeader(HeaderConstant.TOKEN); //校验逻辑 if (!validToken(token)) throw new TokenInvalidException("TOKEN失效"); //获取其他的参数..... RequestHeader header = RequestHeader.builder() .token(token) .build(); //放入request中 request.setAttribute(HeaderConstant.HEADER_INFO,header); return true; &#125; /** * 校验token，逻辑自己实现 * @param token * @return */ private boolean validToken(String token)&#123; return Boolean.TRUE; &#125;&#125; 保证幂等性的拦截器，直接从redis中删除token，成功则第一次提交，不成功则重复提交。 1234567891011121314151617181920212223242526272829303132333435363738@Componentpublic class RepeatIntercept implements HandlerInterceptor &#123; @Autowired private TokenService tokenService; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; if (handler instanceof HandlerMethod)&#123; //获取方法上的参数 RepeatLimiter repeatLimiter = AnnotationUtils.findAnnotation(((HandlerMethod) handler).getMethod(), RepeatLimiter.class); if (Objects.isNull(repeatLimiter))&#123; //获取controller类上注解 repeatLimiter=AnnotationUtils.findAnnotation(((HandlerMethod) handler).getBean().getClass(),RepeatLimiter.class); &#125; //使用注解，需要拦截验证 if (Objects.nonNull(repeatLimiter))&#123; //获取全局token，表单提交的唯一id RequestHeader info = RequestContextUtils.getHeaderInfo(); //没有携带token，抛异常，这里的异常需要全局捕获 if (StringUtils.isEmpty(info.getToken())) throw new RepeatException(); //校验token Boolean flag = tokenService.checkToken(info.getToken()); //删除失败，表示 if (Boolean.FALSE.equals(flag)) //抛出重复提交的异常 throw new RepeatException(); &#125; &#125; return true; &#125;&#125; 接口幂等实现，代码如下： 12345678910111213141516171819@RestController@RequestMapping("/order")public class OrderController &#123; @Autowired private OrderService orderService; /** * 下单 * @param order * @return */ @PostMapping @RepeatLimiter //幂等性保证 public CommenResult add(@RequestBody Order order)&#123; orderService.save(order); return new CommenResult("200","下单成功"); &#125;&#125; 演示 发送getToken的请求获取Token 携带Token下单第一次： 第二次下单：]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Mysql性能优化：什么是索引下推？]]></title>
      <url>%2F2020%2F04%2F01%2FMysql%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%EF%BC%9A%E4%BB%80%E4%B9%88%E6%98%AF%E7%B4%A2%E5%BC%95%E4%B8%8B%E6%8E%A8%EF%BC%9F%2F</url>
      <content type="text"><![CDATA[导读 索引下推（index condition pushdown ）简称ICP，在Mysql5.6的版本上推出，用于优化查询。 在不使用ICP的情况下，在使用非主键索引（又叫普通索引或者二级索引）进行查询时，存储引擎通过索引检索到数据，然后返回给MySQL服务器，服务器然后判断数据是否符合条件 。 在使用ICP的情况下，如果存在某些被索引的列的判断条件时，MySQL服务器将这一部分判断条件传递给存储引擎，然后由存储引擎通过判断索引是否符合MySQL服务器传递的条件，只有当索引符合条件时才会将数据检索出来返回给MySQL服务器 。 索引条件下推优化可以减少存储引擎查询基础表的次数，也可以减少MySQL服务器从存储引擎接收数据的次数。 开撸 在开始之前先先准备一张用户表(user)，其中主要几个字段有：id、name、age、address。建立联合索引（name，age）。 假设有一个需求，要求匹配姓名第一个为陈的所有用户，sql语句如下： 1SELECT * from user where name like '陈%' 根据 “最佳左前缀” 的原则，这里使用了联合索引（name，age）进行了查询，性能要比全表扫描肯定要高。 问题来了，如果有其他的条件呢？假设又有一个需求，要求匹配姓名第一个字为陈，年龄为20岁的用户，此时的sql语句如下： 1SELECT * from user where name like '陈%' and age=20 这条sql语句应该如何执行呢？下面对Mysql5.6之前版本和之后版本进行分析。 Mysql5.6之前的版本 5.6之前的版本是没有索引下推这个优化的，因此执行的过程如下图： 会忽略age这个字段，直接通过name进行查询，在(name,age)这课树上查找到了两个结果，id分别为2,1，然后拿着取到的id值一次次的回表查询，因此这个过程需要回表两次。 Mysql5.6及之后版本 5.6版本添加了索引下推这个优化，执行的过程如下图： InnoDB并没有忽略age这个字段，而是在索引内部就判断了age是否等于20，对于不等于20的记录直接跳过，因此在(name,age)这棵索引树中只匹配到了一个记录，此时拿着这个id去主键索引树中回表查询全部数据，这个过程只需要回表一次。 实践 当然上述的分析只是原理上的，我们可以实战分析一下，因此陈某装了Mysql5.6版本的Mysql，解析了上述的语句，如下图： 根据explain解析结果可以看出Extra的值为Using index condition，表示已经使用了索引下推。 总结 索引下推在非主键索引上的优化，可以有效减少回表的次数，大大提升了查询的效率。 关闭索引下推可以使用如下命令，配置文件的修改不再讲述了，毕竟这么优秀的功能干嘛关闭呢： 1set optimizer_switch='index_condition_pushdown=off';]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Mysql性能优化：为什么使用覆盖索引?]]></title>
      <url>%2F2020%2F04%2F01%2FMysql%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%EF%BC%9A%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8%E8%A6%86%E7%9B%96%E7%B4%A2%E5%BC%95%2F</url>
      <content type="text"><![CDATA[导读 相信读者看过很多MYSQL索引优化的文章，其中有很多优化的方法，比如最佳左前缀，覆盖索引等方法，但是你真正理解为什么要使用最佳左前缀，为什么使用覆盖索引会提升查询的效率吗？ 本篇文章将从MYSQL内部结构上讲一下为什么覆盖索引能够提升效率。 InnoDB索引模型 在InnoDB中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。又因为前面我们提到的，InnoDB使用了B+树索引模型，所以数据都是存储在B+树中的。 每一个索引在InnoDB里面对应一棵B+树。 主键索引和非主键索引的区别 主键索引又叫聚簇索引 ，非主键索引又叫普通索引，那么这两种索引有什么区别呢？ 主键索引的叶子节点存放的是整行数据，非主键索引的叶子节点存放的是主键的值。 假设有一张User表（id,age,name,address），其中有id和age两个字段，其中id是主键，age是普通索引，有几行数据u1-u5的(id,age)的值是(100,1)、(200,2)、(300,3)、(500,5)和(600,6) ，此时的两棵树的示例如下： 从上图可以看出来，基于主键索引的树的叶子节点存放的是整行User数据，基于普通索引age的叶子节点存放的是id（主键）的值。 什么是回表？ 假设有一条查询语句如下： 1select * from user where age=3; 上面这条sql语句执行的过程如下： 1、根据age这个普通索引在age索引树上搜索，得到主键id的值为300。 2、因为age索引树并没有存储User的全部数据，因此需要根据在age索引树上查询到的主键id的值300再到id索引树搜索一次，查询到了u3。 3、返回结果。 上述执行的过程中，从age索引树再到id索引树的查询的过程叫做回表（回到主键索引树搜索的过程）。 也就是说通过非主键索引的查询需要多扫描一棵索引树，因此需要尽量使用主键索引查询。 为什么使用覆盖索引？ 有了上述提及到的几个概念，便能很清楚的理解为什么覆盖索引能够提升查询效率了，因为少了一次回表的过程。 假设我们使用覆盖索引查询，语句如下： 1select id from user where age=3; 这条语句执行过程很简单，直接在age索引树中就能查询到id的值，不用再去id索引树中查找其他的数据，避免了回表。 总结 覆盖索引的使用能够减少树的搜索次数，避免了回表，显著提升了查询性能，因此覆盖索引是一个常用的性能优化手段。 留给读者一个问题：身份证是一个人的唯一识别凭证，如果有根据身份证号查询市民信息的需求，我们只要在身份证号字段上建立索引就够了。而再建立一个（身份证号、姓名）的联合索引，是不是浪费空间？]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[一条查询语句到底是如何执行的?]]></title>
      <url>%2F2020%2F04%2F01%2F%E4%B8%80%E6%9D%A1%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5%E5%88%B0%E5%BA%95%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84%2F</url>
      <content type="text"><![CDATA[导读 Mysql在中小型企业中是个香饽饽，目前主流的数据库之一，几乎没有一个后端开发者不会使用的，但是作为一个老司机，仅仅会用真的不够。 今天陈某透过一个简单的查询语句来讲述在Mysql内部的执行过程。 1select * from table where id=10; 撸它 首先通过一张图片来了解一下Mysql的基础架构，如下： 从上图可以看出，Mysql大致分为Server层和存储引擎层两部分。 Server层包括连接器、查询缓存、分析器、优化器等，其中包含了Mysql的大多数核心功能以及所有的内置函数（如日期，时间函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。 存储引擎层负责数据的存储和提取。它的架构是可插拔式的，支持InnoDB、MyISAM等多个存储引擎。Mysql中主流的存储引擎是InnoDB，由于它对事务的支持让它从Mysql5.5.5版本开始成为了默认的存储引擎。 大致了解了整体架构，现在说说每一个基础的模块都承担着怎样的责任。 1. 连接器 顾名思义，是客户端和Mysql之间连接的媒介，负责登录、获取权限、维持连接和管理连接。连接命令一般如下： 1mysql [-h] ip [- P] port -u [user] -p 在完成经典的TCP握手后，连接器会开始认证身份，要求输入密码。 密码认证通过，连接器会查询出拥有的权限，即使管理员修改了权限，也不会影响你这次的连接，只有重新连接才会生效。 密码认证失败，会收到提示信息Access denied for user。 连接完成后，没有后续动作的连接将会变成空闲连接，你可以输入show processlist命令看到它。如下图，其中的Command这一列显示为sleep的这一行表示在系统里面有一个空闲连接。 客户端如果太长时间没有执行动作，连接器将会自动断开，这个时间由参数wait_timeout控制，默认值是8小时。 如果在连接被断开之后，客户端再次发送请求的话，就会收到一个错误提醒： Lost connection to MySQL server during query。这时候如果你要继续，就需要重连，然后再执行请求了。 2. 查询缓存【废材，8.0 版本完全删除】 连接建立完成后，你就可以select语句了，执行之前会查询缓存。 查询缓存在Mysql中的是默认关闭的，因为缓存命中率非常低，只要有对表执行一个更新操作，这个表的所有查询缓存都将被清空。怎么样？一句废材足以形容了！！！ 废材的东西不必多讲，主流的Redis的缓存你不用，别再搞这废材了。 3. 分析器 如果没有命中查询缓存，就要执行查询了，但是在执行查询之前，需要对SQL语句做解析，判断你这条语句有没有语法错误。 分析器会做 ‘词法分析’ ，你输入的无非可就是多个字符串和空格组成的SQL语句，MYSQL需要识别出里面的字符串是什么，代表什么，有没有关键词等。 MYSQL会从你输入的select 这个关键字识别出来是一个查询语句，table是表名，id是列名。 做完这些会做 ‘语法分析’ ，根据MYSQL定义的规则来判断你的SQL语句有没有语法错误，如果你的语法不对，就会收到类似如下的提醒： 1ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &apos;elect * from t where ID=1&apos; at line 1 一般语法错误会提示第一个出现错误的位置，所以你要关注的是紧接“use near”的内容。 4. 优化器 经过分析器词法和语法的分析，此时就能知道这条SQL语句是干什么的。但是在开始执行之前，MYSQL底层还要使用优化器对这条SQL语句进行优化处理。 MYSQL内部会对这条SQL进行评估，比如涉及到多个索引会比较使用哪个索引代价更小、多表join的时候会考虑决定各个表的连接顺序。 优化器的作用一句话总结：根据MYSQL内部的算法决定如何执行这条SQL语句来达到MYSQL认为代价最小目的。 优化器阶段完成后，这个语句的执行方案就确定了，接下来就交给执行器执行了。 5. 执行器 MYSQL通过分析器知道了要做什么，通过优化器知道了如何做，于是就进入了执行器阶段。 执行器开始执行之前，需要检查一下用户对表table有没有执行的权限，没有返回权限不足的错误，有的话就执行。 执行也是分类的，如果Id不是索引则全表扫描，一行一行的查找，如果是索引则在索引组织表中查询，索引的查询很复杂，其中涉及到B+树等算法，这里不再详细介绍。 总结 一条SQL语句在MYSQL内部执行的过程涉及到的内部模块有：连接器、查询缓存、分析器、优化器、执行器、存储引擎。 至此，MYSQL的基础架构已经讲完了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Mysql中的三类锁，你知道吗？]]></title>
      <url>%2F2020%2F04%2F01%2FMysql%E4%B8%AD%E7%9A%84%E4%B8%89%E7%B1%BB%E9%94%81%EF%BC%8C%E4%BD%A0%E7%9F%A5%E9%81%93%E5%90%97%EF%BC%9F%2F</url>
      <content type="text"><![CDATA[导读 正所谓有人(锁)的地方就有江湖(事务)，人在江湖飘，怎能一无所知？ 今天来细说一下Mysql中的三类锁，分别是全局锁、表级锁、行级锁。 全局锁 全局锁简单的说就是锁住整个数据库实例，命令是Flush tables with read lock。当你需要为整个数据库处于只读的状态的时候，可以使用这个命令。 一旦使用全局锁，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。 全局锁的使用场景大部分都是用来数据库备份。 为什么备份要加全局锁？ 用户买东西，首先会从余额里扣除金额，然后在订单里添加商品。如果备份数据库，不加锁，并且备份顺序为先备份用余额，再备份订单商品，有可能备份了用户余额后，用户下订单买东西提交事务，然后再备份订单商品表， 此时订单商品已存在。最后备份出来的数据为。最后用户余额为买东西前的余额，没有减少，但是订单商品却多了。演示如下图： 这种情况可能用户会觉得赚了，但是如果备份顺序反过来，先备份商品表再备份余额表，用户就会发现我付了钱，但是商品没有加，这中结果就会更加的严重。 因此保证备份数据的一致性很重要，必要的手段就是加锁。 全局锁有什么坏处？ 全局锁是个啥？介绍完了读者心里已经有数了，让这个库只读？这是多么可怕的操作，简单列举几个危险之处： 如果在主库备份，备份期间不能执行任何更新操作，会导致整个业务停摆，高并发情况下更甚。 如果你在从库上备份，那么备份期间从库不能执行主库同步过来的binlog，会导致主从延迟。 全局备份比较好的解决方案 全局锁远瞅不错，近瞅吓一跳，陈某在此不推荐使用。 其实 官方自带的逻辑备份工具是mysqldump。当mysqldump使用参数–single-transaction的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于MVCC的支持，这个过程中数据是可以正常更新的。 一致性备份是好，但前提是存储引擎支持事务，这也是MyISAM被InnoDB取代的原因之一。 表级锁 MySQL里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。 表锁一般是在数据库引擎不支持行锁的时候才会被用到的 。 MDL会直到事务提交才释放，在做表结构变更的时候，你一定要小心不要导致锁住线上查询和更新 。 如何加表锁 显式加表锁和解锁的语句很简单，如下： 123lock tables tb_name read/write;unlock tables; 需要注意，lock tables语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。 举个例子, 如果在某个线程A中执行lock tables t1 read, t2 write; 这个语句，则其他线程写t1、读写t2的语句都会被阻塞。同时，线程A在执行unlock tables之前，也只能执行读t1、读写t2的操作。连写t1都不允许，自然也不能访问其他表。 MDL MDL不需要显式使用，在访问一个表的时候会被自动加上。 当对一个表做增删改查操作的时候，加MDL读锁；当要对表做结构变更操作的时候，加MDL写锁。 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。 查询表级锁争用 查询表级锁的争用可以通过以下参数分析获得： Table_locks_immediate：能够立即获得表级锁的次数 Table_locks_waited： 不能立即获取表级锁而需要等待的次数 查询语句如下： 1show status like 'table_locks_waited' 如果Table_locks_waited的值比较大，则说明存在着较严重的表级锁争用情况。 行级锁 MySQL的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如MyISAM引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。InnoDB是支持行锁的，这也是MyISAM被InnoDB替代的重要原因之一。 InnoDB的行锁是针对索引加的锁，不是针对记录加的锁。并且该索引不能失效，否则都会从行锁升级为表锁。 在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。 行级锁分为排它锁（写锁）、共享锁（读锁）、间隙锁。 排他锁 排他锁，也称写锁，独占锁，当前写操作没有完成前，它会阻断其他写锁和读锁。 Mysql中的更新语句(update/delete/insert)会自动加上排它锁。 如上图，事务B中的update语句被阻塞了，直到事务A提交才能执行更新操作。 排他锁也可以手动添加，如下： 1select * from user where id=1 for update; 注意以下两点： 行锁是针对索引加锁的，上述例子中id是主键索引。 加了排他锁并不是其他的事务不能读取这行的数据，而是不能再在这行上面加锁了。 间隙锁 当我们用范围条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做”间隙(GAP)”。InnoDB也会对这个”间隙”加锁，这种锁机制就是所谓的间隙锁(Next-Key锁)。 如上图，给id&gt;5中并不存在的数据加上了间隙锁，当插入id=6的数据时被阻塞了。 这是一个坑：若执行的条件是范围过大，则InnoDB会将整个范围内所有的索引键值全部锁定，很容易对性能造成影响 共享锁 共享锁，也称读锁，多用于判断数据是否存在，多个读操作可以同时进行而不会互相影响。当如果事务对读锁进行修改操作，很可能会造成死锁。如下图所示。 分析行锁定 通过检查InnoDB_row_lock 状态变量分析系统上的行锁的争夺情况 。 1show status like 'innodb_row_lock%' innodb_row_lock_current_waits: 当前正在等待锁定的数量。 innodb_row_lock_time: 从系统启动到现在锁定总时间长度；非常重要的参数 innodb_row_lock_time_avg: 每次等待所花平均时间；非常重要的参数。 innodb_row_lock_time_max: 从系统启动到现在等待最常的一次所花的时间； innodb_row_lock_waits: 系统启动后到现在总共等待的次数；非常重要的参数。直接决定优化的方向和策略。 死锁解决方案1、直接进入等待，直到超时。这个超时时间可以通过参数innodb_lock_wait_timeout来设置，默认50秒。注意超时时间不能设置太短，如果仅仅是短暂的等待，一旦设置时间很短，很快便解锁了，会出现误伤。 2、发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数innodb_deadlock_detect设置为on，表示开启这个逻辑，默认开启。 主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的。 当并发很高的时候，检测死锁将会消耗大量的资源，因此控制并发也是很重要的一种策略。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[IDEA调试技巧]]></title>
      <url>%2F2020%2F03%2F23%2FIDEA%E8%B0%83%E8%AF%95%E6%8A%80%E5%B7%A7%2F</url>
      <content type="text"><![CDATA[导读 前天面试了一个985高校的实习生，问了他平时用什么开发工具，他想也没想的说IDEA，于是我抛砖引玉的问了一下IDEA的调试用过吧，你说说怎么设置断点条件？那孩子懵了，想了好一会对我说没用过，甚至都没听说过这个。 作为一名资深的老司机，IDEA调试可以说是家常便饭，如果不会debug，我都不信你读过源码，就别和我说原理了，直接pass掉。 基本界面 ① 以Debug模式启动服务，左边的一个按钮则是以Run模式启动。在开发中，我一般会直接启动Debug模式，方便随时调试代码。 ② 断点：在左边行号栏单击左键，或者快捷键Ctrl+F8 打上/取消断点，断点行的颜色可自己去设置。 ③ Debug窗口：访问请求到达第一个断点后，会自动激活Debug窗口。如果没有自动激活，可以去设置里设置。 ④ 调试按钮：一共有8个按钮，调试的主要功能就对应着这几个按钮，鼠标悬停在按钮上可以查看对应的快捷键。 ⑤ 服务按钮：可以在这里关闭/启动服务，设置断点等。 ⑥ 方法调用栈：这里显示了该线程调试所经过的所有方法，勾选右上角的[Show All Frames]按钮，就不会显示其它类库的方法了，否则这里会有一大堆的方法。 ⑦ Variables：在变量区可以查看当前断点之前的当前方法内的变量。 ⑧ Watches：查看变量，可以将Variables区中的变量拖到Watches中查看 。 变量查看 在调试过程中往往需要观察变量的变化来判断业务逻辑，我们可以在以下的四个地方观察。 ① 最常用的变量的观察区域variables ② IDEA中最人性化的地方之一，会将变量的值阴影显示在变量的后面。 ③ watch区域，眼镜的形状，一般不会展开。如下图： 点击’+’号可以新增需要观察的变量，点击’-‘号可以删除。 ④ 鼠标悬停在变量上也会出现变量的值，点击展开即可查看。 计算表达式 在调试业务逻辑的时候一般总会遇到某个条件或者某个变量的计算值的还不知道的情况下就需要判断下一行代码，那么此处就需要用到计算表达式的功能。计算表达式有两种方法，如下： ① 选择需要计算的代码，鼠标右键—-&gt;Evaluate Expression—&gt;Evaluate即可计算。 ② 直接点击计算器形状控件即可弹出计算的窗口，将代码复制进去即可，注意复制进去的代码一定要符合逻辑，比如局部变量一定要是已经声明的。 断点条件设置 对于新手要看Spring源码的话，再遇到调试UserService的doGetBean的方法时可能要崩溃，因为doGetBean在容器启动的时候可能会被调用几十次，你把断点打在doGetBean方法体中能让你生不如死。 设置断点条件有两种方式： ①直接在断点上右键，添加condition条件即可。 ② view breakpoints(ctrl+shift+8)显示所有的断点，在condition中添加条件即可。 异常断点：设置了异常断点后，比如空指针异常，在程序出现需要拦截的异常时会自动定位到指定的行。如下图： ① ctrl+shift+F8显示所有断点，点击+号添加Java Exception Breakpoints。 ② debug运行，一旦有代码出现该异常，会自动定位到指定代码。 线程切换 通常我们在调试的时候，一个请求过来被拦截了，此时想要发起另外一个请求是无法重新发的，因为另外一个请求被阻塞了，只有当前线程执行完成之后才会走其他的线程。在IDEA中可以改变一下阻塞级别，有两种方法： 断点上右键—&gt;选择Thread—-&gt;Make Default，如下图： 显示所有断点(crtl+shift+F8)，选中某一个断点，选择Thread，Make Default即可。如下图： 设置了阻塞级别，此时就可以在线程切换了，如下图： 强制抛异常这是IDEA 2018年加入的新功能，可以直接在调试中抛出指定的异常。使用方法跟上面的弃栈帧类似，右击栈帧并选择Throw Exception，然后输入抛异常的代码，比如throw new NullPointerException，操作如下图： 强制返回 这是IDEA2015版时增加的功能，类似上面的手动抛异常，只不过是返回一个指定值罢了。使用方法跟上面也都类似，右击栈帧并选择Force Return，然后输入要返回的值即可。如果是void的方法那就更简单了，连返回值都不用输。如下图： 笔者有话说 最近建了一个微信交流群，提供给大家一个交流的平台，扫描下方笔者的微信二维码，备注【交流】，我会把大家拉进群]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring生命周期]]></title>
      <url>%2F2020%2F03%2F23%2FSpring%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%2F</url>
      <content type="text"><![CDATA[导读 Spring中Bean的生命周期从容器的启动到停止，涉及到的源码主要是在org.springframework.context.support.AbstractApplicationContext.refresh方法中，下面也是围绕其中的逻辑进行讲解。 开撸【1】 prepareRefresh() 内部其实很简单，就是设置一些标志，比如开始时间，激活的状态等。 【2】prepareBeanFactory(beanFactory) 做一些简单的准备工作，此处不再赘述！！！ 【3】postProcessBeanFactory(beanFactory) 主要的作用就是添加了一个后置处理器ServletContextAwareProcessor 【4】invokeBeanFactoryPostProcessors(beanFactory) 调用容器中的所有的BeanFactoryPostProcessor中的postProcessBeanFactory方法，按照优先级调用，主要实现逻辑在org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(org.springframework.beans.factory.config.ConfigurableListableBeanFactory, java.util.List) (1) 执行所有BeanDefinitionRegistryPostProcessor(对BeanFactoryPostProcessor的扩展，运行在普通的实现类之前注册bean)的方法，同样是内部按照优先级进行排序调用 (2) 对剩余的进行按照优先级排序调用，同样是内部进行排序执行 【5】registerBeanPostProcessors(beanFactory) 注册所有的BeanPostProcessor（后置处理器），按照优先级注册，分别是PriorityOrdered，Ordered，普通的，内部的。主要的实现逻辑在PostProcessorRegistrationDelegate.registerBeanPostProcessors() 【6】initMessageSource()注册MessageSource,提供消息国际化等功能 【7】initApplicationEventMulticaster(); 注册事件广播器ApplicationEventMulticaster，用于spring事件的广播和事件监听器的处理 【8】registerListeners() 注册事件监听器ApplicationListener，并且广播一些早期的事件，主要的逻辑在org.springframework.context.support.AbstractApplicationContext.registerListeners 【9】finishBeanFactoryInitialization(beanFactory) 实例化所有非懒加载的Bean，spring生命周期中的主要方法，主要逻辑在org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons，深入进去其实就是getBean()方法创建，详情向下看。 【10】finishRefresh() 主要的功能是发布事件ContextRefreshedEvent 【11】destroyBeans() 容器启动出现异常时销毁Bean 以上就是Spring容器启动的过程，主要的逻辑都在org.springframework.context.support.AbstractApplicationContext#refresh中，其他的都很容易理解，现在我们着重分析一下单例Bean的创建过程，入口是第9步。 实例化单例Bean【1】debug进入，实际主要的逻辑都在org.springframework.beans.factory.support.DefaultListableBeanFactory#preInstantiateSingletons方法中，逻辑如下： 1234567891011121314151617//获取所有注入到ioc容器中的bean定义信息List&lt;String&gt; beanNames = new ArrayList&lt;&gt;(this.beanDefinitionNames); //循环创建 for (String beanName : beanNames) &#123; RootBeanDefinition bd = getMergedLocalBeanDefinition(beanName); //非抽象，单例，非懒加载的bean初始化 if (!bd.isAbstract() &amp;&amp; bd.isSingleton() &amp;&amp; !bd.isLazyInit()) &#123; //如果是FactoryBean if (isFactoryBean(beanName)) &#123; //getBean Object bean = getBean(FACTORY_BEAN_PREFIX + beanName); //非FactoryBean，getBean else &#123; getBean(beanName); &#125; &#125; &#125; 以上源码总结得知，最终实例化Bean的方法肯定在getBean中的，debug进入，得知doGetBean是大boss，spring源码有趣的是最终的实现都是在doxxxx()。 【2】AbstractBeanFactory#doGetBean，由于篇幅太短，就不贴源码了，只贴关键代码 实例化的主要流程全部都在这里，下面一一解析即可。 (1) Object sharedInstance = getSingleton(beanName) 从早期的缓存中获取，如果存在返回Bean，实例化 （2）BeanFactory parentBeanFactory = getParentBeanFactory() 从父工厂的中获取Bean （3）if (mbd.isSingleton()) 分单例和多例进行分开创建Bean，这里只分析单例Bean的创建 （4）sharedInstance = getSingleton(beanName, () -&gt; { try { return createBean(beanName, mbd, args); } createBean方法创建Bean，进入createBean(） ​ a. Object bean = resolveBeforeInstantiation(beanName, mbdToUse)：执行所有的InstantiationAwareBeanPostProcessor中的postProcessBeforeInstantiation，在实例化之前调用，返回null继续下一步，返回一个bean，那么bean实例化完成，将调用其中的postProcessAfterInstantiation方法 ​ b. Object beanInstance = doCreateBean(beanName, mbdToUse, args)：创建Bean的完成过程 ​ c. 进入doCreateBean，instanceWrapper = createBeanInstance(beanName, mbd, args)：创建Bean的实例 ​ d. populateBean(beanName, mbd, instanceWrapper)：属性装配，执行InstantiationAwareBeanPostProcessor的postProcessAfterInstantiation，再执行postProcessProperties方法。 ​ e. exposedObject = initializeBean(beanName, exposedObject, mbd)：初始化Bean，debug进入 ​ f. invokeAwareMethods(beanName, bean)：调用BeanNameAware，BeanClassLoaderAware，BeanFactoryAware中的对应方法 ​ g. wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName)：调用BeanPostProcessord中的postProcessBeforeInitialization方法 ​ h. invokeInitMethods(beanName, wrappedBean, mbd)：执行InitializingBean中的afterPropertiesSet ​ i. wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName)：调用BeanPostProcessor中的postProcessAfterInitialization方法 总结以上是spring容器从启动到销毁的全部过程，根据源码陈某画了一张生命周期的图，仅供参考，请勿转载！！！ 笔者有话说 最近建了一个微信交流群，提供给大家一个交流的平台，扫描下方笔者的微信二维码，备注【交流】，我会把大家拉进群]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[接口限流算法]]></title>
      <url>%2F2020%2F03%2F23%2F%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81%E7%AE%97%E6%B3%95%2F</url>
      <content type="text"><![CDATA[导读 前几天和一个朋友讨论了他们公司的系统问题，传统的单体应用，集群部署，他说近期服务的并发量可能会出现瞬时增加的风险，虽然部署了集群，但是通过压测后发现请求延迟仍然是很大，想问问我有什么改进的地方。我沉思了一会，现在去改架构显然是不可能的，于是我给出了一个建议，让他去做个接口限流，这样能够保证瞬时并发量飙高也不会出现请求延迟的问题，用户的体验度也会上去。 至于什么是接口限流？怎么实现接口限流？如何实现单机应用的限流？如何实现分布式应用的限流？本篇文章将会详细阐述。 限流的常见几种算法 常见的限流算法有很多，但是最常用的算法无非以下四种。 固定窗口计数器 固定算法的概念如下 将时间划分为多个窗口 在每个窗口内每有一次请求就将计数器加一 如果计数器超过了限制数量，则本窗口内所有的请求都被丢弃当时间到达下一个窗口时，计数器重置。 固定窗口计数器是最为简单的算法，但这个算法有时会让通过请求量允许为限制的两倍。考虑如下情况：限制 1 秒内最多通过 5 个请求，在第一个窗口的最后半秒内通过了 5 个请求，第二个窗口的前半秒内又通过了 5 个请求。这样看来就是在 1 秒内通过了 10 个请求。 滑动窗口计数器 滑动窗口计数器算法概念如下： 将时间划分为多个区间； 在每个区间内每有一次请求就将计数器加一维持一个时间窗口，占据多个区间； 每经过一个区间的时间，则抛弃最老的一个区间，并纳入最新的一个区间； 如果当前窗口内区间的请求计数总和超过了限制数量，则本窗口内所有的请求都被丢弃。 滑动窗口计数器是通过将窗口再细分，并且按照时间 “ 滑动 “，这种算法避免了固定窗口计数器带来的双倍突发请求，但时间区间的精度越高，算法所需的空间容量就越大。 漏桶算法 漏桶算法概念如下： 将每个请求视作 “ 水滴 “ 放入 “ 漏桶 “ 进行存储； “漏桶 “ 以固定速率向外 “ 漏 “ 出请求来执行如果 “ 漏桶 “ 空了则停止 “ 漏水”； 如果 “ 漏桶 “ 满了则多余的 “ 水滴 “ 会被直接丢弃。 漏桶算法多使用队列实现，服务的请求会存到队列中，服务的提供方则按照固定的速率从队列中取出请求并执行，过多的请求则放在队列中排队或直接拒绝。 漏桶算法的缺陷也很明显，当短时间内有大量的突发请求时，即便此时服务器没有任何负载，每个请求也都得在队列中等待一段时间才能被响应。 令牌桶算法 令牌桶算法概念如下： 令牌以固定速率生成。 生成的令牌放入令牌桶中存放，如果令牌桶满了则多余的令牌会直接丢弃，当请求到达时，会尝试从令牌桶中取令牌，取到了令牌的请求可以执行。 如果桶空了，那么尝试取令牌的请求会被直接丢弃。 令牌桶算法既能够将所有的请求平均分布到时间区间内，又能接受服务器能够承受范围内的突发请求，因此是目前使用较为广泛的一种限流算法。 单体应用实现 在传统的单体应用中限流只需要考虑到多线程即可，使用Google开源工具类guava即可。其中有一个RateLimiter专门实现了单体应用的限流，使用的是令牌桶算法。 单体应用的限流不是本文的重点，官网上现成的API，读者自己去看看即可，这里不再详细解释。 分布式限流 分布式限流和熔断现在有很多的现成的工具，比如Hystrix，Sentinel 等，但是还是有些企业不引用外来类库，因此就需要自己实现。 Redis作为单线程多路复用的特性，很显然能够胜任这项任务。 Redis如何实现 使用令牌桶的算法实现，根据前面的介绍，我们了解到令牌桶算法的基础需要两个个变量，分别是桶容量，产生令牌的速率。 这里我们实现的就是每秒产生的速率加上一个桶容量。但是如何实现呢？这里有几个问题。 需要保存什么数据在redis中？ 当前桶的容量，最新的请求时间 以什么数据结构存储？ 因为是针对接口限流，每个接口的业务逻辑不同，对并发的处理也是不同，因此要细化到每个接口的限流，此时我们选用HashMap的结构，hashKey是接口的唯一id，可以是请求的uri，里面的分别存储当前桶的容量和最新的请求时间。 如何计算需要放令牌？ 根据redis保存的上次的请求时间和当前时间比较，如果相差大于的产生令牌的时间（陈某实现的是1秒）则再次产生令牌，此时的桶容量为当前令牌+产生的令牌 如何保证redis的原子性？ 保证redis的原子性，使用lua脚本即可解决。 有了上述的几个问题，便能很容易的实现。 开撸1、lua脚本如下： 1234567891011121314151617181920212223242526272829303132local ratelimit_info = redis.pcall('HMGET',KEYS[1],'last_time','current_token')local last_time = ratelimit_info[1]local current_token = tonumber(ratelimit_info[2])local max_token = tonumber(ARGV[1])local token_rate = tonumber(ARGV[2])local current_time = tonumber(ARGV[3])if current_token == nil then current_token = max_token last_time = current_timeelse local past_time = current_time-last_time if past_time&gt;1000 then current_token = current_token+token_rate last_time = current_time end ## 防止溢出 if current_token&gt;max_token then current_token = max_token last_time = current_time endendlocal result = 0if(current_token&gt;0) then result = 1 current_token = current_token-1 last_time = current_timeendredis.call('HMSET',KEYS[1],'last_time',last_time,'current_token',current_token)return result 调用lua脚本出四个参数，分别是接口方法唯一id，桶容量，每秒产生令牌的数量，当前请求的时间戳。 2、 SpringBoot代码实现 采用Spring-data-redis实现lua脚本的执行。 Redis序列化配置： 12345678910111213141516171819202122/** * 重新注入模板 */ @Bean(value = "redisTemplate") @Primary public RedisTemplate redisTemplate(RedisConnectionFactory redisConnectionFactory)&#123; RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;&gt;(); template.setConnectionFactory(redisConnectionFactory); ObjectMapper objectMapper = new ObjectMapper(); objectMapper.setSerializationInclusion(JsonInclude.Include.NON_NULL); objectMapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); //设置序列化方式，key设置string 方式，value设置成json StringRedisSerializer stringRedisSerializer = new StringRedisSerializer(); Jackson2JsonRedisSerializer jsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); jsonRedisSerializer.setObjectMapper(objectMapper); template.setEnableDefaultSerializer(false); template.setKeySerializer(stringRedisSerializer); template.setHashKeySerializer(stringRedisSerializer); template.setValueSerializer(jsonRedisSerializer); template.setHashValueSerializer(jsonRedisSerializer); return template; &#125; 限流工具类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/** * @Description 限流工具类 * @Author CJB * @Date 2020/3/19 17:21 */public class RedisLimiterUtils &#123; private static StringRedisTemplate stringRedisTemplate=ApplicationContextUtils.applicationContext.getBean(StringRedisTemplate.class); /** * lua脚本，限流 */ private final static String TEXT="local ratelimit_info = redis.pcall('HMGET',KEYS[1],'last_time','current_token')\n" + "local last_time = ratelimit_info[1]\n" + "local current_token = tonumber(ratelimit_info[2])\n" + "local max_token = tonumber(ARGV[1])\n" + "local token_rate = tonumber(ARGV[2])\n" + "local current_time = tonumber(ARGV[3])\n" + "if current_token == nil then\n" + " current_token = max_token\n" + " last_time = current_time\n" + "else\n" + " local past_time = current_time-last_time\n" + " \n" + " if past_time&gt;1000 then\n" + "\t current_token = current_token+token_rate\n" + "\t last_time = current_time\n" + " end\n" + "\n" + " if current_token&gt;max_token then\n" + " current_token = max_token\n" + "\tlast_time = current_time\n" + " end\n" + "end\n" + "\n" + "local result = 0\n" + "if(current_token&gt;0) then\n" + " result = 1\n" + " current_token = current_token-1\n" + " last_time = current_time\n" + "end\n" + "redis.call('HMSET',KEYS[1],'last_time',last_time,'current_token',current_token)\n" + "return result"; /** * 获取令牌 * @param key 请求id * @param max 最大能同时承受多少的并发（桶容量） * @param rate 每秒生成多少的令牌 * @return 获取令牌返回true，没有获取返回false */ public static boolean tryAcquire(String key, int max,int rate) &#123; List&lt;String&gt; keyList = new ArrayList&lt;&gt;(1); keyList.add(key); DefaultRedisScript&lt;Long&gt; script = new DefaultRedisScript&lt;&gt;(); script.setResultType(Long.class); script.setScriptText(TEXT); return Long.valueOf(1).equals(stringRedisTemplate.execute(script,keyList,Integer.toString(max), Integer.toString(rate), Long.toString(System.currentTimeMillis()))); &#125;&#125; 采用拦截器+注解的方式实现，注解如下： 123456789101112131415161718192021/** * @Description 限流的注解，标注在类上或者方法上。在方法上的注解会覆盖类上的注解，同@Transactional * @Author CJB * @Date 2020/3/20 13:36 */@Inherited@Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;)@Retention(RetentionPolicy.RUNTIME)public @interface RateLimit &#123; /** * 令牌桶的容量，默认100 * @return */ int capacity() default 100; /** * 每秒钟默认产生令牌数量，默认10个 * @return */ int rate() default 10;&#125; 拦截器如下： 1234567891011121314151617181920212223242526272829303132333435/** * @Description 限流的拦器 * @Author CJB * @Date 2020/3/19 14:34 */@Componentpublic class RateLimiterIntercept implements HandlerInterceptor &#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; if (handler instanceof HandlerMethod)&#123; HandlerMethod handlerMethod=(HandlerMethod)handler; Method method = handlerMethod.getMethod(); /** * 首先获取方法上的注解 */ RateLimit rateLimit = AnnotationUtils.findAnnotation(method, RateLimit.class); //方法上没有标注该注解，尝试获取类上的注解 if (Objects.isNull(rateLimit))&#123; //获取类上的注解 rateLimit = AnnotationUtils.findAnnotation(handlerMethod.getBean().getClass(), RateLimit.class); &#125; //没有标注注解，放行 if (Objects.isNull(rateLimit)) return true; //尝试获取令牌，如果没有令牌了 if (!RedisLimiterUtils.tryAcquire(request.getRequestURI(),rateLimit.capacity(),rateLimit.rate()))&#123; //抛出请求超时的异常 throw new TimeOutException(); &#125; &#125; return true; &#125;&#125; SpringBoot配置拦截器的代码就不贴了，以上就是完整的代码，至此分布式限流就完成了。 笔者有话说 最近建了一个微信交流群，提供给大家一个交流的平台，扫描下方笔者的微信二维码，备注【交流】，我会把大家拉进群]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SpringBoot整合多数据源的巨坑]]></title>
      <url>%2F2020%2F03%2F18%2FSpringBoot%E6%95%B4%E5%90%88%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%90%E7%9A%84%E5%B7%A8%E5%9D%91%2F</url>
      <content type="text"><![CDATA[导读 本篇文章接上篇SpringBoot整合多数据源，你会了吗？，前面文章最后留了几个问题供大家思考，今天一一揭晓。 配置如何优化 上文整合的过程中的还顺带整合Mybatis和TransactionManager，为什么还要重新定义他们呢？SpringBoot不是给我们都配置好了吗？注意，此处优化就是这两个配置去掉，直接用SpringBoot的自动配置，顿时高级了，别人一看你的代码如此简单就实现了多数据源的切换，牛叉不？ 如何去掉？SpringBoot万变不离自动配置类，且看MybatisAutoConfiguration，如下： 123456@org.springframework.context.annotation.Configuration@ConditionalOnClass(&#123; SqlSessionFactory.class, SqlSessionFactoryBean.class &#125;)@ConditionalOnSingleCandidate(DataSource.class)@EnableConfigurationProperties(MybatisProperties.class)@AutoConfigureAfter(DataSourceAutoConfiguration.class)public class MybatisAutoConfiguration implements InitializingBean &#123; 不多帖了，都是废话，看前几行就行了，醒目的一行啊，@ConditionalOnSingleCandidate(DataSource.class)，什么鬼？该注解的意思就是IOC容器中只有一个指定的候选对象才起作用，但是我们注入了几个DataSource，足足三个啊，这还起作用吗？那不废话嘛。 事务管理器也是一样，且看DataSourceTransactionManagerAutoConfiguration，如下： 12345public class DataSourceTransactionManagerAutoConfiguration &#123; @Configuration @ConditionalOnSingleCandidate(DataSource.class) static class DataSourceTransactionManagerConfiguration &#123; 又看到了什么，@ConditionalOnSingleCandidate(DataSource.class)同样的醒目，mmp，这不玩我呢吗。这怎么搞？ 咦，不着急，此时就要看看@ConditionalOnSingleCandidate注解搞了什么，进去看看，有如下的介绍： 1The condition will also match if multiple matching bean instances are already contained in the BeanFactory but a primary candidate has been defined; essentially, the condition match if auto-wiring a bean with the defined type will succeed. 什么鬼，看不懂，英语太差了吧，不着急，陈某给大家推荐一个IDEA插件，文档翻译更加专注于程序员的专业术语，不像xx度翻译，如下： 好了，翻译准确了就知道了，大致意思就是IOC容器中允许你有多个候选对象，但是你必须有一个主（primary）候选对象，顿时灵光一现，这不就是@Primary注解吗，艹，我这也太优秀了吧。 二话不说，直接开撸，轻轻松松一个注解搞定，此时的数据源配置变得简单多了，如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * @Description 数据源的配置 * @Author CJB * @Date 2020/3/9 13:45 */@Configuration@MapperScan(basePackages = &#123;"com.vivachek.service.dao","com.vivachek.service.dao2"&#125;)public class DatasourceConfig &#123; /** * 注入数据源1 */ @ConfigurationProperties(prefix = "spring.datasource1") @Bean(value = "dataSource1") public DataSource dataSource1() &#123; return new DruidDataSource(); &#125; /** * 第二个数据源 */ @Bean(name = "dataSource2") @ConfigurationProperties(prefix = "spring.datasource2") public DataSource dataSource2() &#123; return new DruidDataSource(); &#125; /** * 动态数据源 * * @return */ @Bean @Primary public DynamicDataSource dynamicDataSource() &#123; DynamicDataSource dataSource = new DynamicDataSource(); //默认数据源，在没有切换数据源的时候使用该数据源 dataSource.setDefaultTargetDataSource(dataSource2()); HashMap&lt;Object, Object&gt; map = Maps.newHashMap(); map.put("dataSource1", dataSource1()); map.put("dataSource2", dataSource2()); //设置数据源Map，动态切换就是根据key从map中获取 dataSource.setTargetDataSources(map); return dataSource; &#125;&#125; 直接在DynamicDataSource添加了一个@Primary就省去了SqlSessionFactory和TransactionManager的手动配置，是不是很easy并且显得自己很牛叉，太有成就感了….. 好了，牛也吹了，运行一下吧，满怀期待等待30秒…….，what？什么鬼？失败了，抛出了异常，如下： 什么鬼，循环依赖异常，搞什么飞机，一万个草泥马在奔腾在横无际涯的草原上。。。。。。。。 别急，还有后续，关注我，将会定时更新后续文章。另外需要源码的联系我，微信联系方式在个人独立博客【关于我】中，加我注明来意，谢谢。 别忘了点赞哟，多来走动走动呗………. 动态路由数据源添加@Primary报循环依赖异常 前面文章Spring解决循环依赖有说过Spring对于循环依赖是完全能够解决的，没有读过的小伙伴建议看一下，里面详细的讲述了Spring是如何解决循环依赖的，此处就不再赘述了。 既然Spring能够解决循环依赖，为什么这里又会报循环依赖的异常呢？我们不妨跟着代码看看是怎样的循环依赖，如下： 上面两个数据源都是自己定义的，先不用看，那么肯定是DataSourceInitializerInvoker造成的循环依赖了，果不其然，其中确实依赖了DataSource，源码如下： 123456DataSourceInitializerInvoker(ObjectProvider&lt;DataSource&gt; dataSource, DataSourceProperties properties, ApplicationContext applicationContext) &#123; this.dataSource = dataSource; this.properties = properties; this.applicationContext = applicationContext; &#125; what？即使依赖了又怎样？Spring不是可以解决循环依赖吗？别着急下面分析 ObjectProvider应该不陌生吧，其实内部就是从IOC容器中获取Bean而已，但是，转折来了……… ，这是什么，这是构造器，Spring能解决构造器的循环依赖吗？答案是不能，所以原因找到了，这里不再细说了，欲知原因请读Spring解循环依赖 问题找到了，如何解决？此时心中一万个草泥马奔腾，怎么解决呢？ 哈哈，此时插播一条广告，本人的独立博客已经发布了很多文章，感兴趣的可以收藏一下，【关于我】中有我的微信联系方式，欢迎交流。 回到正题，如何解决？很简单，找到这个DataSourceInitializerInvoker是什么时候注入到IOC容器中的，因此我们找到了DataSourceAutoConfiguration，继而找到了DataSourceInitializationConfiguration这个配置类，源码如下： 12345678910111213141516171819202122232425262728@Configuration@ConditionalOnClass(&#123; DataSource.class, EmbeddedDatabaseType.class &#125;)@EnableConfigurationProperties(DataSourceProperties.class)@Import(&#123; DataSourcePoolMetadataProvidersConfiguration.class, DataSourceInitializationConfiguration.class &#125;)public class DataSourceAutoConfiguration &#123; @Configuration @Conditional(EmbeddedDatabaseCondition.class) @ConditionalOnMissingBean(&#123; DataSource.class, XADataSource.class &#125;) @Import(EmbeddedDataSourceConfiguration.class) protected static class EmbeddedDatabaseConfiguration &#123; &#125; @Configuration @Conditional(PooledDataSourceCondition.class) @ConditionalOnMissingBean(&#123; DataSource.class, XADataSource.class &#125;) @Import(&#123; DataSourceConfiguration.Hikari.class, DataSourceConfiguration.Tomcat.class, DataSourceConfiguration.Dbcp2.class, DataSourceConfiguration.Generic.class, DataSourceJmxConfiguration.class &#125;) protected static class PooledDataSourceConfiguration &#123; &#125; &#125; @Configuration@Import(&#123; DataSourceInitializerInvoker.class, DataSourceInitializationConfiguration.Registrar.class &#125;)class DataSourceInitializationConfiguration &#123; 贴了那么多代码谁看的懂？草泥马又奔腾了，可以看到源码中出现了两次@ConditionalOnMissingBean({ DataSource.class, XADataSource.class })，这什么鬼，不多说了，相信读过SpringBoot源码的都知道，这个配置类根本不起作用啊，那还要它干嘛，直接搞掉不就完事了。好了，分析到这里终于知道解决的方案了，搞掉DataSourceAutoConfiguration，怎么搞呢？一个注解搞定。 12//排除配置类@SpringBootApplication(exclude = &#123;DataSourceAutoConfiguration.class&#125;) 问题迎刃而解了，简单不，惊喜不，不好，又奔腾了。。。。 笔者有话说 最近建了一个微信交流群，提供给大家一个交流的平台，扫描下方笔者的微信二维码，备注【交流】，我会把大家拉进群]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring解决循环依赖]]></title>
      <url>%2F2019%2F07%2F17%2FSpring%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%2F</url>
      <content type="text"><![CDATA[导读 前几天发表的文章SpringBoot多数据源动态切换和SpringBoot整合多数据源的巨坑中，提到了一个坑就是动态数据源添加@Primary接口就会造成循环依赖异常，如下图： 这个就是典型的构造器依赖，详情请看上面两篇文章，这里不再详细赘述了。本篇文章将会从源码深入解析Spring是如何解决循环依赖的？为什么不能解决构造器的循环依赖？ 什么是循环依赖 简单的说就是A依赖B，B依赖C，C依赖A这样就构成了循环依赖。 循环依赖分为构造器依赖和属性依赖，众所周知的是Spring能够解决属性的循环依赖（set注入）。下文将从源码角度分析Spring是如何解决属性的循环依赖。 思路 如何解决循环依赖，Spring主要的思路就是依据三级缓存，在实例化A时调用doGetBean，发现A依赖的B的实例，此时调用doGetBean去实例B，实例化的B的时候发现又依赖A，如果不解决这个循环依赖的话此时的doGetBean将会无限循环下去，导致内存溢出，程序奔溃。spring引用了一个早期对象，并且把这个”早期引用”并将其注入到容器中，让B先完成实例化，此时A就获取B的引用，完成实例化。 三级缓存 Spring能够轻松的解决属性的循环依赖正式用到了三级缓存，在AbstractBeanFactory中有详细的注释。 12345678/**一级缓存，用于存放完全初始化好的 bean，从该缓存中取出的 bean 可以直接使用*/private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;&gt;(256);/**三级缓存 存放 bean 工厂对象，用于解决循环依赖*/private final Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories = new HashMap&lt;&gt;(16);/**二级缓存 存放原始的 bean 对象（尚未填充属性），用于解决循环依赖*/private final Map&lt;String, Object&gt; earlySingletonObjects = new HashMap&lt;&gt;(16); 一级缓存：singletonObjects，存放完全实例化属性赋值完成的Bean，直接可以使用。 二级缓存：earlySingletonObjects，存放早期Bean的引用，尚未属性装配的Bean 三级缓存：singletonFactories，三级缓存，存放实例化完成的Bean工厂。 开撸 先上一张流程图看看Spring是如何解决循环依赖的 上图标记蓝色的部分都是涉及到三级缓存的操作，下面我们一个一个方法解析 【1】 getSingleton(beanName)：源码如下： 1234567891011121314151617181920212223242526272829303132333435 //查询缓存 Object sharedInstance = getSingleton(beanName); //缓存中存在并且args是null if (sharedInstance != null &amp;&amp; args == null) &#123; //.......省略部分代码 //直接获取Bean实例 bean = getObjectForBeanInstance(sharedInstance, name, beanName, null); &#125; //getSingleton源码，DefaultSingletonBeanRegistry#getSingletonprotected Object getSingleton(String beanName, boolean allowEarlyReference) &#123; //先从一级缓存中获取已经实例化属性赋值完成的Bean Object singletonObject = this.singletonObjects.get(beanName); //一级缓存不存在，并且Bean正处于创建的过程中 if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) &#123; synchronized (this.singletonObjects) &#123; //从二级缓存中查询，获取Bean的早期引用，实例化完成但是未赋值完成的Bean singletonObject = this.earlySingletonObjects.get(beanName); //二级缓存中不存在，并且允许创建早期引用（二级缓存中添加） if (singletonObject == null &amp;&amp; allowEarlyReference) &#123; //从三级缓存中查询，实例化完成，属性未装配完成 ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName); if (singletonFactory != null) &#123; singletonObject = singletonFactory.getObject(); //二级缓存中添加 this.earlySingletonObjects.put(beanName, singletonObject); //从三级缓存中移除 this.singletonFactories.remove(beanName); &#125; &#125; &#125; &#125; return singletonObject; &#125; 从源码可以得知，doGetBean最初是查询缓存，一二三级缓存全部查询，如果三级缓存存在则将Bean早期引用存放在二级缓存中并移除三级缓存。（升级为二级缓存） 【2】addSingletonFactory：源码如下 123456789101112131415161718192021222324252627282930313233 //中间省略部分代码。。。。。 //创建Bean的源码，在AbstractAutowireCapableBeanFactory#doCreateBean方法中 if (instanceWrapper == null) &#123; //实例化Bean instanceWrapper = createBeanInstance(beanName, mbd, args); &#125; //允许提前暴露 if (earlySingletonExposure) &#123; //添加到三级缓存中 addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean)); &#125; try &#123; //属性装配，属性赋值的时候，如果有发现属性引用了另外一个Bean，则调用getBean方法 populateBean(beanName, mbd, instanceWrapper); //初始化Bean，调用init-method，afterproperties方法等操作 exposedObject = initializeBean(beanName, exposedObject, mbd); &#125; &#125;//添加到三级缓存的源码，在DefaultSingletonBeanRegistry#addSingletonFactoryprotected void addSingletonFactory(String beanName, ObjectFactory&lt;?&gt; singletonFactory) &#123; synchronized (this.singletonObjects) &#123; //一级缓存中不存在 if (!this.singletonObjects.containsKey(beanName)) &#123; //放入三级缓存 this.singletonFactories.put(beanName, singletonFactory); //从二级缓存中移除， this.earlySingletonObjects.remove(beanName); this.registeredSingletons.add(beanName); &#125; &#125; &#125; 从源码得知，Bean在实例化完成之后会直接将未装配的Bean工厂存放在三级缓存中，并且移除二级缓存 【3】addSingleton：源码如下： 123456789101112131415161718192021//获取单例对象的方法，DefaultSingletonBeanRegistry#getSingleton//调用createBean实例化BeansingletonObject = singletonFactory.getObject();//。。。。中间省略部分代码 //doCreateBean之后才调用，实例化，属性赋值完成的Bean装入一级缓存，可以直接使用的BeanaddSingleton(beanName, singletonObject);//addSingleton源码，在DefaultSingletonBeanRegistry#addSingleton方法中protected void addSingleton(String beanName, Object singletonObject) &#123; synchronized (this.singletonObjects) &#123; //一级缓存中添加 this.singletonObjects.put(beanName, singletonObject); //移除三级缓存 this.singletonFactories.remove(beanName); //移除二级缓存 this.earlySingletonObjects.remove(beanName); this.registeredSingletons.add(beanName); &#125; &#125; 总之一句话，Bean添加到一级缓存，移除二三级缓存。 扩展 【1】为什么Spring不能解决构造器的循环依赖？ 从流程图应该不难看出来，在Bean调用构造器实例化之前，一二三级缓存并没有Bean的任何相关信息，在实例化之后才放入三级缓存中，因此当getBean的时候缓存并没有命中，这样就抛出了循环依赖的异常了。 【2】为什么多实例Bean不能解决循环依赖？ 多实例Bean是每次创建都会调用doGetBean方法，根本没有使用一二三级缓存，肯定不能解决循环依赖。 总结 根据以上的分析，大概清楚了Spring是如何解决循环依赖的。假设A依赖B，B依赖A（注意：这里是set属性依赖）分以下步骤执行： A依次执行doGetBean、查询缓存、createBean创建实例，实例化完成放入三级缓存singletonFactories中，接着执行populateBean方法装配属性，但是发现有一个属性是B的对象。 因此再次调用doGetBean方法创建B的实例，依次执行doGetBean、查询缓存、createBean创建实例，实例化完成之后放入三级缓存singletonFactories中，执行populateBean装配属性，但是此时发现有一个属性是A对象。 因此再次调用doGetBean创建A的实例，但是执行到getSingleton查询缓存的时候，从三级缓存中查询到了A的实例(早期引用，未完成属性装配)，此时直接返回A，不用执行后续的流程创建A了，那么B就完成了属性装配，此时是一个完整的对象放入到一级缓存singletonObjects中。 B创建完成了，则A自然完成了属性装配，也创建完成放入了一级缓存singletonObjects中。 Spring三级缓存的应用完美的解决了循环依赖的问题，下面是循环依赖的解决流程图。 笔者有话说 最近建了一个微信交流群，提供给大家一个交流的平台，扫描下方笔者的微信二维码，备注【交流】，我会把大家拉进群]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[设计模式之适配器模式]]></title>
      <url>%2F2018%2F04%2F16%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F%2F</url>
      <content type="text"><![CDATA[结构型模式之适配器模式定义 适配器模式用于将一个接口转化成客户想要的另一个接口，使接口不兼容的那些类可以一起工作，其别名为包装器(Wrapper)。适配器模式既可以作为类结构型模式，也可以作为对象结构型模式。 Target（目标抽象类）：目标抽象类定义客户所需接口，可以是一个抽象类或接口，也可以是具体类。 Adapter（适配器类）：适配器可以调用另一个接口，作为一个转换器，对Adaptee和Target进行适配，适配器类是适配器模式的核心，在对象适配器中，它通过继承Target并关联一个Adaptee对象使二者产生联系。 Adaptee（适配者类）：适配者即被适配的角色，它定义了一个已经存在的接口，这个接口需要适配，适配者类一般是一个具体类，包含了客户希望使用的业务方法，在某些情况下可能没有适配者类的源代码。 根据对象适配器模式结构图，在对象适配器中，客户端需要调用request()方法，而适配者类Adaptee没有该方法，但是它所提供的specificRequest()方法却是客户端所需要的。为了使客户端能够使用适配者类，需要提供一个包装类Adapter，即适配器类。这个包装类包装了一个适配者的实例，从而将客户端与适配者衔接起来，在适配器的request()方法中调用适配者的specificRequest()方法。因为适配器类与适配者类是关联关系（也可称之为委派关系），所以这种适配器模式称为对象适配器模式 类适配器 类适配器是继承适配者类实现的，其中对象适配器是使用组合的方式实现的，就是适配者类作为适配器类的成员变量而实现的 一般目标抽象类是一个接口，适配者类一般是一个具体的实现类，有时候甚至不知道其中的源代码，因此需要适配器类将适配者类转换成适合用户的目标类 实例 我们知道笔记本充电的电压是5v，但是我们的高压电是220v，那么我们此时就需要一个适配器将这个220v电压转换成为5v的电压给笔记本充电 这里的220v电压就是适配者类，即是需要转换的类 5v电压是目标抽象类，由适配器将220v转换而来 这里的适配器类的主要功能就是将220v电压转换成5v电压 目标接口(5v电压) 1234567/* * 接口为5v电压的接口 ， 这个目标抽象类 */public interface Power5 &#123; void getPower5();&#125; 220v电压的类（这里是一个具体的类，适配者类） 12345public class Power220 &#123; public void getPower220()&#123; System.out.println("正在输出220v电压....."); &#125;&#125; 适配器类（将220v电压转换成5v） 1234567891011121314151617181920212223242526/* * 适配器类，主要的目的就是将220v电压转换为5v的电压供笔记本充电 * 其中Power5是目标抽象接口，是最终需要的接口，Power220是一个适配者类，是已经存在的，只需要适配器转换即可 */public class AdapterPower5 extends Power220 implements Power5 &#123; /** * 重载Power5中的方法，获取需要的5v电压 * 过程： 先获取220v电压，然后进行转换即可 * */ @Override public void getPower5() &#123; super.getPower220(); //首先获取220v电压 this.transform(); //将220v电压转换成5v的电压 System.out.println("获取5v电压......."); &#125; /* * 将220v电压转换成5v电压的方法 */ public void transform() &#123; System.out.println("现在将220v电压转换成5v电压......."); &#125;&#125; 笔记本充电的类 12345678910111213/* * 笔记本类 */public class NoteBook &#123; /** * 笔记本充电的方法 * @param power5 电压为5v的对象 */ public void PowerOn(Power5 power5)&#123; power5.getPower5(); //获取5v电压 System.out.println("笔记本获取了5v的电压，正在开始充电......"); &#125;&#125; 测试类 123456public class Client &#123; public static void main(String[] args) &#123; NoteBook noteBook=new NoteBook(); //创建笔记本的类 noteBook.PowerOn(new AdapterPower5()); //调用笔记本充电的类 &#125;&#125; 对象适配器 对象适配器是将适配者类作为适配器类的成员变量并不是继承，这个是一种组合方式 这种方式使用的更加普遍 实例 这里的实例还是前面的例子 这里唯一不同的就是适配器类，不是继承适配者类，而是使用组合的方式 1234567891011121314151617181920212223242526/* * 适配器类，这个是对象适配器，适配者类是作为成员变量存在，是组合关系 */public class Adapter implements Power5 &#123; private Power220 power; //220v电压类的对象，作为成员变量 /* * 构造方法，主要是为类初始化Power220v的对象 */ public Adapter(Power220 power)&#123; this.power=power; &#125; @Override public void getPower5() &#123; power.getPower220(); //获取220v电压 transform(); //转换电压 System.out.println("正在输出5v电压......."); &#125; public void transform()&#123; System.out.println("将220v电压转换成5v的电压......"); &#125;&#125; 总结 类适配器是使用类继承的方式，适配器类继承适配者类(不提倡使用) 对象适配器使用的是一种组合的方式，将适配者类作为其中的成员变量，那么也是可以实现（提倡使用） 麻烦支持下博主的广告事业，点击下即可 笔者有话说 最近建了一个微信交流群，提供给大家一个交流的平台，扫描下方笔者的微信二维码，备注【交流】，我会把大家拉进群]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[设计模式之桥接模式]]></title>
      <url>%2F2018%2F04%2F16%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E6%A1%A5%E6%8E%A5%E6%A8%A1%E5%BC%8F%2F</url>
      <content type="text"><![CDATA[结构型模式之桥接模式 桥接模式是一种很实用的结构型设计模式，如果软件系统中某个类存在两个独立变化的维度，通过该模式可以将这两个维度分离出来，使两者可以独立扩展，让系统更加符合“单一职责原则”。与多层继承方案不同，它将两个独立变化的维度设计为两个独立的继承等级结构，并且在抽象层建立一个抽象关联，该关联关系类似一条连接两个独立继承结构的桥，故名桥接模式。 桥接模式用一种巧妙的方式处理多层继承存在的问题，用抽象关联取代了传统的多层继承，将类之间的静态继承关系转换为动态的对象组合关系，使得系统更加灵活，并易于扩展，同时有效控制了系统中类的个数。桥接定义如下： 桥接模式(Bridge Pattern)：将抽象部分与它的实现部分分离，使它们都可以独立地变化。它是一种对象结构型模式，又称为柄体(Handle and Body)模式或接口(Interface)模式。 在桥接模式结构图中包含如下几个角色： Abstraction（抽象类）：用于定义抽象类的接口，它一般是抽象类而不是接口，其中定义了一个Implementor（实现类接口）类型的对象并可以维护该对象，它与Implementor之间具有关联关系，它既可以包含抽象业务方法，也可以包含具体业务方法。 RefinedAbstraction（扩充抽象类）：扩充由Abstraction定义的接口，通常情况下它不再是抽象类而是具体类，它实现了在Abstraction中声明的抽象业务方法，在RefinedAbstraction中可以调用在Implementor中定义的业务方法。 Implementor（实现类接口）：定义实现类的接口，这个接口不一定要与Abstraction的接口完全一致，事实上这两个接口可以完全不同，一般而言，Implementor接口仅提供基本操作，而Abstraction定义的接口可能会做更多更复杂的操作。Implementor接口对这些基本操作进行了声明，而具体实现交给其子类。通过关联关系，在Abstraction中不仅拥有自己的方法，还可以调用到Implementor中定义的方法，使用关联关系来替代继承关系。 ConcreteImplementor（具体实现类）：具体实现Implementor接口，在不同的ConcreteImplementor中提供基本操作的不同实现，在程序运行时，ConcreteImplementor对象将替换其父类对象，提供给抽象类具体的业务操作方法。 实例 从上面的这个实例我们可以看出，如果使用多层继承的话，那么我们可以定义是三个抽象类（台式机，笔记本，平板电脑），在这个三个抽象类的下面每个都有三个不同品牌的具体实现类，那么总共要有3x3=9个具体的实现类。不仅仅是类的数量多，在扩展性能上也是成倍的增加，如果想要添加一个品牌，那么需要添加三个类，这个是极其浪费的。 针对上面的缺点，我们可以使用桥接模式，将电脑分类，品牌分类分成两个维度，如下图： 其中Computer是一个抽象类，不是接口，其中Brand（品牌）是其中的成员变量，我们就完成了一个电脑具有不同品牌，那么如果我们想添加一个品牌，就只是添加一个具体的实现类即可，就不需要添加三个了。 笔者有话说 最近建了一个微信交流群，提供给大家一个交流的平台，扫描下方笔者的微信二维码，备注【交流】，我会把大家拉进群]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[设计模式之原型模式]]></title>
      <url>%2F2018%2F04%2F16%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F%2F</url>
      <content type="text"><![CDATA[创建型模式之原型模式定义 原型模式（Prototype Pattern）是用于创建重复的对象，同时又能保证性能。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。 这种模式是实现了一个原型接口，该接口用于创建当前对象的克隆。当直接创建对象的代价比较大时，则采用这种模式。例如，一个对象需要 在一个高代价的数据库操作之后被创建。我们可以缓存该对象，在下一个请求时返回它的克隆，在需要的时候更新数据库，以此来减少数据库调用。 原型模式可以分为浅克隆和深度克隆 角色 java语言中实现克隆的两种方式 直接创建一个对象，然后设置成员变量的值 123Obj obj=new Obj(); //创建一个新的对象obj.setName(this.name); //设置其中变量的值obj.setAge(this.age); 实现cloneable接口 浅克隆 如果克隆的对象的成员变量是值类型的，比如int，double那么使用浅克隆就可以实现克隆完整的原型对象，但是如果其中的成员变量有引用类型的，那么这个引用类型的克隆过去的其实是地址，克隆对象的这个引用类型变量改变了，那么原来变量的值也是会改变的。 简单的说，浅克隆只能复制值类型的，对于引用类型的数据只能复制地址 实例 一个公司出版周报，那么这个周报的格式一般是相同的，只是将其中的内容稍作修改即可。但是一开始没有这个原型，员工每周都需要重新手写这个周报，现在有了这个周报的原型，只需要在这个clone这个原型，然后在其基础上修改即可。 其中的Cloneable就是抽象原型类 附件类（这个是一个引用类型的对象，验证浅克隆只是复制其中的地址，如果两个对象中的任何一个改变了这个变量的值，那么另外一个也会随之改变） 12345678910111213141516171819/* * 附件类，这个是周报的附件 */public class Attachment &#123; private String name; // 名称 public Attachment(String name) &#123; super(); this.name = name; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; 周报的类（其中实现了Cloneable接口） 其中的clone()方法返回的就是一个克隆的对象，因此我们调用这个方法克隆一个新的对象 1234567891011121314151617181920212223242526272829303132333435/* * 这个是周报类，这个类是实现接口Prototype这个接口的 */public class WeeklyLog implements Cloneable &#123; private String name; // 姓名 private String date; // 日期 private String content; // 内容 private Attachment attachment; //附件，是一个引用对象，这个只能实现浅克隆 public WeeklyLog() &#123; super(); &#125; /** * 构造方法 */ public WeeklyLog(String name, String date, String content) &#123; super(); this.name = name; this.date = date; this.content = content; &#125; /** * 提供一个clone方法，返回的是一个clone对象 */ public WeeklyLog clone() &#123; Object object = null; // 创建一个Object对象 try &#123; object = super.clone(); // 直接调用clone方法，复制对象 return (WeeklyLog) object; // 返回即可 &#125; catch (CloneNotSupportedException e) &#123; System.out.println("这个对象不能复制....."); return null; &#125; &#125;&#125; 测试类 测试浅克隆的值类型是是否完成复制了 测试引用类型的值能否完成克隆，还是只是复制了一个引用地址 从结果来看，对象是完成复制了，因为判断两个对象的地址是不一样的，但是其中的引用类型的成员变量没有完成复制，只是复制了一个地址 12345678910111213141516public class Client &#123; public static void main(String[] args) throws CloneNotSupportedException &#123; WeeklyLog p1 = new WeeklyLog("陈加兵", "第一周", "获得劳动模范的称号..."); // 创建一个对象 Attachment attachment = new Attachment("消息"); p1.setAttachment(attachment); // 添加附件 WeeklyLog p2 = p1.clone(); System.out.println(p1 == p2); // 判断是否正确 p2.setName("Jack"); // 修改P2对象的内容 p2.setDate("第二周"); p2.setContent("工作认真....."); System.out.println(p2.getName()); // 返回true，可以知道这两个附件的地址是一样的 System.out.println(p1.getAttachment() == p2.getAttachment()); &#125;&#125; 总结 浅克隆对于值类型的数据可以复制成功，但是对于引用卡类型的数据只能复制一个地址，如果一个对象中的引用类型的变量的值改变了，那么另外一个也会随之改变 深度克隆 浅克隆只能完成复制值类型，深度克隆可以完成复制引用类型和值类型 条件 引用类型的变量类实现序列化(实现Serializabl接口） 需要克隆的类实现序列化(实现Serializable接口) 为什么实现序列化 因为深度克隆的实现的原理是使用输入和输出流，如果想要将一个对象使用输入和输出流克隆，必须序列化。 实现 附件类(引用类型的成员变量，实现序列化) 1234567891011121314151617/* * 附件类，这个是周报的附件 */public class Attachment implements Serializable&#123; private static final long serialVersionUID = -799959163401886355L; private String name; // 名称 public Attachment(String name) &#123; super(); this.name = name; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; 周报类（需要克隆的类，因为其中有引用类型的成员变量，因此需要实现序列化) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/* * 这个是周报类，这个类是实现接口Prototype这个接口的 */public class WeeklyLog implements Serializable &#123; private static final long serialVersionUID = -8782492113927035907L; private String name; // 姓名 private String date; // 日期 private String content; // 内容 private Attachment attachment; // 附件，是一个引用对象，这个只能实现浅克隆 public WeeklyLog() &#123; super(); &#125; /** * 构造方法 */ public WeeklyLog(String name, String date, String content) &#123; super(); this.name = name; this.date = date; this.content = content; &#125; /** * 提供一个clone方法，返回的是一个clone对象 */ public WeeklyLog clone() &#123; // 将对象写入到对象流中 ByteArrayOutputStream arrayOutputStream = new ByteArrayOutputStream(); try &#123; ObjectOutputStream objectOutputStream = new ObjectOutputStream( arrayOutputStream); // 创建对象输出流 objectOutputStream.writeObject(this); // 将这个类的对象写入到输出流中 &#125; catch (IOException e) &#123; e.printStackTrace(); return null; &#125; // 将对象从流中读出 ByteArrayInputStream arrayInputStream = new ByteArrayInputStream( arrayOutputStream.toByteArray()); WeeklyLog weeklyLog; try &#123; ObjectInputStream objectInputStream = new ObjectInputStream( arrayInputStream);// 新建对象输入流 weeklyLog = (WeeklyLog) objectInputStream.readObject(); // 读取对象从流中 return weeklyLog; &#125; catch (IOException | ClassNotFoundException e) &#123; e.printStackTrace(); return null; &#125; &#125;&#125; 测试类 从中可以看出其中的附件地址是不同的，如果一个对象的附件变量改变了，那么另外一个将保持不变，因此实现了深度克隆，是两个完全不同的对象 12345678910111213141516public class Client &#123; public static void main(String[] args) throws CloneNotSupportedException &#123; WeeklyLog p1 = new WeeklyLog("陈加兵", "第一周", "获得劳动模范的称号..."); // 创建一个对象 Attachment attachment = new Attachment("消息"); p1.setAttachment(attachment); // 添加附件 WeeklyLog p2 = p1.clone(); System.out.println(p1 == p2); // 判断是否正确 p2.setName("Jack"); // 修改P2对象的内容 p2.setDate("第二周"); p2.setContent("工作认真....."); System.out.println(p2.getName()); //返回false，可以看出这个是不同的地址，因此完成了深克隆 System.out.println(p1.getAttachment() == p2.getAttachment()); &#125;&#125; 总结 因为深度克隆使用的是将对象写入输入和输出流中的，因此需要实现序列化，否则将不能完成 总结 浅克隆只能克隆对象中的值类型，不能克隆有引用类型成员变量的对象 使用深度克隆： 引用类型的成员变量的类必须实现序列化 需要克隆的类必须实现序列化 笔者有话说 最近建了一个微信交流群，提供给大家一个交流的平台，扫描下方笔者的微信二维码，备注【交流】，我会把大家拉进群]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[设计模式之建造模式]]></title>
      <url>%2F2018%2F04%2F16%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%BB%BA%E9%80%A0%E6%A8%A1%E5%BC%8F%2F</url>
      <content type="text"><![CDATA[创建型模式之建造者模式定义 建造者模式(Builder Pattern)：将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。建造者模式是一种对象创建型模式。 简单说，建造者的功能就是先构造复杂对象的每一个部件，指挥者的功能就是将这些部件以一定的步骤组装起来，形成一个具有一定功能的产品或者对象。当然这个步骤是透明的对于客户端。 建造者模式一步一步创建一个复杂的对象，它允许用户只通过指定复杂对象的类型和内容就可以构建它们，用户不需要知道内部的具体构建细节。建造者模式结构如图8-2所示： 实例 下面是一个组装汽车的例子，其中汽车由发动机和轮胎组成，那么我们只需要组装轮胎，发动机即可组装完成一个汽车。 汽车包括轮胎，引擎，我们通常在组装汽车的时候一般都是一步一步的组装，比如先装引擎，后装轮胎。使用建造者模式就是将建造汽车的这个过程抽离成几个不同的过程，比如建造引擎和建造轮胎就是两个过程。 轮胎的JavaBean 12345678910111213141516171819/* * 轮胎 */class Tyre &#123; private String name; public Tyre(String name) &#123; this.name = name; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; 引擎的JavaBean 1234567891011121314151617181920/* * 引擎 */class Engine &#123; private String name; public Engine(String name) &#123; this.name = name; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; 汽车的JavaBean(汽车包含轮胎和引擎，因此使用聚合的关系) 123456789101112131415161718192021222324/* * 汽车的类 */public class Car &#123; private Tyre tyre; // 轮胎 private Engine engine; // 引擎 public Tyre getTyre() &#123; return tyre; &#125; public void setTyre(Tyre tyre) &#123; this.tyre = tyre; &#125; public Engine getEngine() &#123; return engine; &#125; public void setEngine(Engine engine) &#123; this.engine = engine; &#125;&#125; 抽象建造者(实际上是一个接口，其中定义了建造轮胎和引擎的方法) 1234567891011public interface Builder &#123; /** * 构造引擎的方法 */ Engine buliderEngine(); /** * 构造轮胎的方法 */ Tyre builderTyre();&#125; 具体的建造者(实现了抽象建造者，实现建造轮胎和引擎的详细过程) 12345678910111213141516/* * 具体的建造者，主要是构造汽车的部件 */public class BuilderCar implements Builder &#123; @Override public Engine buliderEngine() &#123; System.out.println("构造汽车发动机"); return new Engine("傻逼牌发动机"); &#125; @Override public Tyre builderTyre() &#123; System.out.println("构造汽车轮胎"); return new Tyre("傻逼牌轮胎"); &#125;&#125; 抽象指挥者(定义了一个构造汽车的方法)，指挥者的作用就是按照一定步骤将构造者建造的部件组装起来 123456/* * 指挥者的接口，用来按照顺序组装汽车 */public interface Director &#123; Car CreateCar();&#125; 具体的指挥者(实现了指挥者接口) 1234567891011121314151617181920212223242526/* * 指挥者的实现类 */public class DirectorCar implements Director &#123; private Builder builder; // 建造者的对象 /** * 构造方法，主要用来初始化建造者对象 * * @param builder Builder的对象 */ public DirectorCar(Builder builder) &#123; this.builder = builder; &#125; @Override public Car CreateCar() &#123; Car car = new Car(); // 创建汽车对象 Engine engine = builder.buliderEngine(); // 构建发动机 Tyre tyre = builder.builderTyre(); // 构造轮胎 car.setEngine(engine); // 设置属性 car.setTyre(tyre); // 设置属性 return car; // 返回构造好的汽车 &#125;&#125; 测试类 12345678public class Client &#123; public static void main(String[] args) &#123; Director director = new DirectorCar(new BuilderCar()); // 创建指挥者的对象 Car car = director.CreateCar(); // 获取组装完成的 System.out.println(car.getEngine().getName()); // 输出引擎的名字 System.out.println(car.getTyre().getName()); // 输出轮胎的名字 &#125;&#125; 适用场景 基本部件不变，但是其中的组合经常变化的情况 比如你去肯德基点餐，汉堡，可乐，鸡翅这些食物是不变的，但是套餐的组合是经常变化的，建造者模式的指挥者就是将这些部件按照一定步骤将其组合起来的。 java中StringBuilder 需要生成的对象具有复杂的内部结构 复杂的内部结构，我们可以使用建造者模式将其分离，先将其中的各个小的部件组装成功，然后由指挥者按照一定的步骤将其组装成一个复杂的对象 需要生成的对象内部属性本身相互依赖。 笔者有话说 最近建了一个微信交流群，提供给大家一个交流的平台，扫描下方笔者的微信二维码，备注【交流】，我会把大家拉进群]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[设计模式之代理模式]]></title>
      <url>%2F2018%2F04%2F16%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%2F</url>
      <content type="text"><![CDATA[结构型模式之代理模式(静态代理) 由于某些原因，客户端不想或不能直接访问一个对象，此时可以通过一个称之为“代理”的第三者来实现间接访问，该方案对应的设计模式被称为代理模式。 代理其实是实现简介访问的媒介，当然在代理类中还可以在执行代理操作之前，之后，之中，环绕等执行相关动作。Spring 中面向切面编程就是这个原理 代理模式是一种应用很广泛的结构型设计模式，而且变化形式非常多，常见的代理形式包括远程代理、保护代理、虚拟代理、缓冲代理、智能引用代理等，后面将学习这些不同的代理形式 当使用代理类的时候， 真实类中的信息对用户来说是透明的(不可见的) 主要就是用于对象的间接访问提供了一个方案，可以对对象的访问进行控制 定义 Subject（抽象主题角色）：它声明了真实主题和代理主题的共同接口，这样一来在任何使用真实主题的地方都可以使用代理主题，客户端通常需要针对抽象主题角色进行编程。 Proxy（代理主题角色）：它包含了对真实主题的引用，从而可以在任何时候操作真实主题对象；在代理主题角色中提供一个与真实主题角色相同的接口，以便在任何时候都可以替代真实主题；代理主题角色还可以控制对真实主题的使用，负责在需要的时候创建和删除真实主题对象，并对真实主题对象的使用加以约束。通常，在代理主题角色中，客户端在调用所引用的真实主题操作之前或之后还需要执行其他操作，而不仅仅是单纯调用真实主题对象中的操作。 RealSubject（真实主题角色）：它定义了代理角色所代表的真实对象，在真实主题角色中实现了真实的业务操作，客户端可以通过代理主题角色间接调用真实主题角色中定义的操作。 实例第一个例子 需求： 我们知道mac笔记本是在美国生产的，那么如果中国供销商想要卖mac笔记本，那么必须从美国供销商那里先进货，然后中国的顾客才可以在中国供销商买mac。这里的中国供销商就相当于代理，美国供销商就相当于真实主题角色 Mac笔记本抽象接口(相当于其中的抽象主题) 123456/* * 苹果笔记本的接口，其中有一个方法实现了买笔记本的动作 */public interface MacBook &#123; public void buy(); //购买笔记本的行为&#125; 美国供销商(相当于这里RealSubject) 1234567891011/* * 美国的笔记本，实现了MacBook接口，表示在美国买笔记本 */public class USAMac implements MacBook &#123; @Override public void buy() &#123; System.out.println("在美国买笔记本"); &#125;&#125; 中国供销商(相当于这里的代理角色) 我们可以看到我们在使用代理模式的时候可以在之前和之后进行操作12345678910111213141516171819202122232425262728293031/* * 中国的笔记本，实现了MacBook 表示在中国买笔记本 * 但是中国想要买到苹果笔记本，那么还是需要先从美国进货，因此中国只是一个中间的代理作用而已 * 当然代理的最大作用就是在代理之前、之后、之中执行相关的操作，这就是面向切面编程的原理 */public class ChinaMac implements MacBook &#123; private MacBook mcBook=new USAMac(); //创建USAMac的对象 /** * 在购买之前执行的操作 */ public void preBuy()&#123; System.out.println("购买之前执行的操作"); &#125; /** * 在购买之后执行的操作 */ public void afterBuy()&#123; System.out.println("购买之后执行的操作"); &#125; @Override public void buy() &#123; this.preBuy(); //之前执行的操作 mcBook.buy(); //在美国买笔记本 System.out.println("在中国买笔记本"); this.afterBuy(); //之后执行的操作 &#125;&#125; 测试类 我们在使用的时候直接使用代理类即可，我们根本不知道在真实类的使用，完全是代理类为我们提供了 1234567public class Client &#123; public static void main(String[] args) &#123; MacBook macBook=new ChinaMac(); //创建ChinaMac对象，在中国买笔记本 macBook.buy(); //直接在中国买笔记本 &#125;&#125; 第二个例子 我们登录一个网站的服务器端的验证步骤： 读取用户名和密码 验证用户名和密码 记录到日志中 这里的验证密码和记录到日志中可以在代理类中实现，在用户执行操作之前需要读取用户名和密码，并且验证，在操作之后需要将用户的一些操作记录到日志中。其实这里的真实用户需要做的只是执行自己的操作，而验证和记录都是交给代理类实现的。 实现 用户接口(User) 1234567/* * 用户的抽象类 */public interface User &#123; public void DoAction(); //执行动作&#125; 真实的用户类（实现了用户接口） 主要的做的就是执行自己的操作 12345678910111213141516public class RealUser implements User &#123; public String name; public String password; public RealUser(String name, String password) &#123; this.name = name; this.password = password; &#125; public RealUser() &#123;&#125; /* * 执行一些操作 */ @Override public void DoAction() &#123; System.out.println("开始执行操作......"); &#125;&#125; 代理类(实现了User接口) 在执行操作之前验证密码和用户名是否正确 在执行操作之后记录到日志中 实际上这里就是面向切面编程 12345678910111213141516171819202122232425262728293031323334353637383940public class ProxUser implements User &#123; private RealUser user; // 真实用户的对象 /** * 创建对象 * @param name 姓名 * @param password 密码 */ public ProxUser(String name, String password) &#123; user = new RealUser(name, password); &#125; @Override public void DoAction() &#123; //验证用户名和密码 if (Validate()) &#123; user.DoAction(); //调用真实用户的DoAction方法执行相关操作 logger(); //调用日志记录信息 &#125; else &#123; System.out.println("请重新登录......."); &#125; &#125; /* * 验证用户的用户名和密码 */ public Boolean Validate() &#123; if ("陈加兵".equals(user.name) &amp;&amp; "123456".equals(user.password)) &#123; return true; &#125; return false; &#125; /** * 添加日志记录信息 */ public void logger() &#123; System.out.println(user.name + "登录成功......"); &#125;&#125; 测试类 实际上执行了验证用户名和密码，记录日志的操作，但是对于客户端来说只能看到自己执行的操作 123456public class Client &#123; public static void main(String[] args) &#123; ProxUser proxUser=new ProxUser("陈加兵", "123456"); //创建代理对象 proxUser.DoAction(); //执行操作，实际执行了验证信息，doaction(),日志记录这个三个动作 &#125;&#125; 缺点 如果增加一个接口就需要增加一个代理类，如果是要增加很多，那么就要增加很多代理类，代码将会重复 解决方法 下面我们将会讲解到动态代理，仅仅需要一个代理类即可 结构型模式之动态代理模式 前面我们说的代理模式其实是属于静态代理模式，就是说在程序执行之前已经写好了代理类，但是缺点也是说过，必须为每个接口都实现一个代理类，如果有多个接口需要代理，那么代码肯定是要重复的，因此就需要动态代理了。 动态代理可以实现多个接口共用一个代理类，只需要改变初始化的参数即可，可以省去很多的重复的代码。 JDK的动态代理需要一个类一个接口，分别为Proxy和InvocationHandler 主要原理就是利用了反射的原理 InvocationHandler 这个是代理类必须实现的接口，其中有一个方法public Object invoke(Object proxy,Method method,Object[] args) Object proxy：指被代理的对象。 Method method：要调用的方法 Object[] args：方法调用时所需要的参数 Proxy Proxy类是专门完成代理的操作类，可以通过此类为一个或多个接口动态地生成实现类，此类提供了如下的操作方法：public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) ClassLoader loader：类加载器 Class&lt;?&gt;[] interfaces：得到全部的接口 InvocationHandler h：得到InvocationHandler接口的子类实例 实例 肯德基的接口 123456/* * 肯德基的接口，其中一个eat方法 */public interface IKFC &#123; public void eat();&#125; 肯德基的实现类(RealSubject) 1234567891011/* * IKFC的实现类 */public class KFC implements IKFC &#123; @Override public void eat() &#123; System.out.println("我在肯德基吃了饭......"); &#125;&#125; 苹果笔记本的接口 123456/* * 苹果笔记本的接口 */public interface MacBook &#123; public void buy();&#125; 美国供销商的类(RealSubject) 12345678910/* * 美国笔记本的类，实现了MacBook接口 */public class USAMacBook implements MacBook &#123; @Override public void buy() &#123; System.out.println("在美国买了一个苹果电脑......"); &#125;&#125; 动态代理的类（实现了InvocationHandler接口） 1234567891011121314151617181920212223242526272829303132333435363738394041424344import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;/** * 这个是代理类，实现了InvocationHandler接口 * */public class ProxyHandler implements InvocationHandler &#123; private Object Realobject; //被代理的对象 //构造方法，用来初始化被代理的对象 public ProxyHandler(Object obj)&#123; this.Realobject=obj; //初始化真实类的对象 &#125; /** * @param proxy 表示被代理的对象的，就是真实类的对象 * @param method 表示要调用真实类的方法 * @param args 表示方法调用的时候所需要的参数 * @return 方法调用之后的返回值 */ public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; prefunction(); //执行之前调用的方法 Object res=method.invoke(Realobject, args); //Method类中的执行方法的函数，在反射中常用 afterFunction(); //执行之后调用的方法 return res; &#125; /** * 执行方法之前调用的方法 */ public void prefunction()&#123; System.out.println("执行方法之前......"); &#125; /** * 执行方法之后调用的方法 */ public void afterFunction()&#123; System.out.println("执行方法之后......"); &#125;&#125; 测试类 1234567891011121314151617181920212223import java.lang.reflect.Proxy;import com.sun.org.apache.bcel.internal.generic.NEW;import com.sun.org.apache.bcel.internal.util.Class2HTML;public class Client &#123; public static void main(String[] args) &#123; Class[] cls1=&#123;IKFC.class&#125;; //第一个代理的所有接口数组，直接用接口的反射即可 Class[] cls2=USAMacBook.class.getInterfaces(); //直接具体的实现类的反射调用getInterfaces即可返回所有的接口数组 // 返回KFC的代理对象 IKFC kfc = (IKFC) Proxy.newProxyInstance(Client.class.getClassLoader(), cls1, new ProxyHandler(new KFC())); kfc.eat(); //执行方法 MacBook macBook = (MacBook) Proxy.newProxyInstance(Client.class.getClassLoader(), cls2, new ProxyHandler( new USAMacBook())); macBook.buy(); //执行方法 &#125;&#125; 总结 动态代理的好处 即使有多个接口，也仅仅只有一个动态代理类 笔者有话说 最近建了一个微信交流群，提供给大家一个交流的平台，扫描下方笔者的微信二维码，备注【交流】，我会把大家拉进群]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[设计模式之单例模式]]></title>
      <url>%2F2018%2F04%2F12%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
      <content type="text"><![CDATA[创建型模式之单例模式(Singleton)什么是单例模式 该类只有一个实例 构造方法是私有的 有一个获取该类对象的静态方法getInstance() 应用场景 一个国家只有一个主席 如果此时的限定必须是抽象出来的类只能是一个对象，这个时候就需要使用单例模式 懒汉式什么是懒汉式 懒汉式是当用到这个对象的时候才会创建，即是在getInstance()方法创建这个单例对象 优缺点 只有用到的时候才会创建这个对象，因此节省资源 线程不安全 我们知道一旦我们使用了懒汉式就是在getInstance()方法中创建这个单例对象，那么不可避免的就是线程安全问题 实现12345678910111213141516171819202122/** * 懒汉式的单例模式： 不是线程安全的 * 优点： 在使用的时候才会初始化，可以节省资源 */public class SignalLazy &#123; // 将默认的构造器设置为private类型的 private SignalLazy() &#123; &#125; // 静态的单例对象 private static SignalLazy instance; //静态的获取单例的对象，其中有一个判断，如果没有初始化，那么就创建 public static SignalLazy getInstance() &#123; // 如果instance没有被初始化，那么就创建即可，这个是保证了单例，但是并不是线程安全的 if (instance == null) &#123; System.out.println("this is SignalLazy"); instance = new SignalLazy(); // 创建一 个对象 &#125; return instance; // 返回这个对象 &#125;&#125; 从上面的代码中我们可以知道一旦使用多线程创建对象，那么就会出现线程不安全，最后创建出来的就不是单例了 测试代码如下 12345678910111213141516171819public class MainTest &#123; public static void main(String[] args) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; //创建实例，并且输出其中的地址，如果地址相同， 那么就是同一个实例 System.out.println("this is"+ SignalLazy.getInstance()); &#125; &#125;).start(); //主线程也是创建输出其中的地址，运行可以看出这两个地址是不一样的 System.out.println("this is"+SignalLazy.getInstance()); &#125;&#125; 解决线程不安全 线程同步锁(synchronized) 我们知道每一个类都有一个把锁，我们可以使用线程同步锁来实现线程同步方法 但是使用线程同步锁浪费资源，因为每次创建实例都需要请求同步锁，浪费资源 12345678public synchronized static SignalLazy getInstance() &#123; // 如果instance没有被初始化，那么就创建即可，这个是保证了单例，但是并不是线程安全的 if (instance == null) &#123; System.out.println("this is SignalLazy"); instance = new SignalLazy(); // 创建一个对象 &#125; return instance; // 返回这个对象 &#125; 双重校验 双重校验： 两次判断单例对象是否为 null，这样的话，当当线程经过这个判断的时候就会先判断，而不是等待，一旦判断不成立，那么就会继续执行，不需要等待 相对于前面的同步方法更加节省资源 123456789101112131415161718192021222324public class SignalTonDoubleCheck &#123; private volatile static SignalTonDoubleCheck instance = null; private SignalTonDoubleCheck() &#123; &#125;; // 将默认的构造方法设置私有 public static SignalTonDoubleCheck getInstance() &#123; if (instance == null) &#123; synchronized (SignalTonDoubleCheck.class) &#123; if (instance == null) &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; // 这个new 并不是原子操作，因此当多线程进行到这里需要及时刷新这个值，因此要设置为voliate instance = new SignalTonDoubleCheck(); &#125; &#125; &#125; return instance; &#125;&#125; 匿名内部类 （推荐使用） 我们知道静态变量、静态代码块、静态方法都是在类加载的时候只加载一次 12345678910111213141516public class SignalTonInnerHolder &#123; //私有构造函数 private SignalTonInnerHolder() &#123; &#125; /* * 匿名内部类，其中利用了静态成员变量在类加载的时候初始化，并且只加载一次，因此保证了单例 */ private static class InnerHolder &#123; private static SignalTonInnerHolder instance = new SignalTonInnerHolder(); &#125; public static SignalTonInnerHolder getInstance() &#123; return InnerHolder.instance; //加载类 &#125;&#125; 一旦加载SignalTonInnerHolder类的时候就会加载其中的静态类，随之加载的就是其中的创建对象语句，因此在类加载的时候就完成了创建，这个和我们后面说的饿汉式有点相同 饿汉式什么是饿汉式 在类加载的时候就创建单例对象，而不是在getInstance()方法创建 所谓的饿汉式就是利用静态成员变量或者静态语句块在类加载的时候初始化，并且只初始化一次，因此这个是线程安全的，但是在没有用到的时候就初始化，那么是浪费资源 优缺点 还没用到就创建，浪费资源 类加载的时候就创建，线程安全 实现12345678910111213141516/* * 饿汉式：线程安全 * */public class SignalHungry &#123; private SignalHungry() &#123; &#125; // 静态变量只有在类加载的时候初始化一次，因此这个是线程安全的 private static SignalHungry instance = new SignalHungry(); public static SignalHungry getInstance() &#123; return instance; &#125;&#125; 测试12345678910111213141516171819public class MainTest &#123; public static void main(String[] args) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; //创建实例，并且输出其中的地址，如果地址相同， 那么就是同一个实例 System.out.println("this is"+ SignalHungry.getInstance()); &#125; &#125;).start(); //主线程也是创建输出其中的地址，运行可以看出这两个地址是不一样的 System.out.println("this is"+SignalHungry.getInstance()); &#125;&#125; 总结 饿汉式在类加载的时候就会创建单例对象，因此浪费资源 懒汉式在用到的时候才创建，节省资源，但是线程不安全，但是我们可以使用匿名内部类的方式使其线程安全 一般在使用的时候会使用懒汉式的匿名内部类的实现和饿汉式的创建方式 笔者有话说 最近建了一个微信交流群，提供给大家一个交流的平台，扫描下方笔者的微信二维码，备注【交流】，我会把大家拉进群]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[设计模式之常见关系]]></title>
      <url>%2F2018%2F04%2F12%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%B8%B8%E8%A7%81%E5%85%B3%E7%B3%BB%2F</url>
      <content type="text"><![CDATA[继承和泛化 泛华关系是一种继承关系，表示一般与特殊的关系，它指定了子类如何特化父类的所有特征和行为。 使用三角箭头的实线表示继承，其中箭头指向的是父类 接口与实现 在java中一个类只能继承一个父类，但是可以实现多个接口 使用的是带三角的虚线表示，其中箭头指向的是接口 依赖 是一种使用关系，即一个类的实现需要另外一个类的协助，所以尽量不使用双向的依赖关系。 最典型的就是import 比如：一个类要定义String类型的变量，那么这个类就是依赖String这个类 关联 是一种拥有的关系，它使一个类知道另外一个类的属性和方法，比如数据库中的关系，通过学生可以查找到自己课程的成绩，只需要在学生中定义一个课程的对象即可。 代码体现： 成员变量 带普通箭头的实心线，指向被拥有者 聚合 是整体和部分的关系，且部分可以离开整体而单独的存在。车和轮胎是整体和部分的关系，但是轮胎离开车还是可以单独存在的 代码体现： 成员变量 带空心菱形的实心线，菱形指向整体 组合 是整体和部分的关系，但是部分不能离开整体而单独存在 代码体现：成员变量 带实心菱形的实线，菱形指向整体 笔者有话说 最近建了一个微信交流群，提供给大家一个交流的平台，扫描下方笔者的微信二维码，备注【交流】，我会把大家拉进群]]></content>
    </entry>

    
  
  
</search>
